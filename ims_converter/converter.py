"""
IMSä¸»è½¬æ¢å™¨

å°†å®Œæ•´çš„VGPè¾“å‡ºè½¬æ¢ä¸ºé˜¿é‡Œäº‘IMS Timelineæ ¼å¼
"""

from typing import Dict, List, Any, Optional
import logging
from .utils import (
    TransitionConverter,
    FilterConverter,
    EffectConverter,
    FlowerTextConverter,
    OverlayConverter
)

logger = logging.getLogger(__name__)


class IMSConverter:
    """VGPåˆ°IMSçš„ä¸»è½¬æ¢å™¨"""

    def __init__(self, use_filter_preset: bool = True):
        """
        åˆå§‹åŒ–è½¬æ¢å™¨

        Args:
            use_filter_preset: æ˜¯å¦ä½¿ç”¨æ»¤é•œé¢„è®¾(True)æˆ–ç²¾ç¡®å‚æ•°(False)
        """
        self.use_filter_preset = use_filter_preset

    def convert(self, vgp_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        å°†å®Œæ•´çš„VGPè¾“å‡ºè½¬æ¢ä¸ºIMS Timeline

        Args:
            vgp_result: VGPå®Œæ•´è¾“å‡ºï¼ŒåŒ…å«æ‰€æœ‰èŠ‚ç‚¹çš„ç»“æœ
                {
                    "transition_sequence_id": [...],
                    "filter_sequence_id": [...],
                    "effects_sequence_id": [...],
                    "text_overlay_track_id": {...},
                    "auxiliary_track_id": {...},
                    "bgm_composition_id": {...}  # æ–°å¢ï¼šBGMè½¨é“
                }

        Returns:
            IMS Timelineå¯¹è±¡
                {
                    "VideoTracks": [...],
                    "AudioTracks": [...],  # æ–°å¢
                    "EffectTracks": [...],
                    "TextTracks": [...]
                }
        """
        timeline = {
            "VideoTracks": [],
            "AudioTracks": [],  # âœ… æ–°å¢ï¼šéŸ³é¢‘è½¨é“
            "EffectTracks": [],
            "SubtitleTracks": []  # âœ… ä¿®æ­£ï¼šä½¿ç”¨SubtitleTracksè€Œä¸æ˜¯TextTracksï¼ˆIMSæ ‡å‡†ï¼‰
        }

        # 1. è½¬æ¢ä¸»è§†é¢‘è½¨é“ + è½¬åœº
        logger.info("å¼€å§‹è½¬æ¢è§†é¢‘è½¨é“å’Œè½¬åœº...")
        video_clips = self._convert_video_clips(vgp_result)
        if video_clips:
            timeline["VideoTracks"].append({
                "VideoTrackClips": video_clips
            })

        # 2. è½¬æ¢éŸ³é¢‘è½¨é“ (BGM + TTS + SFX)
        logger.info("å¼€å§‹è½¬æ¢éŸ³é¢‘è½¨é“...")
        logger.info(f"   ğŸµ æ£€æŸ¥BGMæ•°æ®: bgm_composition_idå­˜åœ¨={('bgm_composition_id' in vgp_result)}")
        if "bgm_composition_id" in vgp_result:
            bgm = vgp_result["bgm_composition_id"]
            logger.info(f"   ğŸµ BGMç±»å‹: {type(bgm).__name__}")
            if isinstance(bgm, dict):
                logger.info(f"   ğŸµ BGM keys: {list(bgm.keys())}")
                logger.info(f"   ğŸµ BGM clipsæ•°é‡: {len(bgm.get('clips', []))}")

        audio_tracks = self._convert_audio_tracks(vgp_result)
        if audio_tracks:
            timeline["AudioTracks"] = audio_tracks
            logger.info(f"   âœ… æˆåŠŸæ·»åŠ  {len(audio_tracks)} ä¸ªéŸ³é¢‘è½¨é“")

        # 3. è½¬æ¢æ»¤é•œè½¨é“
        logger.info("å¼€å§‹è½¬æ¢æ»¤é•œ...")
        filter_track = self._convert_filters(vgp_result)
        if filter_track:
            timeline["EffectTracks"].append(filter_track)

        # 4. è½¬æ¢ç‰¹æ•ˆè½¨é“
        logger.info("å¼€å§‹è½¬æ¢ç‰¹æ•ˆ...")
        effect_track = self._convert_effects(vgp_result)
        if effect_track:
            timeline["EffectTracks"].append(effect_track)

        # 5. è½¬æ¢æ–‡å­—è½¨é“(èŠ±å­—) - æ·»åŠ åˆ°SubtitleTracks
        logger.info("å¼€å§‹è½¬æ¢æ–‡å­—/èŠ±å­—...")
        text_track = self._convert_text_overlay(vgp_result)
        if text_track:
            timeline["SubtitleTracks"].append(text_track)  # âœ… æ·»åŠ åˆ°SubtitleTracks
            logger.info(f"   âœ… å·²æ·»åŠ èŠ±å­—è½¨é“")

        # 6. è½¬æ¢è¾…åŠ©åª’ä½“ (ä½œä¸ºé¢å¤–çš„è§†é¢‘è½¨é“)
        logger.info("å¼€å§‹è½¬æ¢è¾…åŠ©åª’ä½“...")
        aux_track = self._convert_auxiliary_media(vgp_result)
        if aux_track:
            timeline["VideoTracks"].append(aux_track)

        logger.info("IMS Timelineè½¬æ¢å®Œæˆ")
        return timeline

    def _convert_audio_tracks(self, vgp_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        è½¬æ¢éŸ³é¢‘è½¨é“ (BGM + TTS + SFX)

        ä»bgm_composition_idã€tts_trackã€sfx_trackç­‰æå–
        """
        audio_tracks = []

        # 1. å¤„ç†BGMè½¨é“
        bgm_data = vgp_result.get("bgm_composition_id")
        logger.debug(f"ğŸµ BGMæ•°æ®æ£€æŸ¥: type={type(bgm_data)}, has_clips={isinstance(bgm_data, dict) and 'clips' in bgm_data}")
        if isinstance(bgm_data, dict):
            logger.debug(f"   BGMæ•°æ®keys: {list(bgm_data.keys())}")
            clips_count = len(bgm_data.get("clips", []))
            logger.debug(f"   BGM clipsæ•°é‡: {clips_count}")

        if bgm_data and isinstance(bgm_data, dict):
            bgm_clips = bgm_data.get("clips", [])
            if bgm_clips:
                audio_track_clips = []
                for clip in bgm_clips:
                    audio_info = clip.get("audio", {})
                    audio_url = audio_info.get("url", "")

                    # âœ… è¿‡æ»¤æ— æ•ˆçš„å ä½ç¬¦URLï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰
                    if not audio_url or audio_url.startswith("https://audio.com/") or audio_url.startswith("https://assets.example.com/"):
                        logger.warning(f"âš ï¸ è·³è¿‡æ— æ•ˆçš„BGM URL: {audio_url}")
                        continue

                    # æ™ºèƒ½éŸ³é‡è°ƒæ•´ï¼šBGMé»˜è®¤éŸ³é‡é€‚ä¸­ï¼ˆèƒŒæ™¯éŸ³ä¹ä¸åº”å¤ªå°ï¼Œä½†ä¹Ÿä¸èƒ½ç›–è¿‡äººå£°ï¼‰
                    # VGPçš„volume_dbé€šå¸¸æ˜¯-18åˆ°-20dBï¼Œè½¬æ¢åå¤ªå°ï¼ˆ0.1-0.12ï¼‰
                    # ä¿®æ­£ç­–ç•¥ï¼šä½¿ç”¨å›ºå®šçš„åˆç†éŸ³é‡ï¼ˆ0.3-0.4ï¼Œå³30%-40%éŸ³é‡ï¼‰
                    volume_db = clip.get("volume_db", -18.0)

                    # æ ¹æ®VGPçš„éŸ³é‡å»ºè®®è°ƒæ•´ï¼Œä½†ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…
                    if volume_db >= -10:  # è¾ƒå“
                        gain = 0.5  # 50%éŸ³é‡
                    elif volume_db >= -15:  # ä¸­ç­‰
                        gain = 0.4  # 40%éŸ³é‡
                    elif volume_db >= -20:  # è¾ƒè½»
                        gain = 0.3  # 30%éŸ³é‡
                    else:  # å¾ˆè½»
                        gain = 0.25  # 25%éŸ³é‡

                    logger.debug(f"   BGMéŸ³é‡è°ƒæ•´: {volume_db}dB â†’ Gain {gain}")

                    # è®¡ç®—æ—¶é—´èŒƒå›´
                    timeline_in = float(clip.get("start", 0.0))
                    timeline_out = float(clip.get("end", clip.get("start", 0.0) + clip.get("duration", 0.0)))

                    # é˜²å¾¡æ€§æ£€æŸ¥ï¼šç¡®ä¿timeline_out > timeline_in
                    if timeline_out <= timeline_in:
                        logger.warning(f"âš ï¸ BGMç‰‡æ®µæ—¶é—´èŒƒå›´æ— æ•ˆ [{timeline_in} - {timeline_out}]ï¼Œè·³è¿‡")
                        continue

                    ims_clip = {
                        "MediaURL": audio_info.get("url", ""),
                        "TimelineIn": int(round(timeline_in)),
                        "TimelineOut": int(round(timeline_out)),
                        "In": audio_info.get("in_point", 0.0),
                        "Out": audio_info.get("out_point", audio_info.get("duration", 10.0)),
                        "Effects": [
                            {
                                "Type": "Volume",
                                "Gain": gain  # è½¬æ¢ä¸ºIMSçš„Gainå€¼ (0-2å€, 1ä¸ºåŸå§‹éŸ³é‡)
                            }
                        ]
                    }

                    # æ·»åŠ æ·¡å…¥æ·¡å‡ºæ•ˆæœ
                    transition = clip.get("transition", "")
                    if "æ·¡å…¥" in transition or "fade" in transition.lower():
                        ims_clip["Effects"].append({
                            "Type": "AFade",
                            "StartTime": clip.get("start", 0.0),
                            "Duration": 2.0,
                            "FadeType": "In"
                        })

                    audio_track_clips.append(ims_clip)

                if audio_track_clips:
                    audio_tracks.append({
                        "AudioTrackClips": audio_track_clips
                    })
                    logger.info(f"   âœ… æ·»åŠ BGMè½¨é“ï¼ŒåŒ…å« {len(audio_track_clips)} ä¸ªæœ‰æ•ˆéŸ³é¢‘ç‰‡æ®µ")
                else:
                    logger.warning(f"   âš ï¸ BGMè½¨é“ä¸­æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘URLï¼Œè·³è¿‡BGMè½¨é“")

        # 2. å¤„ç†è¾…åŠ©éŸ³é¢‘ï¼ˆä»auxiliary_track_idä¸­æå–éŸ³é¢‘ç±»å‹çš„ç´ æï¼‰
        aux_track = vgp_result.get("auxiliary_track_id")
        if aux_track and isinstance(aux_track, dict):
            clips = aux_track.get("clips", [])
            audio_clips = [c for c in clips if c.get("type") == "audio"]

            if audio_clips:
                sfx_track_clips = []
                for clip in audio_clips:
                    # éŸ³æ•ˆéŸ³é‡ç•¥é«˜äºBGMï¼Œä½†ä½äºäººå£°
                    gain = 0.5  # 50%éŸ³é‡

                    # è®¡ç®—æ—¶é—´èŒƒå›´
                    timeline_in = float(clip.get("start", 0.0))
                    timeline_out = timeline_in + float(clip.get("duration", 3.0))

                    # é˜²å¾¡æ€§æ£€æŸ¥ï¼šç¡®ä¿timeline_out > timeline_in
                    if timeline_out <= timeline_in:
                        logger.warning(f"âš ï¸ SFXç‰‡æ®µæ—¶é—´èŒƒå›´æ— æ•ˆ [{timeline_in} - {timeline_out}]ï¼Œè·³è¿‡")
                        continue

                    ims_clip = {
                        "MediaURL": clip.get("file_path", ""),
                        "TimelineIn": int(round(timeline_in)),
                        "TimelineOut": int(round(timeline_out)),
                        "Effects": [
                            {
                                "Type": "Volume",
                                "Gain": gain
                            }
                        ]
                    }
                    sfx_track_clips.append(ims_clip)

                if sfx_track_clips:
                    audio_tracks.append({
                        "AudioTrackClips": sfx_track_clips
                    })

        logger.info(f"è½¬æ¢äº† {len(audio_tracks)} ä¸ªéŸ³é¢‘è½¨é“")
        return audio_tracks

    def _db_to_gain(self, db: float) -> float:
        """
        å°†dBéŸ³é‡è½¬æ¢ä¸ºIMSçš„Gainå€¼

        Args:
            db: åˆ†è´å€¼ (-âˆ to 0)

        Returns:
            Gainå€¼ (0-2å€ï¼Œ1ä¸ºåŸå§‹éŸ³é‡)
        """
        # IMS Gain: 0 = é™éŸ³, 1 = åŸå§‹éŸ³é‡, 2 = 200%éŸ³é‡
        # dBè½¬çº¿æ€§: gain = 10^(db/20)
        import math
        if db <= -60:
            return 0.0
        gain = math.pow(10, db / 20.0)
        # é™åˆ¶åœ¨åˆç†èŒƒå›´
        return max(0.0, min(2.0, gain))

    def _convert_video_clips(self, vgp_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        è½¬æ¢ä¸»è§†é¢‘è½¨é“å’Œè½¬åœº

        ä»transition_sequence_idæˆ–filter_sequence_idä¸­æå–
        """
        # ä¼˜å…ˆä½¿ç”¨æœ‰æ»¤é•œçš„åºåˆ—ï¼Œå¦åˆ™ä½¿ç”¨è½¬åœºåºåˆ—
        sequence = vgp_result.get("filter_sequence_id") or \
                   vgp_result.get("effects_sequence_id") or \
                   vgp_result.get("transition_sequence_id") or \
                   []

        if not sequence:
            logger.warning("æœªæ‰¾åˆ°è§†é¢‘å‰ªè¾‘åºåˆ—")
            return []

        video_clips = []

        for i, clip in enumerate(sequence):
            # è®¡ç®—æ—¶é—´èŒƒå›´
            timeline_in = float(clip.get("start", 0.0))
            timeline_out = float(clip.get("end", clip.get("start", 0.0) + clip.get("duration", 0.0)))

            # é˜²å¾¡æ€§æ£€æŸ¥ï¼šç¡®ä¿timeline_out > timeline_in
            if timeline_out <= timeline_in:
                logger.warning(f"âš ï¸ è§†é¢‘ç‰‡æ®µ {i+1} æ—¶é—´èŒƒå›´æ— æ•ˆ [{timeline_in} - {timeline_out}]ï¼Œè·³è¿‡")
                continue

            ims_clip = {
                "MediaURL": clip.get("source_url", ""),
                "TimelineIn": int(round(timeline_in)),
                "TimelineOut": int(round(timeline_out)),
                "Effects": []
            }

            # æ·»åŠ è½¬åœº (åœ¨clipçš„Effectsä¸­)
            if "transition_out" in clip:
                transition = TransitionConverter.convert(clip["transition_out"])
                if transition:
                    # å°è¯•æ¨æ–­æ–¹å‘
                    next_clip = sequence[i + 1] if i + 1 < len(sequence) else None
                    if clip["transition_out"].get("type") in ["wipe_push", "slide"]:
                        subtype = TransitionConverter.infer_direction(
                            clip["transition_out"],
                            current_clip=clip,
                            next_clip=next_clip
                        )
                        transition["SubType"] = subtype

                    ims_clip["Effects"].append(transition)

            video_clips.append(ims_clip)

        return video_clips

    def _convert_filters(self, vgp_result: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        è½¬æ¢æ»¤é•œä¸ºEffectTrack

        ä»filter_sequence_idä¸­æå–color_filter
        """
        sequence = vgp_result.get("filter_sequence_id") or \
                   vgp_result.get("effects_sequence_id") or \
                   []

        if not sequence:
            return None

        filter_items = []

        for clip in sequence:
            if "color_filter" not in clip:
                continue

            color_filter = clip["color_filter"]

            # æ ¹æ®é…ç½®é€‰æ‹©è½¬æ¢æ–¹å¼
            if self.use_filter_preset:
                ims_filter = FilterConverter.convert_preset(color_filter)
            else:
                ims_filter = FilterConverter.convert_params(color_filter)

            # æ·»åŠ æ—¶é—´èŒƒå›´
            timeline_in = float(clip.get("start", 0.0))
            timeline_out = float(clip.get("end", clip.get("start", 0.0) + clip.get("duration", 0.0)))

            # é˜²å¾¡æ€§æ£€æŸ¥ï¼šç¡®ä¿timeline_out > timeline_in
            if timeline_out <= timeline_in:
                logger.warning(f"âš ï¸ æ»¤é•œç‰‡æ®µæ—¶é—´èŒƒå›´æ— æ•ˆ [{timeline_in} - {timeline_out}]ï¼Œè·³è¿‡")
                continue

            ims_filter["TimelineIn"] = int(round(timeline_in))
            ims_filter["TimelineOut"] = int(round(timeline_out))

            filter_items.append(ims_filter)

        if not filter_items:
            return None

        return {
            "EffectTrackItems": filter_items
        }

    def _convert_effects(self, vgp_result: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        è½¬æ¢ç‰¹æ•ˆä¸ºEffectTrack

        ä»effects_sequence_idä¸­æå–visual_effects
        """
        sequence = vgp_result.get("effects_sequence_id", [])

        if not sequence:
            return None

        effect_items = []

        for clip in sequence:
            visual_effects = clip.get("visual_effects", [])

            for vgp_effect in visual_effects:
                ims_effect = EffectConverter.convert(vgp_effect)
                if ims_effect:
                    # æ·»åŠ æ—¶é—´èŒƒå›´
                    timeline_in = float(clip.get("start", 0.0))
                    timeline_out = float(clip.get("end", clip.get("start", 0.0) + clip.get("duration", 0.0)))

                    # é˜²å¾¡æ€§æ£€æŸ¥ï¼šç¡®ä¿timeline_out > timeline_in
                    if timeline_out <= timeline_in:
                        logger.warning(f"âš ï¸ ç‰¹æ•ˆç‰‡æ®µæ—¶é—´èŒƒå›´æ— æ•ˆ [{timeline_in} - {timeline_out}]ï¼Œè·³è¿‡")
                        continue

                    ims_effect["TimelineIn"] = int(round(timeline_in))
                    ims_effect["TimelineOut"] = int(round(timeline_out))

                    effect_items.append(ims_effect)

        if not effect_items:
            return None

        return {
            "EffectTrackItems": effect_items
        }

    def _convert_text_overlay(self, vgp_result: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        è½¬æ¢æ–‡å­—å åŠ ä¸ºTextTrack (èŠ±å­—)

        ä»text_overlay_track_idä¸­æå–
        """
        text_track = vgp_result.get("text_overlay_track_id")

        logger.debug(f"ğŸŒ¸ èŠ±å­—æ•°æ®æ£€æŸ¥: type={type(text_track)}, is_dict={isinstance(text_track, dict)}")
        if isinstance(text_track, dict):
            logger.debug(f"   èŠ±å­—æ•°æ®keys: {list(text_track.keys())}")
            clips_count = len(text_track.get("clips", []))
            logger.debug(f"   èŠ±å­—clipsæ•°é‡: {clips_count}")

        if not text_track or not isinstance(text_track, dict):
            logger.debug("   âš ï¸ èŠ±å­—æ•°æ®ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")
            return None

        clips = text_track.get("clips", [])
        if not clips:
            logger.debug("   âš ï¸ èŠ±å­—clipsä¸ºç©º")
            return None

        subtitle_clips = []

        for vgp_text in clips:
            ims_subtitle = FlowerTextConverter.convert(vgp_text)
            subtitle_clips.append(ims_subtitle)

        return {
            "SubtitleTrackClips": subtitle_clips  # âœ… ä¿®æ­£å­—æ®µåï¼šIMSæœŸæœ›çš„æ˜¯SubtitleTrackClips
        }

    def _convert_auxiliary_media(self, vgp_result: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        è½¬æ¢è¾…åŠ©åª’ä½“ä¸ºé¢å¤–çš„VideoTrack

        ä»auxiliary_track_idä¸­æå–
        """
        aux_track = vgp_result.get("auxiliary_track_id")

        if not aux_track or not isinstance(aux_track, dict):
            return None

        clips = aux_track.get("clips", [])
        if not clips:
            return None

        overlay_clips = []

        for vgp_media in clips:
            ims_clip = OverlayConverter.convert(vgp_media)
            overlay_clips.append(ims_clip)

        if not overlay_clips:
            return None

        return {
            "VideoTrackClips": overlay_clips
        }

    def convert_to_ims_request(self, vgp_result: Dict[str, Any],
                               output_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        è½¬æ¢ä¸ºå®Œæ•´çš„IMS SubmitMediaProducingJobè¯·æ±‚

        Args:
            vgp_result: VGPè¾“å‡º
            output_config: è¾“å‡ºé…ç½® (åˆ†è¾¨ç‡ã€æ ¼å¼ç­‰)

        Returns:
            IMS APIè¯·æ±‚ä½“
        """
        timeline = self.convert(vgp_result)

        # é»˜è®¤è¾“å‡ºé…ç½®
        if output_config is None:
            output_config = {
                "MediaURL": "oss://bucket/output.mp4",
                "Width": 1920,
                "Height": 1080,
                "VideoCodec": "H.264",
                "AudioCodec": "AAC"
            }

        request = {
            "Timeline": timeline,
            "OutputMediaConfig": output_config
        }

        return request

    def get_conversion_summary(self, vgp_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        è·å–è½¬æ¢æ‘˜è¦ä¿¡æ¯

        Args:
            vgp_result: VGPè¾“å‡º

        Returns:
            è½¬æ¢æ‘˜è¦
                {
                    "total_clips": 10,
                    "transitions": 9,
                    "filters": 10,
                    "effects": 5,
                    "texts": 3,
                    "overlays": 2,
                    "audio_tracks": 2,  # æ–°å¢
                    "warnings": [...]
                }
        """
        summary = {
            "total_clips": 0,
            "transitions": 0,
            "filters": 0,
            "effects": 0,
            "texts": 0,
            "overlays": 0,
            "audio_tracks": 0,  # âœ… æ–°å¢
            "warnings": []
        }

        # ç»Ÿè®¡clips
        sequence = vgp_result.get("filter_sequence_id") or \
                   vgp_result.get("effects_sequence_id") or \
                   vgp_result.get("transition_sequence_id") or \
                   []
        summary["total_clips"] = len(sequence)

        # ç»Ÿè®¡è½¬åœº
        for clip in sequence:
            if "transition_out" in clip:
                trans_type = clip["transition_out"].get("type")
                if trans_type not in ["cut", "match_cut", "none"]:
                    summary["transitions"] += 1

        # ç»Ÿè®¡æ»¤é•œ
        filter_seq = vgp_result.get("filter_sequence_id", [])
        summary["filters"] = sum(1 for clip in filter_seq if "color_filter" in clip)

        # ç»Ÿè®¡ç‰¹æ•ˆ
        effects_seq = vgp_result.get("effects_sequence_id", [])
        for clip in effects_seq:
            summary["effects"] += len(clip.get("visual_effects", []))

        # ç»Ÿè®¡æ–‡å­—
        text_track = vgp_result.get("text_overlay_track_id", {})
        summary["texts"] = len(text_track.get("clips", []))

        # ç»Ÿè®¡è¾…åŠ©åª’ä½“
        aux_track = vgp_result.get("auxiliary_track_id", {})
        summary["overlays"] = len(aux_track.get("clips", []))

        # âœ… ç»Ÿè®¡éŸ³é¢‘è½¨é“
        bgm_data = vgp_result.get("bgm_composition_id", {})
        if bgm_data and bgm_data.get("clips"):
            summary["audio_tracks"] += 1

        aux_audio_clips = [c for c in aux_track.get("clips", []) if c.get("type") == "audio"]
        if aux_audio_clips:
            summary["audio_tracks"] += 1

        return summary
