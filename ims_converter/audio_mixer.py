"""
éŸ³é¢‘æ··éŸ³ä¼˜åŒ–å·¥å…·

å®ç°æ™ºèƒ½çš„å¤šéŸ³è½¨Gainè°ƒæ•´ç­–ç•¥ï¼Œé¿å…éŸ³é¢‘çˆ†éŸ³å’Œæ··å“é—®é¢˜
"""

from typing import List, Dict, Any
import math
import logging

logger = logging.getLogger(__name__)


class AudioMixerOptimizer:
    """éŸ³é¢‘æ··éŸ³ä¼˜åŒ–å™¨"""

    # éŸ³è½¨ç±»å‹çš„é»˜è®¤éŸ³é‡å‚è€ƒå€¼ (dB)
    DEFAULT_VOLUMES = {
        "tts": -12.0,      # äººå£°ï¼šæœ€å“ï¼ˆæ ¸å¿ƒå†…å®¹ï¼‰
        "narration": -12.0,  # æ—ç™½ï¼šä¸TTSåŒçº§
        "sfx": -16.0,      # éŸ³æ•ˆï¼šç•¥ä½
        "bgm": -12.0,      # BGMï¼šè°ƒé«˜åˆ°-12dBï¼Œè®©BGMæ›´æ˜æ˜¾ï¼ˆåŸæ¥æ˜¯-20dBå¤ªå°äº†ï¼‰
        "ambient": -22.0   # ç¯å¢ƒéŸ³ï¼šæ›´ä½
    }

    # å¤šéŸ³è½¨åŒæ—¶æ’­æ”¾æ—¶çš„è¡°å‡ç³»æ•°
    CONCURRENT_ATTENUATION = {
        2: 0.85,  # 2ä¸ªéŸ³è½¨åŒæ—¶æ’­æ”¾ï¼šè¡°å‡åˆ°85%
        3: 0.70,  # 3ä¸ªéŸ³è½¨åŒæ—¶æ’­æ”¾ï¼šè¡°å‡åˆ°70%
        4: 0.60,  # 4ä¸ªæˆ–æ›´å¤šéŸ³è½¨ï¼šè¡°å‡åˆ°60%
    }

    def __init__(self, target_peak_db: float = -3.0, target_rms_db: float = -16.0):
        """
        åˆå§‹åŒ–éŸ³é¢‘æ··éŸ³ä¼˜åŒ–å™¨

        Args:
            target_peak_db: ç›®æ ‡å³°å€¼ç”µå¹³ï¼ˆé˜²æ­¢å‰Šæ³¢ï¼‰
            target_rms_db: ç›®æ ‡RMSå“åº¦ï¼ˆå¹³å‡å“åº¦ï¼‰
        """
        self.target_peak_db = target_peak_db
        self.target_rms_db = target_rms_db

    def optimize_audio_tracks(
        self,
        audio_tracks: List[Dict[str, Any]],
        total_duration: float
    ) -> List[Dict[str, Any]]:
        """
        ä¼˜åŒ–å¤šä¸ªéŸ³é¢‘è½¨é“çš„éŸ³é‡é…ç½®

        Args:
            audio_tracks: IMS AudioTracksæ•°ç»„
                [
                    {
                        "AudioTrackClips": [
                            {
                                "MediaURL": "...",
                                "TimelineIn": 0.0,
                                "TimelineOut": 10.0,
                                "Effects": [{"Type": "Volume", "Gain": 1.0}]
                            }
                        ]
                    }
                ]
            total_duration: è§†é¢‘æ€»æ—¶é•¿ï¼ˆç”¨äºè®¡ç®—å¹¶å‘åº¦ï¼‰

        Returns:
            ä¼˜åŒ–åçš„audio_tracks
        """
        if not audio_tracks:
            return audio_tracks

        logger.info(f"ğŸšï¸ å¼€å§‹ä¼˜åŒ– {len(audio_tracks)} ä¸ªéŸ³é¢‘è½¨é“...")

        # 1. åˆ†ææ¯ä¸ªæ—¶é—´æ®µçš„å¹¶å‘éŸ³è½¨æ•°
        concurrent_map = self._analyze_concurrency(audio_tracks, total_duration)

        # 2. è¯†åˆ«éŸ³è½¨ç±»å‹å¹¶åˆ†é…åŸºç¡€éŸ³é‡
        for i, track in enumerate(audio_tracks):
            track_type = self._identify_track_type(track, i)
            base_db = self.DEFAULT_VOLUMES.get(track_type, -18.0)

            logger.info(f"   éŸ³è½¨ {i+1}: ç±»å‹={track_type}, åŸºç¡€éŸ³é‡={base_db}dB")

            # 3. ä¸ºæ¯ä¸ªclipè°ƒæ•´Gain
            clips = track.get("AudioTrackClips", [])
            for clip in clips:
                timeline_in = clip.get("TimelineIn", 0.0)
                timeline_out = clip.get("TimelineOut", 10.0)

                # è®¡ç®—è¯¥æ—¶é—´æ®µçš„å¹³å‡å¹¶å‘åº¦
                avg_concurrent = self._get_average_concurrency(
                    concurrent_map,
                    timeline_in,
                    timeline_out
                )

                # åº”ç”¨å¹¶å‘è¡°å‡
                attenuation = self._get_attenuation_factor(avg_concurrent)
                adjusted_db = base_db + self._linear_to_db(attenuation)

                # è½¬æ¢ä¸ºIMS Gainå€¼
                gain = self._db_to_gain(adjusted_db)

                # æ›´æ–°Gainï¼ˆä¿ç•™å·²æœ‰çš„æ›´é«˜éŸ³é‡è®¾ç½®ï¼‰
                if "Effects" not in clip:
                    clip["Effects"] = []

                volume_effect = next(
                    (e for e in clip["Effects"] if e.get("Type") == "Volume"),
                    None
                )

                if volume_effect:
                    # å¦‚æœå·²æœ‰Gainå€¼ä¸”å¤§äºè®¡ç®—å€¼ï¼Œä¿ç•™ç”¨æˆ·è®¾ç½®ï¼ˆå°Šé‡æ‰‹åŠ¨è°ƒæ•´ï¼‰
                    existing_gain = volume_effect.get("Gain", 0.0)
                    if existing_gain > gain:
                        logger.info(
                            f"      Clip [{timeline_in:.1f}s-{timeline_out:.1f}s]: "
                            f"ä¿ç•™å·²æœ‰éŸ³é‡ Gain={existing_gain:.3f} (å¤§äºè®¡ç®—å€¼{gain:.3f})"
                        )
                        gain = existing_gain  # ä¿ç•™åŸå€¼
                    volume_effect["Gain"] = gain
                else:
                    clip["Effects"].append({
                        "Type": "Volume",
                        "Gain": gain
                    })

                logger.info(
                    f"      Clip [{timeline_in:.1f}s-{timeline_out:.1f}s]: "
                    f"å¹¶å‘={avg_concurrent:.1f}, è¡°å‡={attenuation:.2f}, "
                    f"æœ€ç»ˆGain={gain:.3f}"
                )

        logger.info(f"âœ… éŸ³é¢‘æ··éŸ³ä¼˜åŒ–å®Œæˆ")
        return audio_tracks

    def _identify_track_type(self, track: Dict[str, Any], index: int) -> str:
        """
        è¯†åˆ«éŸ³è½¨ç±»å‹

        æ ¹æ®URLã€æ–‡ä»¶åã€è½¨é“ç´¢å¼•ç­‰æ¨æ–­éŸ³è½¨ç±»å‹
        """
        clips = track.get("AudioTrackClips", [])
        if not clips:
            return "bgm"

        # æ£€æŸ¥ç¬¬ä¸€ä¸ªclipçš„URL
        url = clips[0].get("MediaURL", "").lower()

        if "tts" in url or "voice" in url or "speech" in url:
            return "tts"
        elif "bgm" in url or "music" in url or "background" in url:
            return "bgm"
        elif "sfx" in url or "sound" in url or "effect" in url:
            return "sfx"
        elif "ambient" in url or "atmosphere" in url:
            return "ambient"

        # æ ¹æ®è½¨é“é¡ºåºæ¨æ–­ï¼ˆç¬¬ä¸€è½¨é€šå¸¸æ˜¯BGMï¼‰
        if index == 0:
            return "bgm"
        elif index == 1:
            return "sfx"
        else:
            return "ambient"

    def _analyze_concurrency(
        self,
        audio_tracks: List[Dict[str, Any]],
        total_duration: float,
        resolution: float = 0.5
    ) -> Dict[float, int]:
        """
        åˆ†ææ¯ä¸ªæ—¶é—´ç‚¹çš„å¹¶å‘éŸ³è½¨æ•°

        Args:
            audio_tracks: éŸ³é¢‘è½¨é“æ•°ç»„
            total_duration: æ€»æ—¶é•¿
            resolution: æ—¶é—´åˆ†è¾¨ç‡ï¼ˆç§’ï¼‰

        Returns:
            {æ—¶é—´ç‚¹: å¹¶å‘æ•°} çš„æ˜ å°„
        """
        concurrent_map = {}
        num_samples = int(total_duration / resolution) + 1

        for t_idx in range(num_samples):
            time = t_idx * resolution
            concurrent_count = 0

            for track in audio_tracks:
                clips = track.get("AudioTrackClips", [])
                for clip in clips:
                    timeline_in = clip.get("TimelineIn", 0.0)
                    timeline_out = clip.get("TimelineOut", 10.0)

                    if timeline_in <= time < timeline_out:
                        concurrent_count += 1
                        break  # æ¯ä¸ªè½¨é“åªè®¡æ•°ä¸€æ¬¡

            concurrent_map[time] = concurrent_count

        return concurrent_map

    def _get_average_concurrency(
        self,
        concurrent_map: Dict[float, int],
        start_time: float,
        end_time: float
    ) -> float:
        """è®¡ç®—æŸä¸ªæ—¶é—´æ®µçš„å¹³å‡å¹¶å‘åº¦"""
        relevant_times = [
            (t, count) for t, count in concurrent_map.items()
            if start_time <= t < end_time
        ]

        if not relevant_times:
            return 1.0

        total_count = sum(count for _, count in relevant_times)
        return total_count / len(relevant_times)

    def _get_attenuation_factor(self, concurrent_count: float) -> float:
        """æ ¹æ®å¹¶å‘æ•°è·å–è¡°å‡ç³»æ•°"""
        if concurrent_count < 2:
            return 1.0

        concurrent_int = int(concurrent_count)
        if concurrent_int in self.CONCURRENT_ATTENUATION:
            return self.CONCURRENT_ATTENUATION[concurrent_int]
        elif concurrent_int >= 4:
            return self.CONCURRENT_ATTENUATION[4]
        else:
            # çº¿æ€§æ’å€¼
            lower = self.CONCURRENT_ATTENUATION[concurrent_int]
            upper = self.CONCURRENT_ATTENUATION[concurrent_int + 1]
            fraction = concurrent_count - concurrent_int
            return lower + (upper - lower) * fraction

    def _db_to_gain(self, db: float) -> float:
        """å°†dBè½¬æ¢ä¸ºIMS Gainå€¼ï¼ˆ0-2ï¼‰"""
        if db <= -60:
            return 0.0
        gain = math.pow(10, db / 20.0)
        return max(0.0, min(2.0, gain))

    def _linear_to_db(self, linear: float) -> float:
        """çº¿æ€§å€¼è½¬dB"""
        if linear <= 0:
            return -60.0
        return 20.0 * math.log10(linear)


def optimize_ims_audio_tracks(
    timeline: Dict[str, Any],
    total_duration: float = None
) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šä¼˜åŒ–IMS Timelineä¸­çš„éŸ³é¢‘è½¨é“

    Args:
        timeline: IMS Timelineå¯¹è±¡
        total_duration: æ€»æ—¶é•¿ï¼ˆå¦‚æœä¸æä¾›ï¼Œä¼šè‡ªåŠ¨è®¡ç®—ï¼‰

    Returns:
        ä¼˜åŒ–åçš„timeline
    """
    audio_tracks = timeline.get("AudioTracks", [])
    if not audio_tracks:
        return timeline

    # è‡ªåŠ¨è®¡ç®—æ€»æ—¶é•¿
    if total_duration is None:
        max_time = 0.0
        for track in audio_tracks:
            clips = track.get("AudioTrackClips", [])
            for clip in clips:
                max_time = max(max_time, clip.get("TimelineOut", 0.0))
        total_duration = max_time

    # ä¼˜åŒ–éŸ³é¢‘è½¨é“
    optimizer = AudioMixerOptimizer()
    timeline["AudioTracks"] = optimizer.optimize_audio_tracks(
        audio_tracks,
        total_duration
    )

    return timeline
