import librosa
import numpy as np
import requests  # ç”¨äºè°ƒç”¨é€šä¹‰åƒé—® API
import os

# =================== 1. ç‰¹å¾æå–å‡½æ•° ===================
def extract_audio_features(audio_path):
    y, sr = librosa.load(audio_path, duration=30)  # æœ€å¤š30ç§’

    # å¸¸ç”¨å£°å­¦ç‰¹å¾
    pitches, _ = librosa.piptrack(y=y, sr=sr)
    non_zero_pitches = pitches[pitches > 0]
    mean_pitch = np.mean(non_zero_pitches) if len(non_zero_pitches) > 0 else 0

    spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
    mean_spectral_centroid = np.mean(spectral_centroids)  # äº®åº¦ï¼ˆè¶Šé«˜è¶Šâ€œäº®â€ï¼‰

    zcr = librosa.feature.zero_crossing_rate(y)[0]
    mean_zcr = np.mean(zcr)

    rms = librosa.feature.rms(y=y)[0]
    mean_rms = np.mean(rms)  # èƒ½é‡ï¼ˆå“åº¦ï¼‰

    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)

    # è¿”å›å¯è¯»çš„ç‰¹å¾å­—å…¸
    features = {
        "å¹³å‡éŸ³é«˜ (Hz)": float(mean_pitch),
        "é¢‘è°±è´¨å¿ƒ (Hz)": float(mean_spectral_centroid),  # æ„ŸçŸ¥äº®åº¦
        "èŠ‚å¥ (BPM)": float(tempo),
        "èƒ½é‡ (RMS)": float(mean_rms),
        "é›¶äº¤å‰ç‡": float(mean_zcr)
    }
    return features

# =================== 2. è°ƒç”¨ Qwen APIï¼ˆé€šä¹‰åƒé—®ï¼‰===================
def classify_with_qwen(features_desc, api_key=None):
    if api_key is None:
        api_key = os.getenv("DASHSCOPE_API_KEY")  # æ¨èï¼šè®¾ç½®ç¯å¢ƒå˜é‡
        if not api_key:
            raise ValueError("è¯·è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡æˆ–ä¼ å…¥ API Key")

    url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }

    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„éŸ³ä¹æƒ…ç»ªåˆ†æä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹éŸ³é¢‘ç‰¹å¾ï¼Œåˆ¤æ–­è¿™æ®µéŸ³ä¹æœ€å¯èƒ½æ˜¯å“ªç§é£æ ¼ï¼š

    {features_desc}

    è¯·ä»ä»¥ä¸‹ç±»åˆ«ä¸­é€‰æ‹©ä¸€ä¸ªæœ€åˆé€‚çš„ï¼š
    - èˆ’ç¼“æŸ”ç¾ï¼ˆæ…¢èŠ‚å¥ã€ä½èƒ½é‡ã€ä½äº®åº¦ï¼‰
    - é›„å£®æœ‰åŠ›ï¼ˆä¸­é«˜èƒ½é‡ã€ä¸­é«˜é€ŸèŠ‚å¥ï¼‰
    - æ´»æ³¼æ¬¢å¿«ï¼ˆé«˜èŠ‚å¥ã€ä¸­ç­‰èƒ½é‡ã€æ˜äº®ï¼‰
    - åˆºè€³/å°–é”ï¼ˆé«˜é¢‘é›†ä¸­ã€é«˜äº®åº¦ã€é«˜é›¶äº¤å‰ï¼‰
    - å˜ˆæ‚æ··ä¹±ï¼ˆé«˜é›¶äº¤å‰ã€ä½å’Œè°æ€§ï¼‰

    è¯·åªå›ç­”ç±»åˆ«åç§°ï¼Œä¸è¦è§£é‡Šã€‚
    """

    data = {
        "model": "qwen-max",  # æˆ– qwen-plus, qwen-turbo
        "input": {
            "messages": [
                {"role": "user", "content": prompt}
            ]
        },
        "parameters": {
            "temperature": 0.1  # é™ä½éšæœºæ€§ï¼Œæ›´ç¨³å®š
        }
    }

    response = requests.post(url, headers=headers, json=data)
    result = response.json()
    if "output" in result and "text" in result["output"]:
        return result["output"]["text"].strip()
    else:
        raise Exception(f"API Error: {result}")

# =================== 3. ä¸»å‡½æ•° ===================
def classify_music_with_qwen(audio_path, api_key=None):
    print(f"æ­£åœ¨åˆ†æéŸ³é¢‘ï¼š{audio_path}")
    
    # æå–ç‰¹å¾
    features = extract_audio_features(audio_path)
    
    # è½¬ä¸ºè‡ªç„¶è¯­è¨€æè¿°
    desc = (
        f"å¹³å‡éŸ³é«˜: {features['å¹³å‡éŸ³é«˜ (Hz)']:.1f} Hz\n"
        f"é¢‘è°±è´¨å¿ƒï¼ˆäº®åº¦ï¼‰: {features['é¢‘è°±è´¨å¿ƒ (Hz)']:.1f} Hz\n"
        f"èŠ‚å¥ï¼ˆBPMï¼‰: {features['èŠ‚å¥ (BPM)']:.1f}\n"
        f"èƒ½é‡ï¼ˆRMSï¼‰: {features['èƒ½é‡ (RMS)']:.3f}\n"
        f"é›¶äº¤å‰ç‡: {features['é›¶äº¤å‰ç‡']:.3f}"
    )
    print("æå–ç‰¹å¾ï¼š\n" + desc)

    # è°ƒç”¨ Qwen åˆ¤æ–­
    try:
        result = classify_with_qwen(desc, api_key)
        print(f"\nğŸµ éŸ³ä¹é£æ ¼åˆ¤æ–­ï¼š{result}")
        return result
    except Exception as e:
        print(f"è°ƒç”¨ Qwen å¤±è´¥ï¼š{e}")
        return None

# =================== ä½¿ç”¨ç¤ºä¾‹ ===================
if __name__ == "__main__":
    # è¯·å…ˆè·å– DashScope API Keyï¼šhttps://dashscope.console.aliyun.com/
    # å¹¶è®¾ç½®ç¯å¢ƒå˜é‡ï¼šexport DASHSCOPE_API_KEY="your-api-key-here"
    
    classify_music_with_qwen("sample.mp3")