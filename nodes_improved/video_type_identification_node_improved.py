#!/usr/bin/env python3
"""
Improved Video Type Identification Node

Enhanced version with better AI integration, caching, and error handling.
"""

import sys
from pathlib import Path
import asyncio
import json
from typing import Dict, Any, List

# Add project root for imports
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from nodes_improved.base_node_improved import BaseNodeImproved, call_ai_service, NodeExecutionError
from config import settings

# Supported video types with detailed descriptions
VIDEO_TYPES_DATABASE = {
    "äº§å“å®£ä¼ ç‰‡": {
        "description": "å±•ç¤ºäº§å“ç‰¹æ€§å’Œä¼˜åŠ¿çš„å•†ä¸šå®£ä¼ è§†é¢‘",
        "typical_duration": [30, 60, 90],
        "key_elements": ["äº§å“å±•ç¤º", "åŠŸèƒ½ä»‹ç»", "ç”¨æˆ·åœºæ™¯"],
        "structure_template": "intro_problem_solution_cta"
    },
    "å“ç‰Œå½¢è±¡ç‰‡": {
        "description": "å±•ç¤ºä¼ä¸šæ–‡åŒ–å’Œå“ç‰Œä»·å€¼çš„å½¢è±¡å®£ä¼ ",
        "typical_duration": [60, 120, 180],
        "key_elements": ["ä¼ä¸šç†å¿µ", "å›¢é˜Ÿé£è²Œ", "å‘å±•å†ç¨‹"],
        "structure_template": "story_driven_brand"
    },
    "æ•™å­¦è§†é¢‘": {
        "description": "çŸ¥è¯†ä¼ æˆå’ŒæŠ€èƒ½æ•™å­¦ç±»è§†é¢‘",
        "typical_duration": [300, 600, 1200],
        "key_elements": ["çŸ¥è¯†ç‚¹", "æ­¥éª¤æ¼”ç¤º", "ç»ƒä¹ æ¡ˆä¾‹"],
        "structure_template": "intro_teach_practice_summary"
    },
    "VLOG": {
        "description": "ä¸ªäººç”Ÿæ´»è®°å½•å’Œåˆ†äº«ç±»è§†é¢‘",
        "typical_duration": [180, 300, 600],
        "key_elements": ["ä¸ªäººè§†è§’", "æ—¥å¸¸è®°å½•", "æƒ…æ„Ÿè¡¨è¾¾"],
        "structure_template": "chronological_narrative"
    },
    "çŸ­è§†é¢‘æ•…äº‹": {
        "description": "ç®€çŸ­çš„æ•…äº‹æ€§å†…å®¹ï¼Œé€‚åˆç¤¾äº¤åª’ä½“",
        "typical_duration": [15, 30, 60],
        "key_elements": ["å†²çªè®¾ç½®", "è½¬æŠ˜ç‚¹", "æƒ…æ„Ÿå…±é¸£"],
        "structure_template": "hook_build_payoff"
    },
    "æ–°é—»æ’­æŠ¥": {
        "description": "æ–°é—»äº‹ä»¶æŠ¥é“å’Œä¿¡æ¯ä¼ é€’",
        "typical_duration": [60, 120, 300],
        "key_elements": ["äº‹å®é™ˆè¿°", "èƒŒæ™¯ä»‹ç»", "ä¸“å®¶è§‚ç‚¹"],
        "structure_template": "lead_body_conclusion"
    },
    "è®¿è°ˆèŠ‚ç›®": {
        "description": "å¯¹è¯å½¢å¼çš„æ·±åº¦äº¤æµèŠ‚ç›®",
        "typical_duration": [600, 1800, 3600],
        "key_elements": ["ä¸»æŒå¼•å¯¼", "å˜‰å®¾è§‚ç‚¹", "äº’åŠ¨äº¤æµ"],
        "structure_template": "intro_questions_insights"
    }
}


class VideoTypeIdentificationNodeImproved(BaseNodeImproved):
    """
    Improved Video Type Identification Node
    
    Features:
    - Enhanced AI prompt engineering
    - Confidence scoring
    - Caching for similar requests
    - Multiple structure templates
    - Detailed reasoning output
    """
    
    node_name = "VideoTypeIdentificationNode"
    node_description = "æ™ºèƒ½è¯†åˆ«è§†é¢‘ç±»å‹å¹¶ç”Ÿæˆç»“æ„æ¨¡æ¿"
    node_version = "2.0.0"
    
    required_inputs = [
        {
            "name": "theme_id",
            "label": "è§†é¢‘ä¸»é¢˜",
            "type": str,
            "required": True,
            "description": "è§†é¢‘çš„ä¸»è¦è¯é¢˜æˆ–èƒŒæ™¯"
        },
        {
            "name": "keywords_id", 
            "label": "å…³é”®è¯",
            "type": list,
            "required": True,
            "description": "ä¸è§†é¢‘å†…å®¹ç›¸å…³çš„å…³é”®è¯åˆ—è¡¨"
        },
        {
            "name": "target_duration_id",
            "label": "ç›®æ ‡æ—¶é•¿",
            "type": int,
            "required": True,
            "description": "è§†é¢‘çš„ç›®æ ‡é•¿åº¦ï¼ˆç§’ï¼‰"
        },
        {
            "name": "user_description_id",
            "label": "ç”¨æˆ·æè¿°",
            "type": str,
            "required": True,
            "description": "ç”¨æˆ·å¯¹è§†é¢‘çš„è¯¦ç»†æè¿°"
        }
    ]
    
    output_schema = [
        {
            "name": "video_type_id",
            "type": str,
            "description": "è¯†åˆ«çš„è§†é¢‘ç±»å‹"
        },
        {
            "name": "structure_template_id",
            "type": str,
            "description": "æ¨èçš„è§†é¢‘ç»“æ„æ¨¡æ¿"
        },
        {
            "name": "confidence_score",
            "type": float,
            "description": "è¯†åˆ«ç½®ä¿¡åº¦ (0-1)"
        },
        {
            "name": "reasoning",
            "type": str,
            "description": "è¯†åˆ«ç†ç”±å’Œå»ºè®®"
        },
        {
            "name": "alternative_types",
            "type": list,
            "description": "å…¶ä»–å¯èƒ½çš„è§†é¢‘ç±»å‹"
        }
    ]
    
    def __init__(self, node_id: str):
        super().__init__(node_id)
        self._cache = {}  # Simple in-memory cache
    
    def _generate_cache_key(self, context: Dict[str, Any]) -> str:
        """Generate cache key for similar requests"""
        key_data = {
            "theme": context["theme_id"],
            "keywords": sorted(context["keywords_id"]),
            "duration_range": self._get_duration_range(context["target_duration_id"])
        }
        return str(hash(json.dumps(key_data, sort_keys=True)))
    
    def _get_duration_range(self, duration: int) -> str:
        """Categorize duration into ranges"""
        if duration <= 60:
            return "short"
        elif duration <= 300:
            return "medium"
        elif duration <= 900:
            return "long"
        else:
            return "extended"
    
    def _build_ai_prompt(self, context: Dict[str, Any]) -> str:
        """Build comprehensive AI prompt for video type identification"""
        
        # Build context information
        theme = context["theme_id"]
        keywords = ", ".join(context["keywords_id"])
        duration = context["target_duration_id"]
        description = context["user_description_id"]
        
        # Build video types information
        types_info = []
        for video_type, info in VIDEO_TYPES_DATABASE.items():
            types_info.append(f"- {video_type}: {info['description']}")
        
        prompt = f"""
# è§†é¢‘ç±»å‹è¯†åˆ«ä»»åŠ¡

ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æå¸ˆï¼Œéœ€è¦æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯è¯†åˆ«æœ€é€‚åˆçš„è§†é¢‘ç±»å‹ã€‚

## ç”¨æˆ·è¾“å…¥ä¿¡æ¯ï¼š
- ä¸»é¢˜ï¼š{theme}
- å…³é”®è¯ï¼š{keywords}
- ç›®æ ‡æ—¶é•¿ï¼š{duration}ç§’
- è¯¦ç»†æè¿°ï¼š{description}

## å¯é€‰è§†é¢‘ç±»å‹ï¼š
{chr(10).join(types_info)}

## åˆ†æè¦æ±‚ï¼š
1. åˆ†æç”¨æˆ·éœ€æ±‚çš„æ ¸å¿ƒç‰¹å¾
2. è€ƒè™‘æ—¶é•¿ä¸å†…å®¹ç±»å‹çš„åŒ¹é…åº¦
3. è¯„ä¼°å…³é”®è¯ä¸å„ç±»å‹çš„ç›¸å…³æ€§
4. ç»™å‡ºä¸»è¦æ¨èç±»å‹å’Œç½®ä¿¡åº¦
5. æä¾›2-3ä¸ªå¤‡é€‰ç±»å‹

## è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
    "primary_type": "ä¸»è¦æ¨èçš„è§†é¢‘ç±»å‹",
    "confidence": 0.95,
    "reasoning": "è¯¦ç»†çš„åˆ†æç†ç”±ï¼ŒåŒ…æ‹¬ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªç±»å‹ï¼Œè€ƒè™‘äº†å“ªäº›å› ç´ ",
    "structure_template": "æ¨èçš„ç»“æ„æ¨¡æ¿ID",
    "alternative_types": [
        {{
            "type": "å¤‡é€‰ç±»å‹1",
            "confidence": 0.75,
            "reason": "é€‰æ‹©ç†ç”±"
        }},
        {{
            "type": "å¤‡é€‰ç±»å‹2", 
            "confidence": 0.65,
            "reason": "é€‰æ‹©ç†ç”±"
        }}
    ],
    "duration_analysis": "æ—¶é•¿ä¸ç±»å‹åŒ¹é…åº¦åˆ†æ",
    "suggestions": "é’ˆå¯¹ç”¨æˆ·éœ€æ±‚çš„å…·ä½“å»ºè®®"
}}

è¯·è¿›è¡Œä¸“ä¸šåˆ†æå¹¶è¾“å‡ºç»“æœï¼š
"""
        
        return prompt
    
    async def generate_async(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Async implementation of video type identification
        """
        
        # Check cache first
        cache_key = self._generate_cache_key(context)
        if cache_key in self._cache:
            self.logger.info("ğŸ“‹ Using cached result")
            return self._cache[cache_key]
        
        # Build AI prompt
        prompt = self._build_ai_prompt(context)
        
        # Call AI service
        ai_response = await call_ai_service(
            prompt,
            parse_json=True,
            json_schema={
                "type": "object",
                "properties": {
                    "primary_type": {"type": "string"},
                    "confidence": {"type": "number"},
                    "reasoning": {"type": "string"},
                    "structure_template": {"type": "string"},
                    "alternative_types": {"type": "array"}
                }
            }
        )
        
        if not ai_response["success"]:
            # Fallback to rule-based analysis
            self.logger.warning("ğŸ¤– AI service failed, using rule-based fallback")
            return self._rule_based_analysis(context)
        
        # Parse AI response
        try:
            ai_result = ai_response["result"]
            
            # Validate the result
            primary_type = ai_result.get("primary_type", "äº§å“å®£ä¼ ç‰‡")
            if primary_type not in VIDEO_TYPES_DATABASE:
                primary_type = self._find_closest_type(primary_type)
            
            # Build result
            result = {
                "video_type_id": primary_type,
                "structure_template_id": VIDEO_TYPES_DATABASE[primary_type]["structure_template"],
                "confidence_score": min(ai_result.get("confidence", 0.8), 1.0),
                "reasoning": ai_result.get("reasoning", "AIåˆ†æå¾—å‡ºçš„ç»“æœ"),
                "alternative_types": ai_result.get("alternative_types", []),
                "duration_analysis": ai_result.get("duration_analysis", ""),
                "suggestions": ai_result.get("suggestions", ""),
                "type_details": VIDEO_TYPES_DATABASE[primary_type]
            }
            
            # Cache the result
            self._cache[cache_key] = result
            
            return result
            
        except Exception as e:
            self.logger.error(f"Failed to parse AI response: {e}")
            return self._rule_based_analysis(context)
    
    def _rule_based_analysis(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Fallback rule-based analysis when AI service fails
        """
        theme = context["theme_id"].lower()
        keywords = [k.lower() for k in context["keywords_id"]]
        duration = context["target_duration_id"]
        description = context["user_description_id"].lower()
        
        # Simple keyword matching
        type_scores = {}
        
        for video_type, info in VIDEO_TYPES_DATABASE.items():
            score = 0
            
            # Check theme matching
            if any(word in theme for word in ["äº§å“", "å®£ä¼ ", "æ¨å¹¿"]):
                if video_type == "äº§å“å®£ä¼ ç‰‡":
                    score += 0.4
            
            if any(word in theme for word in ["æ•™å­¦", "æ•™è‚²", "åŸ¹è®­"]):
                if video_type == "æ•™å­¦è§†é¢‘":
                    score += 0.4
            
            if any(word in theme for word in ["vlog", "ç”Ÿæ´»", "æ—¥å¸¸"]):
                if video_type == "VLOG":
                    score += 0.4
            
            # Check duration matching
            typical_durations = info["typical_duration"]
            duration_score = 1.0 - min(abs(duration - d) / d for d in typical_durations)
            score += duration_score * 0.3
            
            # Check keyword matching
            for keyword in keywords:
                if keyword in " ".join(info["key_elements"]).lower():
                    score += 0.1
            
            type_scores[video_type] = score
        
        # Find best match
        best_type = max(type_scores, key=type_scores.get)
        best_score = type_scores[best_type]
        
        # Build alternative types
        sorted_types = sorted(type_scores.items(), key=lambda x: x[1], reverse=True)
        alternatives = [
            {
                "type": t,
                "confidence": round(s, 2),
                "reason": f"Rule-based matching score: {s:.2f}"
            }
            for t, s in sorted_types[1:4]  # Top 3 alternatives
        ]
        
        return {
            "video_type_id": best_type,
            "structure_template_id": VIDEO_TYPES_DATABASE[best_type]["structure_template"],
            "confidence_score": round(best_score, 2),
            "reasoning": f"åŸºäºè§„åˆ™åˆ†æï¼šä¸»é¢˜åŒ¹é…ã€æ—¶é•¿é€‚é…ã€å…³é”®è¯ç›¸å…³æ€§ç»¼åˆè¯„åˆ†",
            "alternative_types": alternatives,
            "type_details": VIDEO_TYPES_DATABASE[best_type],
            "fallback_method": True
        }
    
    def _find_closest_type(self, unknown_type: str) -> str:
        """Find closest known video type"""
        # Simple string matching fallback
        for known_type in VIDEO_TYPES_DATABASE:
            if unknown_type.lower() in known_type.lower() or known_type.lower() in unknown_type.lower():
                return known_type
        
        # Default fallback
        return "äº§å“å®£ä¼ ç‰‡"


# Factory function
def create_video_type_identification_node(node_id: str) -> VideoTypeIdentificationNodeImproved:
    """Create video type identification node"""
    return VideoTypeIdentificationNodeImproved(node_id)


if __name__ == "__main__":
    # Test the node
    print("ğŸ§ª Testing VideoTypeIdentificationNode...")
    
    node = create_video_type_identification_node("video_type_001")
    
    test_context = {
        "theme_id": "AIäº§å“ä»‹ç»",
        "keywords_id": ["äººå·¥æ™ºèƒ½", "åˆ›æ–°", "æŠ€æœ¯"],
        "target_duration_id": 60,
        "user_description_id": "æƒ³è¦åˆ¶ä½œä¸€ä¸ª60ç§’çš„AIäº§å“å®£ä¼ è§†é¢‘ï¼Œå±•ç¤ºæˆ‘ä»¬çš„æŠ€æœ¯ä¼˜åŠ¿"
    }
    
    result = node.execute(test_context)
    print(f"âœ… Result: {result}")
    print(f"ğŸ“Š Node info: {node.get_node_info()}")