# nodes/aux_text_insertion_node.py

from video_generate_protocol import BaseNode
from typing import Dict, List, Any,Optional
import re
import random
from datetime import datetime
import asyncio

from materials_supplies import match_font,FontRequest,FontResponse
from llm import QwenLLM  # å‡è®¾è¿™æ˜¯ä½ å°è£…å¥½çš„ Qwen è°ƒç”¨æ¨¡å—

# æ–‡å­—æ¨¡æ¿åº“ï¼ˆå¯æ‰©å±•ä¸ºæ•°æ®åº“æˆ–JSONé…ç½®ï¼‰
TEXT_TEMPLATES = [
    {
        "id": "fact_001",
        "keywords": "æ•°æ®|ç»Ÿè®¡|å¢é•¿|ç™¾åˆ†æ¯”|åˆ†æ",
        "type": "fact_label",
        "category": "data",
        "text": "{value}% çš„ç”¨æˆ·è¡¨ç¤ºæ»¡æ„",
        "style": "bold_badge",
        "position": "top-center",
        "duration": 3.0,
        "fade_in": 0.3,
        "fade_out": 0.3,
        "color": "#FFD700",
        "font_size": 24,
        "relevance": 0.9
    },
    {
        "id": "quote_002",
        "keywords": "æ€æƒ³|å“²å­¦|äººç”Ÿ|æ„ä¹‰|åæ€",
        "type": "quote",
        "category": "philosophy",
        "text": "â€œæˆ‘ä»¬çœ‹åˆ°çš„ä¸ä»…æ˜¯å…‰ï¼Œæ›´æ˜¯æ—¶é—´çš„å›å“ã€‚â€",
        "style": "elegant_center",
        "position": "center",
        "duration": 5.0,
        "fade_in": 0.8,
        "fade_out": 0.8,
        "color": "#FFFFFF",
        "font": "Georgia",
        "relevance": 0.85
    },
    {
        "id": "location_003",
        "keywords": "åœ°ç‚¹|åŸå¸‚|å›½å®¶|ä½ç½®|åœ°å›¾",
        "type": "location_tag",
        "category": "info",
        "text": "ğŸ“ {location}",
        "style": "minimalist",
        "position": "bottom-left",
        "duration": 4.0,
        "color": "#A0A0A0",
        "font_size": 18,
        "relevance": 0.9
    },
    {
        "id": "year_004",
        "keywords": "å¹´ä»½|æ—¶é—´|å†å²|è¿‡å»|1990|2020",
        "type": "time_tag",
        "category": "info",
        "text": "ğŸ“… {year}",
        "style": "retro",
        "position": "top-left",
        "duration": 3.5,
        "color": "#C0C0C0",
        "relevance": 0.88
    },
    {
        "id": "mood_005",
        "keywords": "å¤œæ™š|å­¤ç‹¬|å¯‚é™|æ£®æ—|ç¥ç§˜",
        "type": "atmosphere_text",
        "category": "mood",
        "text": "å¯‚é™ä¸­ï¼Œè—ç€æœªè¯´çš„ç§˜å¯†â€¦",
        "style": "fade_in_out",
        "position": "center-bottom",
        "duration": 6.0,
        "fade_in": 1.0,
        "fade_out": 1.0,
        "color": "#8888FF",
        "italic": True,
        "relevance": 0.8
    },
    {
        "id": "title_006",
        "keywords": "ç« èŠ‚|ç¬¬ä¸€éƒ¨åˆ†|å¼•è¨€|åºå¹•",
        "type": "chapter_title",
        "category": "navigation",
        "text": "ç¬¬ä¸€ç« ï¼šèµ·æº",
        "style": "cinematic_intro",
        "position": "center",
        "duration": 4.0,
        "color": "#FFFFFF",
        "font_size": 36,
        "bold": True,
        "relevance": 0.92
    }
]

# è§†é¢‘ç±»å‹åå¥½
GENRE_TO_TEXT_HINT = {
    "documentary": ["fact_label", "location_tag", "time_tag", "quote"],
    "educational": ["fact_label", "chapter_title", "data"],
    "vlog": ["location_tag", "mood", "atmosphere_text"],
    "storytelling": ["quote", "mood", "chapter_title"],
    "tech_review": ["fact_label", "data"]
}

# åŠ¨æ€å˜é‡æ˜ å°„ï¼ˆä»ä¸Šä¸‹æ–‡æå–ï¼‰
DYNAMIC_VARS = {
    "location": ["å·´é»", "ä¸œäº¬", "çº½çº¦", "ä¸Šæµ·", "å¼€ç½—"],
    "year": ["1920", "1969", "1995", "2020", "2049"],
    "value": ["78", "92", "65", "88", "100"]
}


class AuxTextInsertionNode(BaseNode):
    required_inputs = [
        {
            "name": "shot_blocks_id",
            "label": "åˆ†é•œæè¿°",
            "type": List[Dict],
            "required": True,
            "desc": "åŒ…å«é•œå¤´ç±»å‹ã€è§†è§‰æè¿°ã€èŠ‚å¥ç­‰ä¿¡æ¯çš„åˆ†é•œåˆ—è¡¨",
            "field_type": "json"
        }
    ]

    output_schema=[
        {
            "name": "text_overlay_track_id",
            "label": "é¢å¤–æ–‡å­—è½¨é“",
            "type": str,
            "desc": "é¢å¤–æ–‡å­—è½¨é“ï¼Œå¦‚åœºæ™¯æè¿°ã€æç¤ºè¯­ç­‰"
        },
       
    ]

    system_parameters = {
        "max_texts_per_scene": 1,
        "min_caption_length": 3,
        "enable_qwen_decision": True,
        "default_font_style": {"color": "#FFFFFF", "stroke": "#000000", "size": 28, "bold": True}
    }

    def __init__(self, node_id: str, name: str = "é¢å¤–æ’å…¥çš„è¯´æ˜æˆ–è£…é¥°æ–‡å­—"):
        super().__init__(node_id=node_id, node_type="aux_text_insertion", name=name)
        self.qwen = QwenLLM()

    # async def generate(self, context: Dict[str, Any]) -> Dict[str, Any]:
    #     """
    #     åŒæ­¥å…¥å£ï¼Œå†…éƒ¨è¿è¡Œå¼‚æ­¥é€»è¾‘
    #     """
    #     try:
    #         # å°è¯•è·å–å½“å‰äº‹ä»¶å¾ªç¯
    #         loop = asyncio.get_running_loop()
    #     except RuntimeError:
    #         # å¦‚æœæ²¡æœ‰è¿è¡Œä¸­çš„å¾ªç¯ï¼Œåˆ™æ–°å»ºä¸€ä¸ª
    #         loop = asyncio.new_event_loop()
    #         asyncio.set_event_loop(loop)

    #     return loop.run_until_complete(self.generate_async(context))
    async def generate(self, context: Dict[str, Any]) -> Dict[str, Any]:
        self.validate_context(context)
        shot_blocks: List[Dict] = context["shot_blocks_id"]

        text_track = {
            "track_name": "text_overlay",
            "track_type": "text",
            "clips": []
        }

        cumulative_time = 0.0

        # ç¬¬ä¸€æ­¥ï¼šå†³å®šå“ªäº›åˆ†é•œéœ€è¦æ·»åŠ è¡¥å……æ€§è¯´æ˜æ–‡å­—
        selected_shots_for_text = await self._select_relevant_shots(shot_blocks)


        for block in shot_blocks:
            if block not in selected_shots_for_text:
                cumulative_time += block["duration"]
                continue

            duration = block["duration"]
            visual_desc = block["visual_description"]
            raw_caption = block.get("caption", "").strip()
            shot_type = block["shot_type"]
            pacing = block["pacing"]

            # ä½¿ç”¨ Qwen å†³ç­–ï¼šæ˜¯å¦æ˜¾ç¤ºï¼Ÿä½ç½®ï¼Ÿæ ·å¼ï¼Ÿ
            # å‡è®¾ shot_block ä¸­å¯é€‰åŒ…å« 'frame_image' å­—æ®µ
            frame_image = block.get("frame_image")  # å¯èƒ½ä¸º None

            decision = await self._decide_text_insertion(
                caption=raw_caption,
                visual_desc=visual_desc,
                shot_type=shot_type,
                pacing=pacing,
                frame_image_url=frame_image  # ä¼ å…¥å›¾åƒï¼ˆå¯ä¸º Noneï¼‰
            )

            if not decision or not decision.get("should_display", False):
                cumulative_time += duration
                continue

            # è·å–å­—ä½“
            font_url = await self._get_font_url(visual_desc)

            # æ„å»ºå­—å¹•ç‰‡æ®µ
            clip = {
                "text": decision["text"],
                "start": cumulative_time,
                "duration": duration,
                "position": decision["position"],
                "font": font_url,
                "style": decision["style"]  # åŒ…å« color, size, bold ç­‰
            }

            text_track["clips"].append(clip)
            cumulative_time += duration

        return {"text_overlay_track_id": text_track}

    async def _select_shots_for_text(self, shot_blocks: List[Dict]) -> List[Dict]:
        """ä½¿ç”¨Qwenå†³ç­–é€‰æ‹©å“ªäº›åˆ†é•œéœ€è¦æ·»åŠ è¡¥å……æ€§è¯´æ˜æ–‡å­—"""
        prompt = """
        æ ¹æ®æä¾›çš„åˆ†é•œåˆ—è¡¨ï¼Œé€‰å‡ºæœ€é€‚åˆæ·»åŠ è¡¥å……æ€§è¯´æ˜æ–‡å­—çš„åˆ†é•œã€‚è¯·è€ƒè™‘ç”»é¢çš„æƒ…æ„Ÿè¡¨è¾¾å’Œæ°›å›´è¥é€ ç­‰å› ç´ ã€‚

        åˆ†é•œåˆ—è¡¨ï¼š
        {shots}

        è¾“å‡º JSONï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
        {{
            "selected_shots": [{{shot_indices}}]
        }}
        """.format(shots="\n".join([f"{i}. {shot}" for i, shot in enumerate(shot_blocks)]))

        json_schema = {
            "type": "object",
            "properties": {
                "selected_shots": {
                    "type": "array",
                    "items": {"type": "integer"}
                }
            },
            "required": ["selected_shots"]
        }

        response = self.qwen.generate(prompt=prompt, parse_json=True)
        selected_indices = response.get("selected_shots", [])
        return [shot_blocks[i] for i in selected_indices]

    async def _decide_text_insertion(
        self,
        caption: str,
        visual_desc: str,
        shot_type: str,
        pacing: str,
        frame_image_url: Optional[str] = None
    ) -> Optional[Dict[str, Any]]:
        """
        å†³å®šè¾…åŠ©æ–‡å­—å†…å®¹ã€ä½ç½®ã€æ ·å¼
        ä¼˜å…ˆä½¿ç”¨ Qwen-VLï¼ˆè‹¥æœ‰å›¾åƒï¼‰ï¼Œå¦åˆ™é™çº§ä¸ºçº¯æ–‡æœ¬åˆ†æ
        ä¸¤ä¸ªé˜¶æ®µéƒ½èƒ½ç‹¬ç«‹ç”Ÿæˆå®Œæ•´å­—æ®µ
        """
        # === å…±ç”¨ JSON Schema ===
        schema = self._get_decision_schema()

        # === é˜¶æ®µ1ï¼šå¦‚æœæœ‰å›¾åƒï¼Œä½¿ç”¨ Qwen-VL è¿›è¡Œå›¾æ–‡ç†è§£ ===
        if frame_image_url:
            vl_prompt = f"""
            ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘è§†è§‰è®¾è®¡å¸ˆã€‚è¯·æ ¹æ®æä¾›çš„ç”»é¢æˆªå›¾å’Œæè¿°ï¼Œå†³å®šæ˜¯å¦æ·»åŠ ä¸€æ¡è¾…åŠ©æ€§æ–‡å­—ï¼Œå¹¶å®Œæ•´è®¾è®¡å…¶å†…å®¹ã€ä½ç½®å’Œæ ·å¼ã€‚

            ã€ä»»åŠ¡ã€‘
            è®¾è®¡ä¸€æ¡ç®€çŸ­çš„æƒ…ç»ª/æ°›å›´è¯ï¼ˆå¦‚â€œå¤ªå¥½åƒäº†ï¼â€ã€â€œè§å±±è§æ€§â€ã€â€œè¿™ä¸€åˆ»â€ï¼‰ï¼Œç”¨äºå¢å¼ºæ„ŸæŸ“åŠ›ã€‚

            ã€ç”»é¢ä¿¡æ¯ã€‘
            - é•œå¤´ç±»å‹ï¼š{shot_type}
            - èŠ‚å¥ï¼š{pacing}
            - è§†è§‰æè¿°ï¼š{visual_desc}
            - åŸå§‹å­—å¹•ï¼ˆå‚è€ƒï¼‰ï¼š{caption}

            ã€è¦æ±‚ã€‘
            1. æ–‡å­—å¿…é¡»ç®€çŸ­ï¼ˆ2-6å­—ä¸ºä½³ï¼‰ï¼Œæœ‰æ„ŸæŸ“åŠ›ï¼Œé¿å…ä¸å­—å¹•é‡å¤
            2. ä½ç½®å¿…é¡»é¿å¼€äººè„¸ã€ä¸»ä½“ã€å·²æœ‰æ–‡å­—åŒºåŸŸï¼ˆè¯·ç»“åˆå›¾åƒåˆ¤æ–­æ„å›¾ï¼‰
            3. é£æ ¼åŒ¹é…ç”»é¢æ°›å›´ï¼ˆå¦‚æ¸©é¦¨â†’æ‰‹å†™ä½“æ„Ÿï¼Œéœ‡æ’¼â†’å¤§å­—ç²—ä½“ï¼‰
            4. è‹¥ç”»é¢è¿‡äºå¤æ‚æˆ–æ— å®‰å…¨åŒºåŸŸï¼Œå¯è¿”å› should_display: false

            è¾“å‡º JSONï¼ˆå¿…é¡»åŒ…å«æ‰€æœ‰å­—æ®µï¼‰ï¼š
            {{"should_display": true, "text": "æ–‡å­—", "position": "top-center", "style": {{"color": "#FFFFFF", "stroke": "#000000", "size": 36, "bold": true}}}}
            """

            try:
                response = self.qwen.generate(
                    prompt=vl_prompt,
                    images=[frame_image_url],
                    parse_json=True,
                )
                if response:
                    print(f"[âœ… Qwen-VL æˆåŠŸ] ç”Ÿæˆæ–‡å­—: '{response['text']}' @ {response['position']}")
                    return response
            except Exception as e:
                print(f"[âš ï¸ Qwen-VL å¤±è´¥] {e} â†’ é™çº§åˆ°çº¯æ–‡æœ¬åˆ†æ...")

        # === é˜¶æ®µ2ï¼šæ— å›¾åƒ æˆ– VL å¤±è´¥ â†’ ä½¿ç”¨çº¯æ–‡æœ¬åˆ†æï¼ˆå¿…é¡»èƒ½ç‹¬ç«‹ç”Ÿæˆå®Œæ•´å†³ç­–ï¼‰===
        text_prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªè§†é¢‘æ–‡æ¡ˆè®¾è®¡å¸ˆã€‚å½“å‰æ— æ³•è·å–ç”»é¢æˆªå›¾ï¼Œéœ€ä»…æ ¹æ®æ–‡å­—æè¿°ï¼Œå†³å®šæ˜¯å¦æ·»åŠ è¾…åŠ©æ€§æ–‡å­—ï¼Œå¹¶è®¾è®¡å…¶å†…å®¹ã€ä½ç½®å’Œæ ·å¼ã€‚

        ã€ç”»é¢æè¿°ã€‘
        {visual_desc}

        - é•œå¤´ç±»å‹ï¼š{shot_type}
        - èŠ‚å¥ï¼š{pacing}
        - åŸå§‹å­—å¹•ï¼š{caption}

        ã€ä»»åŠ¡ã€‘
        è¯·è®¾è®¡ä¸€æ¡ç®€çŸ­çš„æƒ…ç»ª/æ°›å›´è¯ï¼ˆå¦‚â€œå¤ªéœ‡æ’¼äº†â€ã€â€œé™è°§æ—¶å…‰â€ã€â€œçªç ´è‡ªæˆ‘â€ï¼‰ï¼Œå¢å¼ºç”»é¢æ„ŸæŸ“åŠ›ã€‚

        ã€è¦æ±‚ã€‘
        1. æ–‡å­— 2-6 å­—ï¼Œæœ‰æ„ŸæŸ“åŠ›ï¼Œé¿å…ä¸å­—å¹•é‡å¤
        2. æ¨æµ‹æ„å›¾å¹¶é€‰æ‹©å®‰å…¨ä½ç½®ï¼ˆå¦‚ï¼šäººç‰©å±…å·¦ â†’ æ–‡å­—æ”¾å³ï¼›é¡¶éƒ¨å¼€é˜” â†’ æ”¾ top-centerï¼‰
        3. é£æ ¼åŒ¹é…æ°›å›´ï¼ˆé¢œè‰²ã€ç²—ç»†ç­‰ï¼‰
        4. è‹¥æè¿°æ¨¡ç³Šæˆ–ä¿¡æ¯å¯†é›†ï¼Œå¯è¿”å› should_display: false

        æ¨èä½ç½®é€‰é¡¹ï¼š
        top-left, top-center, top-right, center, center-bottom, bottom-left, bottom-center, bottom-right

        è¾“å‡º JSONï¼ˆå¿…é¡»å®Œæ•´ï¼Œæ ¼å¼å¦‚ä¸‹ï¼‰ï¼š
        {{"should_display": true, "text": "æ–‡å­—", "position": "top-center", "style": {{"color": "#FFFFFF", "stroke": "#000000", "size": 36, "bold": true}}}}
        """

        try:
            response = self.qwen.generate(
                prompt=text_prompt,
                parse_json=True,
            )
            if response:
                print(f"[âœ… æ–‡æœ¬åˆ†ææˆåŠŸ] ç”Ÿæˆæ–‡å­—: '{response['text']}' @ {response['position']}")
                return response
        except Exception as e:
            print(f"[âŒ æ–‡æœ¬åˆ†æå¤±è´¥] {e}")

        return None
    async def _get_font_url(self, visual_desc: str) -> str:
        """è°ƒç”¨å¤–éƒ¨æœåŠ¡è·å–å­—ä½“ URL"""
        try:
            request = FontRequest(description=visual_desc)
            fonts: List[FontResponse] = await match_font(request)
            return fonts[0].url if fonts else "https://fonts.example.com/default.ttf"
        except Exception as e:
            print(f"[Font Error] {e}")
            return "https://fonts.example.com/default.ttf"
        
    
    async def regenerate(self, context: Dict[str, Any], user_intent: Dict[str, Any]) -> Dict[str, Any]:
        """
        é‡æ–°ç”Ÿæˆæ¥å£ï¼Œæ”¯æŒç”¨æˆ·å¹²é¢„
        user_intent ç¤ºä¾‹:
        {
            "action": "reselect",  # æˆ– "modify_text", "adjust_position"
            "target_shot_index": 1,
            "new_text": "å¤ªéœ‡æ’¼äº†ï¼",
            "new_position": "top-center"
        }
        """
        shot_blocks: List[Dict] = context["shot_blocks"]
        user_action = user_intent.get("action")

        # 1. å…ˆç”ŸæˆåŸå§‹ç»“æœ
        result = await self.generate(context)
        clips = result["aux_text_track"]["clips"]

        if not clips:
            return result  # æ— æ³•ä¿®æ”¹ç©ºç»“æœ

        if user_action == "reselect":
            # ç”¨æˆ·å¸Œæœ›é‡æ–°é€‰æ‹©å“ªäº›é•œå¤´åŠ æ–‡å­—
            selected_blocks = await self._select_relevant_shots(shot_blocks, user_intent)
            # é‡æ–°ç”Ÿæˆï¼ˆå¯åŠ å…¥ç”¨æˆ·åå¥½ï¼‰
            return await self.generate({**context, "user_intent": user_intent})

        elif user_action == "modify_text" and "target_shot_index" in user_intent:
            idx = user_intent["target_shot_index"]
            if 0 <= idx < len(clips):
                new_text = user_intent.get("new_text", clips[idx]["text"])
                # ä¿æŒå…¶ä»–å±æ€§ï¼Œåªæ”¹æ–‡å­—
                clips[idx]["text"] = new_text

        elif user_action == "adjust_position" and "target_shot_index" in user_intent:
            idx = user_intent["target_shot_index"]
            if 0 <= idx < len(clips):
                new_pos = user_intent.get("new_position", clips[idx]["position"])
                clips[idx]["position"] = new_pos

        elif user_action == "regenerate_all":
            # å®Œå…¨é‡æ–°ç”Ÿæˆï¼ˆå¯åŠ å…¥æ–°æç¤ºï¼‰
            prompt_hint = user_intent.get("prompt_hint", "")
            # å¯æ‰©å±•ï¼šå°† hint ä¼ å…¥ _select_relevant_shots æˆ– _decide_text_insertion
            return await self.generate(context)  # ç®€åŒ–ç‰ˆï¼Œå®é™…å¯æ›´æ™ºèƒ½

        return result

    async def _select_relevant_shots(self, shot_blocks: List[Dict], user_intent: Dict[str, Any] = None) -> List[Dict]:
        """
        å…¨å±€å†³ç­–ï¼šå“ªäº›é•œå¤´é€‚åˆåŠ è¾…åŠ©æ–‡å­—ï¼ˆé¿å…æ¯ä¸ªéƒ½åŠ ï¼‰
        """
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªè§†é¢‘å™äº‹è®¾è®¡å¸ˆã€‚è¯·ä»ä»¥ä¸‹åˆ†é•œä¸­ï¼Œé€‰æ‹©æœ€é€‚åˆæ·»åŠ **éå­—å¹•ç±»è¾…åŠ©æ€§æ–‡å­—**çš„é•œå¤´ã€‚
        è¿™ç±»æ–‡å­—æ˜¯æƒ…ç»ªæ€§ï¼ˆå¦‚â€œå¤ªå¥½åƒäº†ï¼â€ï¼‰ã€æ°›å›´æ€§ï¼ˆå¦‚â€œè§å±±è§æ€§â€ï¼‰ã€æˆ–å¼ºè°ƒæ€§çŸ­è¯­ï¼Œç”¨äºå¢å¼ºæ„ŸæŸ“åŠ›ã€‚

        è¯·é¿å…é€‰æ‹©ï¼š
        - äººç‰©è¯´è¯/è®²è§£çš„é•œå¤´ï¼ˆå·²æœ‰å­—å¹•ï¼‰
        - ç”»é¢ä¿¡æ¯å¯†é›†æˆ–æ–‡å­—/äººè„¸é®æŒ¡é£é™©é«˜çš„é•œå¤´

        åˆ†é•œåˆ—è¡¨ï¼š
        {self._format_shots_for_prompt(shot_blocks)}

        {f'ç”¨æˆ·åå¥½æç¤ºï¼š{user_intent.get("prompt_hint", "")}' if user_intent else ''}

        è¾“å‡º JSONï¼š
        {{
            "selected_indices": [0, 2]  // é€‰ä¸­çš„åˆ†é•œç´¢å¼•
        }}
        """

        json_schema = {
            "type": "object",
            "properties": {
                "selected_indices": {
                    "type": "array",
                    "items": {"type": "integer", "minimum": 0},
                    "uniqueItems": True
                }
            },
            "required": ["selected_indices"]
        }

        try:
            response = self.qwen.generate(
                prompt=prompt,
                parse_json=True,
            )
            indices = response.get("selected_indices", [])
            # è¿‡æ»¤åˆæ³•ç´¢å¼•
            return [shot_blocks[i] for i in indices if 0 <= i < len(shot_blocks)]
        except Exception as e:
            print(f"[Selection Error] {e}")
            return []  # é»˜è®¤ä¸åŠ 



    def _get_decision_schema(self) -> Dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "should_display": {"type": "boolean"},
                "text": {"type": "string", "minLength": 1},
                "position": {
                    "type": "string",
                    "enum": ["top-left", "top-center", "top-right", "center", "center-bottom", 
                            "bottom-left", "bottom-center", "bottom-right"]
                },
                "style": {
                    "type": "object",
                    "properties": {
                        "color": {"type": "string"},
                        "stroke": {"type": "string"},
                        "size": {"type": "integer", "minimum": 12, "maximum": 72},
                        "bold": {"type": "boolean"},
                        "italic": {"type": "boolean"}
                    },
                    "required": ["color", "size"]
                }
            },
            "required": ["should_display", "text", "position", "style"]
        }
    

    def _format_shots_for_prompt(self, shot_blocks: List[Dict]) -> str:
        """æ ¼å¼åŒ–åˆ†é•œç”¨äº prompt"""
        lines = []
        for i, block in enumerate(shot_blocks):
            lines.append(f"{i}. [{block['shot_type']}] {block['visual_description']} (æ—¶é•¿: {block['duration']}s)")
        return "\n".join(lines)
