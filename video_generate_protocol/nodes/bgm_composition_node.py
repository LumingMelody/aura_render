# nodes/bgm_composition_node.py

from video_generate_protocol import BaseNode
from typing import Dict, List, Any
import random
import math
from dataclasses import dataclass
import requests
from materials_supplies import match_bgm,BGMRequest,BGMResponse
import asyncio


# ==================== æƒ…æ„Ÿå¼ºåº¦æƒé‡ï¼ˆç”¨äºè¯„åˆ†ï¼‰====================
MOOD_WEIGHTS = {
    "æ¿€æ˜‚": 1.0,
    "åŠ±å¿—": 0.9,
    "æ„ŸåŠ¨": 0.85,
    "æ¸©é¦¨": 0.8,
    "å¹½é»˜": 0.6,
    "å†·é™": 0.5,
    "æ‚¬ç–‘": 0.75,
    "ç§‘æŠ€": 0.6
}

# BPM å®¹å·®èŒƒå›´
BPM_TOLERANCE = 8  # Â±8 BPM

# é»˜è®¤æ·¡å…¥æ·¡å‡ºæ—¶é—´ï¼ˆç§’ï¼‰
DEFAULT_FADE_IN = 3.0
DEFAULT_FADE_OUT = 5.0

# éŸ³ä¹ API åœ°å€ï¼ˆç¤ºä¾‹ï¼‰
MUSIC_SEARCH_API = "https://api.yourbgmservice.com/v1/tracks/search"


@dataclass
class Track:
    id: str
    title: str
    file_path: str
    bpm: float
    duration: float
    genre: List[str]
    mood: List[str]
    key: str
    has_bass_drop: bool

class BGMCompositionNode(BaseNode):
    # å£°æ˜ generate æ‰€éœ€çš„è¾“å…¥ç»“æ„
    required_inputs = [
        {
            "name":"bgm_tracks_id",
            "label": "BGMåˆ†é•œå—åˆ—è¡¨",
            "type": List[Dict],
            "desc": "BGMåˆ†é•œå—åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« start_time, end_time, mood, genre, instruments, narrative_role ç­‰",
            "required": True,
            "schema": {
                "start_time": {"type": "float", "description": "ç‰‡æ®µèµ·å§‹æ—¶é—´ï¼ˆç§’ï¼‰"},
                "end_time": {"type": "float", "description": "ç‰‡æ®µç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰"},
                "mood": {"type": "str", "description": "æƒ…ç»ªï¼Œå¦‚ æ¸©é¦¨ã€åŠ±å¿—ã€å†·é™"},
                "genre": {"type": "str", "description": "éŸ³ä¹ç±»å‹ï¼Œå¦‚ è½»éŸ³ä¹ / é’¢ç´æ›²"},
                "bpm": {"type": "int", "description": "èŠ‚å¥é€Ÿåº¦"},
                "instruments": {"type": "list[str]", "description": "ä¸»è¦ä¹å™¨"},
                "transition": {"type": "str", "description": "è¿‡æ¸¡æ–¹å¼ï¼šæ·¡å…¥ã€æ¸å¼ºã€äº¤å‰æ·¡åŒ–ç­‰"},
                "narrative_role": {"type": "str", "description": "è¯¥æ®µéŸ³ä¹åœ¨å™äº‹ä¸­çš„ä½œç”¨"},
                "segment_index": {"type": "int", "description": "ç‰‡æ®µç´¢å¼•"},
                "recommended_track": {
                    "type": "dict",
                    "description": "æ¨èæ›²ç›®ä¿¡æ¯",
                    "fields": {
                        "title": {"type": "str"},
                        "artist": {"type": "str"},
                        "reason": {"type": "str"}
                    }
                }
            }
        },
        {
            "name":"narrative_arc_id",
            "type": str,
            "desc": "æ•´ä½“å™äº‹ç»“æ„åˆ†æï¼Œå¦‚ è‹±é›„ä¹‹æ—…ã€ä¸‰å¹•å‰§ ç­‰",
            "required": False,
            "default": ""
        }
    ]

    output_schema=[
        {
            "name": "bgm_composition_id",
            "label": "BGMåˆæˆç»“æœåˆ—è¡¨",
            "type": list,
            "required": True,
            "desc": "åŒ…å«æ¯æ®µåŒ¹é…çš„éŸ³ä¹èµ„æºï¼Œå¦‚ [{'segment_index': 0, 'start_time': 0.0, 'end_time': 10.0, 'mood': 'æ¸©é¦¨', 'genre': 'è½»éŸ³ä¹', 'narrative_role': 'å¼€åœº', 'transition': 'æ·¡å…¥', 'music_suggestion': {'title': 'è½»æ¾çš„æ—©æ™¨', 'artist': 'è½»éŸ³ä¹å¤§å¸ˆ', 'reason': 'é€‚åˆå¼€åœºçš„æ¸©é¦¨æ°›å›´'}, 'matched_audio': {...}, 'alternatives': [...] }]",
            "field_type": "json"
        },
        {
            "name": "total_music_duration_id",
            "label": "æ€»éŸ³ä¹æ—¶é•¿",
            "type": float,
            "required": False,
            "desc": "éŸ³ä¹æ€»æ—¶é•¿ï¼Œå•ä½ä¸ºç§’",
            "field_type": "text"
        }
    ]

    def __init__(self, node_id: str, name: str = "BGMåˆæˆï¼ˆåˆ†é•œé©±åŠ¨ï¼‰"):
        self.node_id = node_id
        self.name = name

    # async def generate(self, context: Dict[str, Any]) -> Dict[str, Any]:
    #     """
    #     ä¸»ç”Ÿæˆå‡½æ•°ï¼šè¾“å…¥ä¸º bgm_tracks åˆ†é•œå—ï¼Œè¾“å‡ºä¸ºæ¯æ®µåŒ¹é…çš„éŸ³ä¹èµ„æº
    #     """
    #     bgm_tracks = context.get("bgm_tracks")
    #     narrative_arc = context.get("narrative_arc", "")

    #     if not bgm_tracks:
    #         raise ValueError("ç¼ºå°‘ bgm_tracks åˆ†é•œæ•°æ®")

    #     result_segments = []

    #     # å¹¶å‘åœ°ä¸ºæ¯ä¸ªåˆ†é•œæ®µè¯·æ±‚éŸ³ä¹
    #     tasks = [self._fetch_music_for_segment(segment) for segment in bgm_tracks]
    #     music_results = await asyncio.gather(*tasks)

    #     for segment, matches in zip(bgm_tracks, music_results):
    #         primary_match = matches[0] if matches else None

    #         result_segment = {
    #             "segment_index": segment["segment_index"],
    #             "start_time": segment["start_time"],
    #             "end_time": segment["end_time"],
    #             "mood": segment["mood"],
    #             "genre": segment["genre"],
    #             "narrative_role": segment["narrative_role"],
    #             "transition": segment["transition"],
    #             "music_suggestion": {
    #                 "title": segment["recommended_track"]["title"],
    #                 "artist": segment["recommended_track"]["artist"],
    #                 "reason": segment["recommended_track"]["reason"]
    #             },
    #             "matched_audio": primary_match.dict() if primary_match else None,
    #             "alternatives": [m.dict() for m in matches[1:]] if matches and len(matches) > 1 else []
    #         }
    #         result_segments.append(result_segment)

    #     return {
    #         # "status": "success",
    #         # "narrative_arc": narrative_arc,
    #         "bgm_composition_id": result_segments,
    #         "total_music_duration_id": max((seg["end_time"] for seg in bgm_tracks), default=0),
    #         # "timestamp": asyncio.get_event_loop().time()
    #     }

    async def generate(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä¸»ç”Ÿæˆå‡½æ•°ï¼šè¾“å…¥ä¸º bgm_tracks åˆ†é•œå—ï¼Œè¾“å‡ºä¸ºç¬¦åˆæ ‡å‡†æ ¼å¼çš„ BGM éŸ³è½¨
        """
        self.validate_context(context)
        bgm_tracks = context.get("bgm_tracks_id")
        narrative_arc = context.get("narrative_arc", "")

        if not bgm_tracks:
            raise ValueError("ç¼ºå°‘ bgm_tracks åˆ†é•œæ•°æ®")

        # å¹¶å‘åŒ¹é…éŸ³ä¹
        tasks = [self._fetch_music_for_segment(segment) for segment in bgm_tracks]
        music_results = await asyncio.gather(*tasks)

        clips = []
        for idx, (segment, matches) in enumerate(zip(bgm_tracks, music_results)):
            duration = segment["end_time"] - segment["start_time"]

            primary_match = matches[0] if matches else None
            alternatives = [m.dict() for m in matches[1:]] if matches and len(matches) > 1 else []

            # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œä½¿ç”¨é™éŸ³æˆ–é»˜è®¤éŸ³æ•ˆå ä½
            if not primary_match:
                fallback_url = "https://assets.example.com/silence.mp3"
                primary_match = {
                    "url": fallback_url,
                    "cut_start": 0.0,
                    "cut_end": duration,
                    "duration": duration
                }
            else:
                primary_match = primary_match.dict()

            clip = {
                "clip_id": f"bgm_{idx}",
                "start": segment["start_time"],
                "end": segment["end_time"],
                "duration": duration,
                "mood": segment["mood"],
                "genre": segment["genre"],
                "narrative_role": segment["narrative_role"],
                "transition": segment["transition"],
                "music_suggestion": {
                    "title": segment["recommended_track"]["title"],
                    "artist": segment["recommended_track"]["artist"],
                    "reason": segment["recommended_track"]["reason"]
                },
                "audio": {
                    "url": primary_match["url"],
                    "in_point": primary_match["cut_start"],
                    "out_point": primary_match["cut_end"],
                    "duration": primary_match["duration"]
                },
                "alternatives": alternatives,
                "volume_db": self._suggest_volume_db(segment["mood"]),  # è‡ªåŠ¨å»ºè®®éŸ³é‡
                "pan": 0.0  # å±…ä¸­
            }
            clips.append(clip)

        total_duration = max((seg["end_time"] for seg in bgm_tracks), default=0)

        # âœ… è¿”å›æ ‡å‡†éŸ³è½¨æ ¼å¼
        return {
            "track_id": "bgm_track",
            "track_name": "èƒŒæ™¯éŸ³ä¹",
            "track_type": "background_music",
            "total_duration": total_duration,
            "clips": clips,
            "metadata": {
                "narrative_arc": narrative_arc,
                "generated_by": self.node_id,
                "timestamp": asyncio.get_event_loop().time()
            }
        }

    async def _fetch_music_for_segment(self, segment: Dict[str, Any]) -> List[BGMResponse]:
        """
        ä¸ºå•ä¸ªåˆ†é•œæ®µè°ƒç”¨ match_bgm è·å–åŒ¹é…éŸ³ä¹
        """
        duration = segment["end_time"] - segment["start_time"]

        # æ„é€ è¯·æ±‚æè¿°
        description = (
            f"{segment['mood']}æƒ…ç»ªï¼Œä½¿ç”¨{', '.join(segment['instruments'])}ï¼Œ"
            f"èŠ‚å¥{segment['bpm']} BPMï¼Œç”¨äº{segment['narrative_role']}"
        )

        category = segment["genre"].split("/")[0].strip()  # å–ä¸»ç±»å‹

        request = BGMRequest(
            description=description,
            category=category,
            duration=duration
        )

        try:
            matches = await match_bgm(request)
            return matches
        except Exception as e:
            print(f"âš ï¸ åŒ¹é…éŸ³ä¹å¤±è´¥ [{segment['segment_index']}]: {str(e)}")
            return []
        
    def _suggest_volume_db(self, mood: str) -> float:
        """æ ¹æ®æƒ…ç»ªå»ºè®®é»˜è®¤éŸ³é‡"""
        volume_map = {
            "åŠ±å¿—": -16.0,
            "æ¿€åŠ¨": -15.0,
            "ç´§å¼ ": -17.0,
            "æ¸©é¦¨": -18.0,
            "å¹³é™": -20.0,
            "å†·é™": -20.0,
            "èˆ’ç¼“": -20.0,
            "æ‚²ä¼¤": -19.0
        }
        return volume_map.get(mood, -18.0)
    async def regenerate(self, context: Dict[str, Any], user_intent: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ”¯æŒç”¨æˆ·å¹²é¢„çš„é‡æ–°ç”Ÿæˆå‡½æ•°
        æ”¯æŒçš„å¹²é¢„ç±»å‹ï¼š
        - æ›´æ¢æŸæ®µçš„æƒ…ç»ªæˆ–æè¿°
        - å¼ºåˆ¶é‡æ–°åŒ¹é…æŸæ®µ
        - æŒ‡å®šæŸæ®µä½¿ç”¨ç‰¹å®šéŸ³ä¹ URL
        - æ·»åŠ è‡ªå®šä¹‰æç¤ºè¯­ä¼˜åŒ–åŒ¹é…
        """
        bgm_tracks = context.get("bgm_tracks")
        if not bgm_tracks:
            raise ValueError("ç¼ºå°‘ bgm_tracks åˆ†é•œæ•°æ®")

        # åˆ›å»ºå¯ä¿®æ”¹çš„åˆ†é•œå‰¯æœ¬
        modified_segments = [dict(segment) for segment in bgm_tracks]

        override = user_intent.get("bgm_override")
        if not override:
            # å¦‚æœæ²¡æœ‰è¦†ç›–æŒ‡ä»¤ï¼Œåªæ˜¯é‡æ–°ç”Ÿæˆï¼ˆæ¯”å¦‚é‡æ–°éšæœºé€‰æ›²ï¼‰
            return await self.generate(context)

        updated_indices = set()

        for cmd in override:
            idx = cmd.get("segment_index")

            if idx is None or idx >= len(modified_segments):
                continue

            segment = modified_segments[idx]
            updated_indices.add(idx)

            # === 1. æ›´æ¢æƒ…ç»ª/é£æ ¼ ===
            if "mood" in cmd:
                segment["mood"] = cmd["mood"]
                segment["narrative_role"] = cmd.get("narrative_role", segment["narrative_role"])
                print(f"ğŸ” ç”¨æˆ·å¹²é¢„ï¼šæ®µè½ {idx} æƒ…ç»ªæ›´æ”¹ä¸º '{cmd['mood']}'")

            if "genre" in cmd:
                segment["genre"] = cmd["genre"]

            # === 2. è‡ªå®šä¹‰æè¿°å¢å¼ºåŒ¹é… ===
            if "description_hint" in cmd:
                # é™„åŠ åˆ° narrative_role æˆ– instruments
                extra = cmd["description_hint"]
                segment["narrative_role"] += f"ã€‚ç‰¹åˆ«æ³¨æ„ï¼š{extra}"
                print(f"ğŸ” æ®µè½ {idx} æ·»åŠ æè¿°æç¤ºï¼š{extra}")

            # === 3. å¼ºåˆ¶ä½¿ç”¨æŒ‡å®šéŸ³ä¹ URL ===
            if "use_url" in cmd:
                url = cmd["use_url"]
                duration = segment["end_time"] - segment["start_time"]
                cut_start = cmd.get("cut_start", 0.0)
                cut_end = cmd.get("cut_end", cut_start + duration)

                # ç›´æ¥æ³¨å…¥ matched_audioï¼Œè·³è¿‡ match_bgm
                segment["_forced_audio"] = {
                    "url": url,
                    "cut_start": cut_start,
                    "cut_end": cut_end,
                    "duration": cut_end - cut_start
                }
                print(f"ğŸµ å¼ºåˆ¶æŒ‡å®šéŸ³ä¹ï¼šæ®µè½ {idx} â†’ {url}")

            # === 4. å¼ºåˆ¶é‡æ–°åŒ¹é…ï¼ˆå¸¦æ–°å‚æ•°ï¼‰===
            if "reroll" in cmd and cmd["reroll"]:
                # å¯ç»“åˆ hint ä¸€èµ·ä½¿ç”¨
                hint = cmd.get("hint", "")
                if hint:
                    segment["narrative_role"] += f"ã€‚ä¼˜å…ˆè€ƒè™‘ï¼š{hint}"
                print(f"ğŸ”„ é‡æ–°åŒ¹é…æ®µè½ {idx}ï¼ˆå¸¦æ–°æç¤ºï¼‰")

        # é‡æ–°ç”Ÿæˆï¼šå¯¹è¢«ä¿®æ”¹çš„æ®µè½é‡æ–°è¯·æ±‚ï¼Œå…¶ä½™ä¿ç•™åŸç»“æœï¼Ÿ
        # æ³¨æ„ï¼šå½“å‰è®¾è®¡æ˜¯å…¨é‡é‡æ–°ç”Ÿæˆã€‚è‹¥è¦å¢é‡æ›´æ–°ï¼Œéœ€æ›´å¤æ‚çš„çŠ¶æ€ç®¡ç†

        # è¿™é‡Œæˆ‘ä»¬é€‰æ‹©ï¼šå…¨é‡é‡æ–°ç”Ÿæˆï¼ˆç®€å•å¯é ï¼‰
        # ä½†ä½ å¯ä»¥æ‰©å±•ä¸ºï¼šä»…å¯¹ updated_indices é‡æ–°è¯·æ±‚

        # ä¸´æ—¶æ‰“æ ‡å¼ºåˆ¶éŸ³é¢‘ï¼Œåœ¨ generate åæ³¨å…¥
        context_with_forced = {"bgm_tracks": modified_segments, "narrative_arc": context.get("narrative_arc", "")}
        result = await self.generate(context_with_forced)

        # æ³¨å…¥ç”¨æˆ·å¼ºåˆ¶æŒ‡å®šçš„éŸ³é¢‘ï¼ˆç»•è¿‡ match_bgmï¼‰
        for seg_result in result["bgm_composition"]:
            idx = seg_result["segment_index"]
            orig_segment = modified_segments[idx]
            # if "_forced_audio" in orig_segment:
            #     forced = orig_segment["_forced_audio"]
            #     seg_result["matched_audio"] = forced
            #     seg_result["alternatives"] = []
            #     seg_result["music_suggestion"] = {
            #         "title": "ç”¨æˆ·æŒ‡å®šæ›²ç›®",
            #         "artist": "Custom",
            #         "reason": f"æ¥è‡ªç”¨æˆ·æŒ‡ä»¤: {forced['url']}"
            #     }
            #     print(f"âœ… å·²æ³¨å…¥ç”¨æˆ·æŒ‡å®šéŸ³é¢‘åˆ°æ®µè½ {idx}")
            # åœ¨ regenerate ä¸­æ³¨å…¥ç”¨æˆ·æŒ‡å®šéŸ³é¢‘æ—¶ï¼Œä¿æŒç»“æ„ä¸€è‡´
            if "_forced_audio" in orig_segment:
                forced = orig_segment["_forced_audio"]
                seg_result["audio"] = {
                    "url": forced["url"],
                    "in_point": forced["cut_start"],
                    "out_point": forced["cut_end"],
                    "duration": forced["cut_end"] - forced["cut_start"]
                }
                seg_result["music_suggestion"] = {
                    "title": "ç”¨æˆ·æŒ‡å®šæ›²ç›®",
                    "artist": "Custom",
                    "reason": f"æ¥è‡ªç”¨æˆ·æŒ‡ä»¤: {forced['url']}"
                }
                seg_result["alternatives"] = []
                print(f"âœ… å·²æ³¨å…¥ç”¨æˆ·æŒ‡å®šéŸ³é¢‘åˆ°æ®µè½ {idx}")
        # è®°å½•ç”¨æˆ·æ„å›¾
        result["regeneration_reason"] = str(user_intent)
        return result


    def validate_inputs(self, context: Dict[str, Any]) -> (bool, List[str]):
        """
        æ ¹æ® required_inputs æ ¡éªŒè¾“å…¥
        è¿”å›: (is_valid, error_messages)
        """
        errors = []

        for key, spec in self.required_inputs.items():
            required = spec.get("required", False)
            if required and key not in context:
                errors.append(f"ç¼ºå°‘å¿…éœ€è¾“å…¥: {key}")
                continue

            value = context.get(key)
            if value is None and required:
                errors.append(f"è¾“å…¥ä¸èƒ½ä¸ºç©º: {key}")
                continue

            # ç±»å‹æ£€æŸ¥ï¼ˆç®€åŒ–ç‰ˆï¼‰
            if value is not None:
                expected_type = spec["type"]
                if expected_type == "list[dict]" and not isinstance(value, list):
                    errors.append(f"è¾“å…¥ '{key}' åº”ä¸ºåˆ—è¡¨ç±»å‹ï¼Œå®é™…ä¸º {type(value)}")
                elif expected_type == "str" and not isinstance(value, str):
                    errors.append(f"è¾“å…¥ '{key}' åº”ä¸ºå­—ç¬¦ä¸²ç±»å‹ï¼Œå®é™…ä¸º {type(value)}")
                elif expected_type == "list[str]" and not (
                    isinstance(value, list) and all(isinstance(i, str) for i in value)
                ):
                    errors.append(f"è¾“å…¥ '{key}' åº”ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨")

        return len(errors) == 0, errors
if __name__ == "__main__":
    print("ğŸ¬ åˆ†é•œé©±åŠ¨BGMåˆæˆç³»ç»Ÿå¯åŠ¨...\n")

    # åˆ›å»ºèŠ‚ç‚¹
    node = BGMCompositionNode(node_id="bgm_001")

    # è¾“å…¥åˆ†é•œå—
    shot_blocks = [
        {
            "shot_type": "ä¸­æ™¯",
            "duration": 8,
            "visual_description": "è®²å¸ˆç«™åœ¨ç™½æ¿å‰å¾®ç¬‘ï¼Œæ‰‹æŒ‡å‘å±å¹•ä¸Šçš„è¯¾ç¨‹æ€»ç»“è¦ç‚¹ï¼›èƒŒæ™¯ä¸ºæ˜äº®æ¸©é¦¨çš„æ•™å®¤ã€‚",
            "pacing": "å¸¸è§„",
            "caption": "æˆ‘ä»¬å·²ç»èµ°è¿‡äº†è¿™æ®µæ—…ç¨‹çš„å…³é”®ç‚¹ã€‚"
        },
        {
            "shot_type": "ç‰¹å†™",
            "duration": 4,
            "visual_description": "è®²å¸ˆçš„æ‰‹æŒ‡è½»è½»è§¦ç¢°ç¬”è®°æœ¬ç”µè„‘è§¦æ§æ¿ï¼Œå±å¹•ä¸Šæ˜¾ç¤ºâ€˜å¼€å§‹ä½ çš„é¡¹ç›®â€™å­—æ ·ã€‚",
            "pacing": "æ…¢é•œå¤´",
            "caption": "ç°åœ¨è½®åˆ°ä½ äº†ï¼"
        },
        {
            "shot_type": "å…¨æ™¯",
            "duration": 8,
            "visual_description": "ç”»é¢åˆ‡æ¢è‡³ä¸€ä½å­¦ç”Ÿåœ¨å®¶ä¸­è®¾ç½®å¥½çš„å·¥ä½œåŒºè®¤çœŸæ“ä½œç”µè„‘ï¼Œå‘¨å›´ç¯å¢ƒæ•´æ´æœ‰åºï¼Œå¢™ä¸ŠæŒ‚ç€æ¿€åŠ±æ€§çš„æµ·æŠ¥ã€‚",
            "pacing": "å¸¸è§„",
            "caption": "å¼€å¯ä½ çš„æœºå™¨å­¦ä¹ ä¹‹æ—…å§ã€‚"
        }
    ]

    context = {
        "shot_blocks": shot_blocks,
        "target_duration": 60.0
    }

    print("ğŸ“Œ åˆ†é•œæ•°é‡:", len(shot_blocks))
    print("ğŸ¯ ç›®æ ‡æ—¶é•¿:", context["target_duration"], "ç§’\n")

    # æ‰§è¡Œç”Ÿæˆ
    result = node.generate(context)
    print("ğŸ‰ BGMåˆæˆç»“æœ:"+str(result))

    if "bgm_track" in result and result["bgm_track"].get("file_path"):
        track = result["bgm_track"]
        print("âœ… æ¨èBGM:")
        print(f"   æ›²å: {track['title']}")
        print(f"   æ¥æº: {track['source']}")
        print(f"   æ—¶é•¿: {track['duration']}s")
        print(f"   BPM: {track['original_bpm']}")
        print(f"   æƒ…ç»ª: {track['metadata']['mood']}")
        print(f"   æ–‡ä»¶: {track['file_path']}")
    else:
        print("âŒ æœªèƒ½ç”ŸæˆBGMã€‚")