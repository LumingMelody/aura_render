# nodes/emotion_analysis_node.py

from typing import Dict, List, Any, Optional, Tuple
import random
import json
import re
import asyncio
from concurrent.futures import ThreadPoolExecutor
import numpy as np
from dataclasses import dataclass
from collections import defaultdict
import hashlib
import time
from functools import wraps

from video_generate_protocol import BaseNode
from video_generate_protocol.prompt_manager import get_prompt_manager
from llm import QwenLLM

# æƒ…æ„Ÿç±»å‹å®šä¹‰ï¼ˆå¯æ‰©å±•ï¼‰
EMOTION_CATEGORIES = [
    "æ¿€æ˜‚", "æ¸©é¦¨", "æ‚¬ç–‘", "å¹½é»˜", "æ‚²ä¼¤", "åŠ±å¿—", "å†·é™", "æµªæ¼«", "ææƒ§", "æ„ŸåŠ¨"
]

# æ‰©å±•çš„æƒ…æ„Ÿç»´åº¦
EMOTION_DIMENSIONS = {
    # èƒ½é‡ç»´åº¦ (Energy)
    "energy": {
        "high": ["æ¿€æ˜‚", "å¹½é»˜", "ææƒ§"],
        "medium": ["åŠ±å¿—", "æ‚¬ç–‘", "æ„ŸåŠ¨"],
        "low": ["æ¸©é¦¨", "æ‚²ä¼¤", "å†·é™", "æµªæ¼«"]
    },
    # æƒ…æ„Ÿä»·å€¼ (Valence)
    "valence": {
        "positive": ["æ¿€æ˜‚", "æ¸©é¦¨", "å¹½é»˜", "åŠ±å¿—", "æµªæ¼«", "æ„ŸåŠ¨"],
        "neutral": ["å†·é™", "æ‚¬ç–‘"],
        "negative": ["æ‚²ä¼¤", "ææƒ§"]
    },
    # ç´§å¼ åº¦ (Tension)
    "tension": {
        "high": ["æ‚¬ç–‘", "ææƒ§", "æ¿€æ˜‚"],
        "medium": ["åŠ±å¿—", "æ„ŸåŠ¨"],
        "low": ["æ¸©é¦¨", "å¹½é»˜", "å†·é™", "æµªæ¼«", "æ‚²ä¼¤"]
    }
}

# æƒ…æ„Ÿè½¬ç§»çŸ©é˜µ - å®šä¹‰æƒ…æ„Ÿä¹‹é—´çš„å…¼å®¹æ€§
EMOTION_COMPATIBILITY = {
    "æ¿€æ˜‚": {"åŠ±å¿—": 0.8, "æ„ŸåŠ¨": 0.6, "å¹½é»˜": 0.4},
    "æ¸©é¦¨": {"æµªæ¼«": 0.9, "æ„ŸåŠ¨": 0.8, "å†·é™": 0.7},
    "æ‚¬ç–‘": {"ææƒ§": 0.7, "å†·é™": 0.6},
    "å¹½é»˜": {"æ¸©é¦¨": 0.6, "æ¿€æ˜‚": 0.4},
    "æ‚²ä¼¤": {"æ„ŸåŠ¨": 0.8, "å†·é™": 0.6},
    "åŠ±å¿—": {"æ¿€æ˜‚": 0.8, "æ„ŸåŠ¨": 0.7, "å†·é™": 0.5},
    "å†·é™": {"æ¸©é¦¨": 0.7, "æ‚²ä¼¤": 0.6, "åŠ±å¿—": 0.5},
    "æµªæ¼«": {"æ¸©é¦¨": 0.9, "æ„ŸåŠ¨": 0.6},
    "ææƒ§": {"æ‚¬ç–‘": 0.7, "æ‚²ä¼¤": 0.5},
    "æ„ŸåŠ¨": {"æ¸©é¦¨": 0.8, "æ‚²ä¼¤": 0.8, "åŠ±å¿—": 0.7}
}

@dataclass
class EmotionCurve:
    """æƒ…æ„Ÿæ›²çº¿æ•°æ®ç»“æ„"""
    timeline: List[float]  # æ—¶é—´ç‚¹
    emotion_values: Dict[str, List[float]]  # æ¯ä¸ªæƒ…æ„Ÿåœ¨å„æ—¶é—´ç‚¹çš„å¼ºåº¦
    peak_moments: List[Tuple[float, str, float]]  # (æ—¶é—´, æƒ…æ„Ÿ, å¼ºåº¦)
    transitions: List[Tuple[float, str, str]]  # (æ—¶é—´, ä»æƒ…æ„Ÿ, åˆ°æƒ…æ„Ÿ)

@dataclass
class EmotionAnalysisResult:
    """æƒ…æ„Ÿåˆ†æç»“æœ"""
    primary_emotions: Dict[str, float]  # ä¸»è¦æƒ…æ„ŸåŠæƒé‡
    emotion_curve: Optional[EmotionCurve] = None  # æƒ…æ„Ÿæ›²çº¿
    emotion_tags: List[str] = None  # æƒ…æ„Ÿæ ‡ç­¾
    confidence_score: float = 0.0  # ç½®ä¿¡åº¦
    analysis_method: str = "llm"  # åˆ†ææ–¹æ³•
    recommendations: Dict[str, Any] = None  # å»ºè®®

# è§†é¢‘ç±»å‹ â†’ æƒ…æ„Ÿå€¾å‘å¢å¼ºæƒé‡ï¼ˆç¤ºä¾‹é…ç½®ï¼‰
VIDEO_TYPE_EMOTION_BIAS = {
    "äº§å“å¹¿å‘Š": {"æ¿€æ˜‚": 0.2, "å¹½é»˜": 0.15},
    "å“ç‰Œå®£ä¼ ": {"æ¿€æ˜‚": 0.25, "åŠ±å¿—": 0.2},
    "ä¿ƒé”€è§†é¢‘": {"æ¿€æ˜‚": 0.3, "å¹½é»˜": 0.1},
    "çŸ¥è¯†è®²è§£": {"å†·é™": 0.2, "æ¸©é¦¨": 0.1},
    "æŠ€èƒ½æ•™å­¦": {"å†·é™": 0.15},
    "åœ¨çº¿è¯¾ç¨‹": {"å†·é™": 0.2, "æ¸©é¦¨": 0.1},
    "å¾®ç”µå½±": {"æ„ŸåŠ¨": 0.2, "æ‚²ä¼¤": 0.15},
    "çŸ­è§†é¢‘æ•…äº‹": {"å¹½é»˜": 0.2, "æ„ŸåŠ¨": 0.1},
    "åŠ¨ç”»çŸ­ç‰‡": {"å¹½é»˜": 0.25, "æµªæ¼«": 0.1},
    "VLOG": {"æ¸©é¦¨": 0.3, "å¹½é»˜": 0.15},
    "ç¤¾äº¤åª’ä½“å†…å®¹": {"å¹½é»˜": 0.3, "æ¿€æ˜‚": 0.1},
    "ç›´æ’­å›æ”¾": {"å¹½é»˜": 0.2, "æ¸©é¦¨": 0.1},
    "æ–°é—»æ’­æŠ¥": {"å†·é™": 0.4},
    "è®¿è°ˆèŠ‚ç›®": {"å†·é™": 0.2, "æ„ŸåŠ¨": 0.15},
    "çºªå½•ç‰‡": {"å†·é™": 0.3, "æ„ŸåŠ¨": 0.2}
}

# ç¼“å­˜å’Œé‡è¯•æœºåˆ¶
class EmotionCache:
    """æƒ…æ„Ÿåˆ†æç»“æœç¼“å­˜"""
    def __init__(self, max_size: int = 100, ttl: int = 3600):  # TTL: 1å°æ—¶
        self.cache = {}
        self.timestamps = {}
        self.max_size = max_size
        self.ttl = ttl

    def _generate_key(self, text: str, video_type: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{text}_{video_type}"
        return hashlib.md5(content.encode()).hexdigest()

    def get(self, text: str, video_type: str) -> Optional[Dict[str, float]]:
        """è·å–ç¼“å­˜ç»“æœ"""
        key = self._generate_key(text, video_type)

        if key not in self.cache:
            return None

        # æ£€æŸ¥TTL
        if time.time() - self.timestamps[key] > self.ttl:
            self._remove(key)
            return None

        return self.cache[key]

    def set(self, text: str, video_type: str, result: Dict[str, float]):
        """è®¾ç½®ç¼“å­˜"""
        key = self._generate_key(text, video_type)

        # å¦‚æœç¼“å­˜æ»¡äº†ï¼Œåˆ é™¤æœ€è€çš„æ¡ç›®
        if len(self.cache) >= self.max_size:
            oldest_key = min(self.timestamps, key=self.timestamps.get)
            self._remove(oldest_key)

        self.cache[key] = result.copy()
        self.timestamps[key] = time.time()

    def _remove(self, key: str):
        """åˆ é™¤ç¼“å­˜æ¡ç›®"""
        self.cache.pop(key, None)
        self.timestamps.pop(key, None)

def async_retry(max_attempts: int = 3, delay: float = 1.0, backoff: float = 2.0):
    """å¼‚æ­¥é‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            last_exception = None

            for attempt in range(max_attempts):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_attempts - 1:
                        wait_time = delay * (backoff ** attempt)
                        print(f"âš ï¸ {func.__name__} ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥: {e}")
                        print(f"â³ ç­‰å¾… {wait_time:.1f}s åé‡è¯•...")
                        await asyncio.sleep(wait_time)
                    else:
                        print(f"âŒ {func.__name__} ç»è¿‡{max_attempts}æ¬¡å°è¯•åæœ€ç»ˆå¤±è´¥")

            raise last_exception
        return wrapper
    return decorator


class EmotionAnalysisNode(BaseNode):
    required_inputs = [
        {
            "name": "user_description_id",
            "label": "ç”¨æˆ·åŸå§‹è¾“å…¥",
            "type": str,
            "required": True,
            "default": "",
            "desc": "ç”¨æˆ·åŸå§‹è¾“å…¥",
            "field_type": "textarea"
        },
        {
            "name": "video_type_id",
            "label": "è§†é¢‘ç±»å‹",
            "type": str,
            "required": True,
            "default": "",
            "desc": "è§†é¢‘ç±»å‹ï¼Œå¦‚â€œå®£ä¼ ç‰‡â€ã€â€œVLOGâ€ç­‰"
        },
       
    ]

    output_schema=[
         {
            "name": "emotions_id",
            "label": "æƒ…æ„Ÿæ ‡ç­¾åŠæƒé‡",
            "type": str,
            "required": True,
            "default": "",
            "desc": "æƒ…æ„Ÿæ ‡ç­¾åŠæƒé‡ï¼Œå¦‚ {'åŠ±å¿—': 50, 'å†·é™': 30}",
            "field_type": "text"
        },
        {
            "name": "primary_emotion",
            "label": "ä¸»è¦æƒ…æ„Ÿ",
            "type": str,
            "required": True,
            "default": "å†·é™",
            "desc": "å¾—åˆ†æœ€é«˜çš„ä¸»è¦æƒ…æ„Ÿç±»åˆ«",
            "field_type": "text"
        }

    ]

    file_upload_config = {
        "image": {"enabled": False},
        "video": {"enabled": False},
        "audio": {"enabled": False}
    }

    system_parameters = {
        "max_emotion_labels": 3,
        "min_confidence": 0.05,
        "cache_enabled": True,
        "cache_size": 100,
        "cache_ttl": 3600,  # 1 hour
        "retry_attempts": 3,
        "retry_delay": 1.0,
        "retry_backoff": 2.0
    }

    def __init__(self, node_id: str, name: str = "æƒ…æ„ŸåŸºè°ƒåˆ†æ"):
        super().__init__(node_id=node_id, node_type="emotion_analysis", name=name)
        self._qwen = None  # æ‡’åŠ è½½ QwenLLM å®ä¾‹

        # åˆå§‹åŒ–ç¼“å­˜
        cache_params = self.system_parameters
        self.cache = EmotionCache(
            max_size=cache_params["cache_size"],
            ttl=cache_params["cache_ttl"]
        ) if cache_params["cache_enabled"] else None

        # å¢å¼ºé…ç½®ï¼ˆä¸´æ—¶ç¦ç”¨å¤æ‚åŠŸèƒ½ä»¥ç¡®ä¿åŸºæœ¬åŠŸèƒ½å¯ç”¨ï¼‰
        self.enable_curve_analysis = False
        self.enable_music_matching = False
        self.enable_multi_dimensional_analysis = False

        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_requests": 0,
            "cache_hits": 0,
            "llm_calls": 0,
            "fallback_calls": 0,
            "avg_response_time": 0.0
        }

    async def generate(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¢å¼ºçš„æƒ…æ„Ÿåˆ†æç”Ÿæˆæ–¹æ³•"""
        start_time = time.time()
        self.stats["total_requests"] += 1

        try:
            self.validate_context(context)  # å¼‚æ­¥è°ƒç”¨çˆ¶ç±»æ–¹æ³•

            user_description = context["user_description_id"]
            video_type = context["video_type_id"]

            # è·å–å¯é€‰çš„æ—¶é•¿å’Œåˆ†é•œä¿¡æ¯
            total_duration = context.get("total_duration", 60.0)
            shots_info = context.get("shots_info", [])

            # æ‰§è¡Œå¤šç»´æƒ…æ„Ÿåˆ†æ
            analysis_result = await self.analyze_emotions_comprehensive(
                user_description,
                video_type,
                total_duration,
                shots_info
            )
        except Exception as e:
            # è®°å½•é”™è¯¯å¹¶ä½¿ç”¨fallback
            print(f"âŒ EmotionAnalysisNode.generate å¤±è´¥: {e}")
            fallback_emotions = self._fallback_emotion_analysis(context.get("user_description_id", ""))
            analysis_result = EmotionAnalysisResult(
                primary_emotions=fallback_emotions,
                emotion_tags=["å†·é™"],
                confidence_score=0.3,
                analysis_method="fallback",
                recommendations={}
            )
            self.stats["fallback_calls"] += 1

            # âœ… è¾“å‡ºé™çº§åˆ†æç»“æœ
            print(f"âš ï¸ [Node 2] ä½¿ç”¨é™çº§æƒ…æ„Ÿåˆ†æç»“æœ:")
            print(f"   æƒ…æ„Ÿåˆ†å¸ƒ: {fallback_emotions}")
        finally:
            # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
            response_time = time.time() - start_time
            self._update_stats(response_time)

        # ç”Ÿæˆæƒ…æ„Ÿæ›²çº¿ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.enable_curve_analysis and total_duration > 10:
            analysis_result.emotion_curve = await self.generate_emotion_curve(
                analysis_result.primary_emotions,
                total_duration,
                shots_info
            )

        # ç”ŸæˆéŸ³ä¹åŒ¹é…å»ºè®®
        if self.enable_music_matching:
            analysis_result.recommendations = await self.generate_music_recommendations(
                analysis_result.primary_emotions
            )

        # æå–ä¸»è¦æƒ…æ„Ÿï¼ˆå¾—åˆ†æœ€é«˜çš„ï¼‰
        primary_emotion = max(analysis_result.primary_emotions, key=analysis_result.primary_emotions.get) if analysis_result.primary_emotions else "å†·é™"

        # âœ… è¾“å‡ºåˆ†æç»“æœåˆ°æ—¥å¿—
        print(f"ğŸ­ [Node 2] æƒ…æ„ŸåŸºè°ƒåˆ†æç»“æœ:")
        print(f"   ä¸»æƒ…æ„Ÿ: {primary_emotion}")
        print(f"   æƒ…æ„Ÿåˆ†å¸ƒ: {analysis_result.primary_emotions}")
        print(f"   æƒ…æ„Ÿæ ‡ç­¾: {analysis_result.emotion_tags}")
        print(f"   ç½®ä¿¡åº¦: {analysis_result.confidence_score:.2f}")
        print(f"   åˆ†ææ–¹æ³•: {analysis_result.analysis_method}")

        return {
            "emotions_id": analysis_result.primary_emotions,
            "primary_emotion": primary_emotion,  # âœ… æ·»åŠ ä¸»è¦æƒ…æ„Ÿå­—æ®µ
            "emotion_analysis_result": analysis_result,
            "emotion_curve": analysis_result.emotion_curve,
            "music_recommendations": analysis_result.recommendations
        }

    async def analyze_emotions_comprehensive(
        self,
        text: str,
        video_type: str,
        duration: float = 60.0,
        shots_info: List[Dict] = None
    ) -> EmotionAnalysisResult:
        """ç»¼åˆæƒ…æ„Ÿåˆ†æ"""

        # Step 1: åŸºç¡€æƒ…æ„Ÿåˆ†æ
        base_emotions = await self._enhanced_emotion_analysis(text, video_type)

        # Step 2: è§†é¢‘ç±»å‹è°ƒæ•´
        adjusted_emotions = self._adjust_emotions_by_video_type(base_emotions, video_type)

        # Step 3: å¤šç»´åº¦åˆ†æ
        if self.enable_multi_dimensional_analysis:
            dimensional_scores = self._calculate_dimensional_scores(adjusted_emotions)
            adjusted_emotions = self._apply_dimensional_constraints(adjusted_emotions, dimensional_scores)

        # Step 4: åˆ†é•œçº§åˆ«åˆ†æï¼ˆå¦‚æœæœ‰åˆ†é•œä¿¡æ¯ï¼‰
        if shots_info:
            shot_emotions = await self._analyze_shot_emotions(shots_info, adjusted_emotions)
        else:
            shot_emotions = None

        # Step 5: å½’ä¸€åŒ–å’Œé™åˆ¶
        final_emotions = self._normalize_and_limit(adjusted_emotions)

        # Step 6: è®¡ç®—ç½®ä¿¡åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰
        confidence = 0.8  # å›ºå®šç½®ä¿¡åº¦

        # Step 7: ç”Ÿæˆæƒ…æ„Ÿæ ‡ç­¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
        emotion_tags = list(final_emotions.keys())[:3]  # å–å‰3ä¸ªæƒ…æ„Ÿä½œä¸ºæ ‡ç­¾

        return EmotionAnalysisResult(
            primary_emotions=final_emotions,
            emotion_tags=emotion_tags,
            confidence_score=confidence,
            analysis_method="comprehensive_llm",
            recommendations={}
        )

    async def _enhanced_emotion_analysis(self, text: str, video_type: str = "") -> Dict[str, float]:
        """å¢å¼ºçš„æƒ…æ„Ÿåˆ†æï¼ŒåŒ…å«ç¼“å­˜å’Œé‡è¯•æœºåˆ¶"""
        # æ£€æŸ¥ç¼“å­˜
        if self.cache:
            cached_result = self.cache.get(text, video_type)
            if cached_result:
                self.stats["cache_hits"] += 1
                print(f"âœ… ç¼“å­˜å‘½ä¸­ï¼Œè·³è¿‡LLMè°ƒç”¨")
                return cached_result

        try:
            # ä½¿ç”¨LLMåˆ†æï¼ˆä¸»è¦æ–¹æ³•ï¼‰
            llm_result = await self._llm_emotion_analysis_with_retry(text)

            # å­˜å‚¨åˆ°ç¼“å­˜
            if self.cache:
                self.cache.set(text, video_type, llm_result)

            self.stats["llm_calls"] += 1
            return llm_result

        except Exception as e:
            print(f"âŒ Enhanced emotion analysis å¤±è´¥: {e}")
            fallback_result = self._fallback_emotion_analysis(text)
            self.stats["fallback_calls"] += 1
            return fallback_result

    @async_retry(max_attempts=3, delay=1.0, backoff=2.0)
    async def _llm_emotion_analysis_with_retry(self, text: str) -> Dict[str, float]:
        """å¸¦é‡è¯•æœºåˆ¶çš„LLMæƒ…æ„Ÿåˆ†æ"""
        return await self._llm_emotion_analysis(text)

    async def _llm_emotion_analysis(self, text: str) -> Dict[str, float]:
        """ä½¿ç”¨LLMè¿›è¡Œæƒ…æ„Ÿåˆ†æï¼Œé›†æˆä¸“ä¸šæ—¶ä»£åå¥½æŒ‡å¯¼"""
        try:
            qwen = self._get_qwen()

            # è·å–ä¸“ä¸šæ—¶ä»£åå¥½æŒ‡å¯¼æç¤ºè¯
            prompt_manager = get_prompt_manager()

            emotion_list = ", ".join(EMOTION_CATEGORIES)
            specific_task = f"""
è¯·æ·±åº¦åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼Œä¸ä»…è¦è¯†åˆ«æ˜æ˜¾çš„æƒ…æ„Ÿï¼Œè¿˜è¦æ•æ‰éšå«çš„æƒ…ç»ªã€è¯­å¢ƒæš—ç¤ºå’Œæƒ…æ„Ÿå±‚æ¬¡ã€‚

æƒ…æ„Ÿç±»åˆ«ï¼š{emotion_list}

åˆ†æè¦æ±‚ï¼š
1. æ¯ä¸ªæƒ…æ„Ÿç±»åˆ«éƒ½è¦è¯„åˆ†ï¼ˆ0-1åˆ†ï¼Œä¿ç•™2ä½å°æ•°ï¼‰
2. è€ƒè™‘æ–‡æœ¬çš„æ·±å±‚å«ä¹‰å’Œéšå«æƒ…æ„Ÿ
3. æ³¨æ„æƒ…æ„Ÿçš„å¼ºåº¦å’ŒæŒç»­æ€§
4. è¯†åˆ«å¯èƒ½çš„æƒ…æ„Ÿè½¬æ¢å’Œå±‚æ¬¡
5. è¾“å‡ºæ ‡å‡†JSONæ ¼å¼ï¼Œæ— å…¶ä»–å†…å®¹

è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
{{"æ¿€æ˜‚": 0.75, "æ¸©é¦¨": 0.20, "æ‚¬ç–‘": 0.05, "å¹½é»˜": 0.40, "æ‚²ä¼¤": 0.10, "åŠ±å¿—": 0.65, "å†·é™": 0.30, "æµªæ¼«": 0.15, "ææƒ§": 0.00, "æ„ŸåŠ¨": 0.80}}

åˆ†ææ–‡æœ¬ï¼š
"{text.strip()}"
"""

            # ä½¿ç”¨PromptManagerå¢å¼ºæç¤ºè¯ï¼Œèå…¥äº§å“æ—¶ä»£åå¥½åˆ†æ
            enhanced_prompt = prompt_manager.enhance_prompt(
                specific_task,
                "emotion_analysis",
                context={
                    "product": text,
                    "input": text
                }
            )

            # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡ŒåŒæ­¥æ–¹æ³•
            loop = asyncio.get_event_loop()
            executor = ThreadPoolExecutor(max_workers=1)

            response = await loop.run_in_executor(
                executor,
                lambda: qwen.generate(prompt=enhanced_prompt)
            )

            cleaned_response = self._extract_json_from_text(response)

            if not cleaned_response:
                raise ValueError("æœªèƒ½ä»å“åº”ä¸­æå–æœ‰æ•ˆ JSON")

            result = json.loads(cleaned_response)

            # éªŒè¯å¹¶æ¸…æ´—è¾“å‡º
            scores = {}
            for emotion in EMOTION_CATEGORIES:
                score = result.get(emotion, 0.1)
                try:
                    score = float(score)
                    scores[emotion] = max(0.0, min(1.0, score))
                except (TypeError, ValueError):
                    scores[emotion] = 0.1

            return scores

        except Exception as e:
            print(f"âš ï¸ LLM æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            return self._fallback_emotion_analysis(text)

    def _get_qwen(self):
        """æ‡’åŠ è½½ QwenLLM å®ä¾‹"""
        if self._qwen is None:
            try:
                
                self._qwen = QwenLLM()
            except ImportError as e:
                raise ImportError("æ— æ³•å¯¼å…¥ QwenLLMï¼Œè¯·ç¡®ä¿ qwenllm.py å­˜åœ¨å¹¶æ­£ç¡®å®ç°ã€‚") from e
        return self._qwen

    def _mock_nlp_emotion_analysis(self, text: str) -> Dict[str, float]:
        """
        ä½¿ç”¨ QwenLLM è¿›è¡Œæƒ…æ„Ÿåˆ†æï¼Œè¾“å‡º JSON æ ¼å¼çš„åˆ†æ•°ã€‚
        è‹¥å¤±è´¥ï¼Œåˆ™é™çº§ä¸ºå…³é”®è¯åŒ¹é… + éšæœºæ‰°åŠ¨ã€‚
        """
        try:
            qwen = self._get_qwen()

            emotion_list = ", ".join(EMOTION_CATEGORIES)
            prompt = f"""
            ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿåˆ†ææ¨¡å‹ã€‚è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼Œå¹¶ä¸ºä»¥ä¸‹æƒ…æ„Ÿç±»åˆ«åˆ†åˆ«æ‰“åˆ†ï¼ˆ0-1åˆ†ï¼Œä¿ç•™1ä½å°æ•°ï¼‰ï¼š
            {emotion_list}

            è¦æ±‚ï¼š
            1. æ¯ä¸ªæƒ…æ„Ÿç±»åˆ«éƒ½è¦è¯„åˆ†ï¼Œä¸èƒ½é—æ¼ã€‚
            2. åˆ†æ•°æ˜¯ç‹¬ç«‹çš„ï¼Œä¸éœ€è¦å½’ä¸€åŒ–ã€‚
            3. ä»…è¾“å‡ºä¸€ä¸ªæ ‡å‡†çš„ JSON å¯¹è±¡ï¼Œä¸è¦ä»»ä½•è§£é‡Šã€å‰ç¼€æˆ–åç¼€ã€‚
            4. å¦‚æœä¸ç¡®å®šï¼Œç»™0.1-0.3çš„ä½åˆ†ã€‚

            è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
            {{"æ¿€æ˜‚": 0.7, "æ¸©é¦¨": 0.2, "æ‚¬ç–‘": 0.1, "å¹½é»˜": 0.5, "æ‚²ä¼¤": 0.1, "åŠ±å¿—": 0.4, "å†·é™": 0.3, "æµªæ¼«": 0.2, "ææƒ§": 0.0, "æ„ŸåŠ¨": 0.8}}

            æ–‡æœ¬å†…å®¹ï¼š
            "{text.strip()}"
            """

            response = qwen.generate(prompt=prompt)
            cleaned_response = self._extract_json_from_text(response)

            if not cleaned_response:
                raise ValueError("æœªèƒ½ä»å“åº”ä¸­æå–æœ‰æ•ˆ JSON")

            result = json.loads(cleaned_response)

            # éªŒè¯å¹¶æ¸…æ´—è¾“å‡º
            scores = {}
            for emotion in EMOTION_CATEGORIES:
                score = result.get(emotion, 0.1)
                try:
                    score = float(score)
                    scores[emotion] = max(0.0, min(1.0, score))
                except (TypeError, ValueError):
                    scores[emotion] = 0.1

            return scores

        except Exception as e:
            print(f"âš ï¸ Qwen æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            print("â¡ï¸ ä½¿ç”¨é™çº§ç­–ç•¥ï¼šå…³é”®è¯åŒ¹é… + éšæœºæ‰°åŠ¨")

            # é™çº§é€»è¾‘
            return self._fallback_emotion_analysis(text)

    def _extract_json_from_text(self, text: str) -> str:
        """ä»å¯èƒ½åŒ…å«ä»£ç å—ã€æ¢è¡Œã€æ³¨é‡Šçš„æ–‡æœ¬ä¸­æå– JSON å­—ç¬¦ä¸²"""
        # å»é™¤é¦–å°¾ç©ºç™½
        text = text.strip()

        # å°è¯•åŒ¹é… ```json ... ``` æˆ– ``` ... ```
        json_pattern = r'```(?:json)?\s*([\s\S]*?)\s*```'
        match = re.search(json_pattern, text, re.DOTALL)
        if match:
            text = match.group(1).strip()

        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { åˆ°æœ€åä¸€ä¸ª } ä¹‹é—´çš„å†…å®¹
        start = text.find('{')
        end = text.rfind('}')
        if start == -1 or end == -1:
            return ""

        try:
            # å°è¯•è§£ææˆªå–çš„å†…å®¹
            candidate = text[start:end + 1]
            json.loads(candidate)  # éªŒè¯æ˜¯å¦åˆæ³•
            return candidate
        except json.JSONDecodeError:
            return ""

    def _fallback_emotion_analysis(self, text: str) -> Dict[str, float]:
        """é™çº§ç”¨çš„æƒ…æ„Ÿåˆ†æï¼šå…³é”®è¯åŒ¹é… + éšæœºæ‰°åŠ¨"""
        lower_text = text.lower()
        scores = {emotion: 0.1 for emotion in EMOTION_CATEGORIES}

        rules = [
            (["æ¿€åŠ¨", "çƒ­è¡€", "ç‡ƒ", "çˆ†å‘"], "æ¿€æ˜‚", 0.5),
            (["æ¸©æš–", "å®¶", "çˆ±", "é™ªä¼´"], "æ¸©é¦¨", 0.5),
            (["ç¥ç§˜", "æœªçŸ¥", "èƒŒå", "çœŸç›¸"], "æ‚¬ç–‘", 0.6),
            (["æç¬‘", "ç¬‘æ­»", "æ®µå­"], "å¹½é»˜", 0.4),
            (["æ„Ÿäºº", "æ³ªç›®", "åšæŒ"], "æ„ŸåŠ¨", 0.5),
            (["æ‚²ä¼¤", "éš¾è¿‡", "å¤±è½"], "æ‚²ä¼¤", 0.5),
            (["åŠ±å¿—", "å¥‹æ–—", "æ¢¦æƒ³"], "åŠ±å¿—", 0.4),
            (["å†·é™", "ç†æ€§", "åˆ†æ"], "å†·é™", 0.5),
            (["æµªæ¼«", "çˆ±æƒ…", "ç”œèœœ"], "æµªæ¼«", 0.4),
            (["ææƒ§", "å®³æ€•", "æƒŠæ‚š"], "ææƒ§", 0.6),
        ]

        for keywords, emotion, boost in rules:
            if any(word in lower_text for word in keywords):
                scores[emotion] += boost

        # æ·»åŠ éšæœºæ‰°åŠ¨
        for k in scores:
            scores[k] += random.uniform(-0.1, 0.2)
            scores[k] = max(0.0, scores[k])

        return scores

    def _adjust_emotions_by_video_type(self, emotions: Dict[str, float], video_type: str) -> Dict[str, float]:
        adjusted = emotions.copy()
        bias = VIDEO_TYPE_EMOTION_BIAS.get(video_type, {})
        for emotion, boost in bias.items():
            if emotion in adjusted:
                adjusted[emotion] *= (1 + boost)
            else:
                adjusted[emotion] = 0.3 * boost
        return adjusted

    def _normalize_and_limit(self, emotions: Dict[str, float]) -> Dict[str, int]:
        total = sum(emotions.values())
        if total == 0:
            return {"å†·é™": 100}

        percentages = {k: round((v / total) * 100) for k, v in emotions.items() if v > 0}
        min_confidence = self.system_parameters["min_confidence"] * 100
        filtered = {k: v for k, v in percentages.items() if v >= min_confidence}

        max_labels = self.system_parameters["max_emotion_labels"]
        sorted_emotions = sorted(filtered.items(), key=lambda x: -x[1])
        top_emotions = dict(sorted_emotions[:max_labels])

        new_total = sum(top_emotions.values())
        if new_total == 0:
            return {"å†·é™": 100}
        final = {k: round((v / new_total) * 100) for k, v in top_emotions.items()}

        # ä¿®æ­£æµ®ç‚¹è¯¯å·®
        while sum(final.values()) != 100:
            diff = 100 - sum(final.values())
            key = max(final, key=final.get)
            final[key] += diff

        return final

    def _update_stats(self, response_time: float):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        # æ›´æ–°å¹³å‡å“åº”æ—¶é—´
        if self.stats["total_requests"] > 1:
            current_avg = self.stats["avg_response_time"]
            n = self.stats["total_requests"] - 1
            self.stats["avg_response_time"] = (current_avg * n + response_time) / self.stats["total_requests"]
        else:
            self.stats["avg_response_time"] = response_time

    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        total = self.stats["total_requests"]
        if total == 0:
            return {"message": "æš‚æ— ç»Ÿè®¡æ•°æ®"}

        cache_hit_rate = (self.stats["cache_hits"] / total) * 100 if total > 0 else 0
        return {
            "total_requests": total,
            "cache_hits": self.stats["cache_hits"],
            "cache_hit_rate": f"{cache_hit_rate:.1f}%",
            "llm_calls": self.stats["llm_calls"],
            "fallback_calls": self.stats["fallback_calls"],
            "avg_response_time": f"{self.stats['avg_response_time']:.3f}s"
        }

    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        if self.cache:
            self.cache.cache.clear()
            self.cache.timestamps.clear()
            print("âœ… æƒ…æ„Ÿåˆ†æç¼“å­˜å·²æ¸…ç©º")

    def regenerate(self, context: Dict[str, Any], user_intent: Dict[str, Any]) -> Dict[str, Any]:
        super().regenerate(context, user_intent)
        override = user_intent.get("emotion_override")
        if override and isinstance(override, dict):
            return {"emotions": {k: v for k, v in override.items() if k in EMOTION_CATEGORIES}}
        return self.generate(context)
    
if __name__ == "__main__":
    import asyncio

    async def test_enhanced_emotion_analysis():
        # 1. åˆ›å»ºæƒ…æ„Ÿåˆ†æèŠ‚ç‚¹å®ä¾‹
        emotion_node = EmotionAnalysisNode(node_id="emotion_1", name="å¢å¼ºæƒ…æ„Ÿåˆ†æèŠ‚ç‚¹")
        print("ğŸš€ æµ‹è¯•å¢å¼ºç‰ˆæƒ…æ„Ÿåˆ†æèŠ‚ç‚¹ (å¸¦ç¼“å­˜å’Œé‡è¯•)")

        # 2. æ¨¡æ‹Ÿä¸Šæ¸¸èŠ‚ç‚¹ä¼ æ¥çš„ä¸Šä¸‹æ–‡ï¼ˆcontextï¼‰
        context = {
            "user_description_id": "æˆ‘æƒ³åšä¸€ä¸ªpythonçš„æ•™å­¦è§†é¢‘",
            "video_type_id": "çŸ¥è¯†è®²è§£"
        }

        # 3. è°ƒç”¨ generate æ–¹æ³•è¿›è¡Œæƒ…æ„Ÿåˆ†æ (ç¬¬ä¸€æ¬¡)
        try:
            print("\n--- ç¬¬ä¸€æ¬¡è°ƒç”¨ (å°†è°ƒç”¨LLM) ---")
            result = await emotion_node.generate(context)
            print("âœ… æƒ…æ„Ÿåˆ†æç»“æœï¼š")
            print(result["emotions_id"])
        except Exception as e:
            print(f"âŒ æ‰§è¡Œå¤±è´¥ï¼š{e}")

        # 4. ç¬¬äºŒæ¬¡è°ƒç”¨åŒæ ·å†…å®¹ (åº”è¯¥å‘½ä¸­ç¼“å­˜)
        try:
            print("\n--- ç¬¬äºŒæ¬¡è°ƒç”¨ (åº”è¯¥å‘½ä¸­ç¼“å­˜) ---")
            result2 = await emotion_node.generate(context)
            print("âœ… æƒ…æ„Ÿåˆ†æç»“æœ (ç¼“å­˜)ï¼š")
            print(result2["emotions_id"])
        except Exception as e:
            print(f"âŒ æ‰§è¡Œå¤±è´¥ï¼š{e}")

        # 5. æµ‹è¯•ä¸åŒå†…å®¹
        print("\n--- æµ‹è¯•äº§å“å¹¿å‘Šå†…å®¹ ---")
        context_ad = {
            "user_description_id": "è¿™æ¬¾æ‰‹æœºæ€§èƒ½è¶…å¼ºï¼Œè¿è¡Œé€Ÿåº¦é£å¿«ï¼Œæ¸¸æˆä½“éªŒçˆ†æ£šï¼Œçƒ­è¡€æ²¸è…¾ï¼",
            "video_type_id": "äº§å“å¹¿å‘Š"
        }
        try:
            ad_result = await emotion_node.generate(context_ad)
            print("ğŸ¯ å¹¿å‘Šæƒ…æ„Ÿåˆ†æç»“æœï¼š")
            print(ad_result["emotions_id"])
        except Exception as e:
            print(f"âŒ å¹¿å‘Šåˆ†æå¤±è´¥ï¼š{e}")

        # 6. æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        print("\n--- æ€§èƒ½ç»Ÿè®¡ ---")
        stats = emotion_node.get_performance_stats()
        for key, value in stats.items():
            print(f"{key}: {value}")

        # 7. æµ‹è¯•ç¼“å­˜æ¸…ç†
        print("\n--- æ¸…ç†ç¼“å­˜ ---")
        emotion_node.clear_cache()

    # è¿è¡Œå¼‚æ­¥æµ‹è¯•
    asyncio.run(test_enhanced_emotion_analysis())
