"""
å¢å¼ºç‰ˆè§†é¢‘ç¼–æ’å™¨ - å®Œå–„æ‰€æœ‰ç¼ºå¤±åŠŸèƒ½
"""
from typing import Dict, List, Any, Optional, Tuple
import asyncio
from dataclasses import dataclass
from pathlib import Path
import json

from video_generate_protocol.nodes.video_storyboard_orchestrator import VideoStoryboardOrchestrator, VideoStoryboardRequest
from video_generate_protocol.nodes.image_generation_node import ImageGenerationNode, ImageGenerationTask, ImageGenerationNodeRequest


class EnhancedVideoOrchestrator(VideoStoryboardOrchestrator):
    """
    å¢å¼ºç‰ˆè§†é¢‘ç¼–æ’å™¨
    å®Œå–„ç¼ºå¤±çš„åŠŸèƒ½ï¼š
    1. ä¸¤ç§è§†é¢‘ç”Ÿæˆæ–¹å¼ï¼ˆé¦–å°¾å¸§ vs ä»…é¦–å¸§ï¼‰
    2. VLè§†è§‰éªŒè¯
    3. åŒä¸€ç‰©ä½“çš„å›¾ç”Ÿå›¾ä¼˜å…ˆçº§
    4. æ®µè½åˆ’åˆ†æ—¶çš„è½¬åœºé¢„å¤„ç†
    """

    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)

        # VLæ¨¡å‹é…ç½®ï¼ˆç”¨äºè§†è§‰éªŒè¯ï¼‰
        self.vl_validation_enabled = config.get("vl_validation", True)

    async def process_video_request(self, request: VideoStoryboardRequest) -> Dict[str, Any]:
        """
        å¢å¼ºçš„è§†é¢‘ç”Ÿæˆæµç¨‹
        """

        print(f"\nğŸ¬ å¼€å§‹å¢å¼ºè§†é¢‘ç”Ÿæˆæµç¨‹ ({request.duration_seconds}ç§’)")
        print("="*60)

        try:
            # ç¬¬1æ­¥ï¼šé¢„å¤„ç† - è½¬åœºæ£€æµ‹å’Œæ®µè½ä¼˜åŒ–
            preprocessed_segments = await self._preprocess_segments(request)

            # ç¬¬2æ­¥ï¼šVGPä¼˜åŒ–åˆ†é•œè§„åˆ’
            storyboard_plan = await self._optimize_storyboard_enhanced(request, preprocessed_segments)

            # ç¬¬3æ­¥ï¼šæ™ºèƒ½å›¾åƒç”Ÿæˆç­–ç•¥
            keyframes = await self._generate_keyframes_with_priority(storyboard_plan)

            # ç¬¬4æ­¥ï¼šVLè§†è§‰éªŒè¯
            if self.vl_validation_enabled:
                validation_result = await self._vl_validate_keyframes(keyframes)
                if not validation_result["passed"]:
                    # é‡æ–°ç”Ÿæˆæœ‰é—®é¢˜çš„å¸§
                    keyframes = await self._regenerate_failed_frames(keyframes, validation_result)

            # ç¬¬5æ­¥ï¼šæ™ºèƒ½è§†é¢‘ç”Ÿæˆï¼ˆä¸¤ç§æ¨¡å¼ï¼‰
            video_clips = await self._generate_video_clips_enhanced(keyframes)

            # ç¬¬6æ­¥ï¼šåˆå¹¶æœ€ç»ˆè§†é¢‘
            final_video = await self._merge_final_video(video_clips, request.output_path)

            return {
                "success": True,
                "video_path": final_video,
                "duration_seconds": request.duration_seconds,
                "segments_count": len(video_clips),
                "keyframes_count": len(keyframes),
                "validation_passed": validation_result.get("passed", True) if self.vl_validation_enabled else True,
                "storyboard_plan": storyboard_plan
            }

        except Exception as e:
            print(f"âŒ å¢å¼ºè§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    async def _preprocess_segments(self, request: VideoStoryboardRequest) -> List[Dict]:
        """
        ç¬¬1æ­¥ï¼šé¢„å¤„ç†æ®µè½ - è½¬åœºæ£€æµ‹

        "å¦‚æœåˆ†é•œè½¬åœºå¾ˆå¤§ï¼Œæ¶‰åŠåˆ°é•œå¤´åˆ‡æ¢ï¼Œå»ºè®®åœ¨çŸ­æ®µè½åˆ’åˆ†å¤„å°±è§£å†³"
        """

        print("\n[ç¬¬1æ­¥] ğŸ” é¢„å¤„ç†æ®µè½å’Œè½¬åœºæ£€æµ‹...")

        raw_segments = self._parse_text_to_segments(request.text_description)

        # æ£€æµ‹æ¯ä¸ªæ®µè½é—´çš„è½¬åœºå¼ºåº¦
        enhanced_segments = []

        for i, segment in enumerate(raw_segments):
            enhanced_segment = {**segment}

            if i > 0:
                # æ£€æµ‹ä¸å‰ä¸€æ®µçš„è½¬åœºå¼ºåº¦
                prev_segment = raw_segments[i-1]
                transition_intensity = self._calculate_transition_intensity(
                    prev_segment["description"],
                    segment["description"]
                )

                enhanced_segment["transition_intensity"] = transition_intensity
                enhanced_segment["needs_hard_cut"] = transition_intensity > 0.7

                if enhanced_segment["needs_hard_cut"]:
                    print(f"  ğŸ¬ æ£€æµ‹åˆ°å¼ºè½¬åœº: æ®µ{i-1} â†’ æ®µ{i}")
            else:
                enhanced_segment["transition_intensity"] = 0.0
                enhanced_segment["needs_hard_cut"] = False

            enhanced_segments.append(enhanced_segment)

        return enhanced_segments

    def _calculate_transition_intensity(self, desc1: str, desc2: str) -> float:
        """è®¡ç®—è½¬åœºå¼ºåº¦"""

        # å¼ºè½¬åœºæŒ‡ç¤ºè¯
        strong_transition_words = [
            "åˆ‡æ¢åˆ°", "è½¬åœºåˆ°", "åœºæ™¯å˜åŒ–", "ä½ç½®æ”¹å˜", "æ—¶é—´è·³è·ƒ",
            "cut to", "switch to", "transition to", "move to", "jump to",
            "different", "another", "new location", "elsewhere"
        ]

        # åœºæ™¯ç±»åˆ«è¯
        scene_categories = {
            "å®¤å†…": ["indoor", "inside", "room", "office", "home", "å®¤å†…"],
            "æˆ·å¤–": ["outdoor", "outside", "street", "park", "æˆ·å¤–"],
            "å·¥ä½œ": ["work", "office", "meeting", "business", "å·¥ä½œ"],
            "ç”Ÿæ´»": ["home", "personal", "life", "daily", "ç”Ÿæ´»"],
            "è¿åŠ¨": ["sport", "gym", "exercise", "fitness", "è¿åŠ¨"]
        }

        # æ£€æŸ¥å¼ºè½¬åœºè¯
        desc1_lower = desc1.lower()
        desc2_lower = desc2.lower()

        for word in strong_transition_words:
            if word in desc1_lower or word in desc2_lower:
                return 0.9

        # æ£€æŸ¥åœºæ™¯ç±»åˆ«å˜åŒ–
        desc1_categories = set()
        desc2_categories = set()

        for category, keywords in scene_categories.items():
            if any(kw in desc1_lower for kw in keywords):
                desc1_categories.add(category)
            if any(kw in desc2_lower for kw in keywords):
                desc2_categories.add(category)

        if desc1_categories and desc2_categories:
            if not desc1_categories.intersection(desc2_categories):
                return 0.8  # å®Œå…¨ä¸åŒçš„åœºæ™¯ç±»åˆ«

        # è¯æ±‡ç›¸ä¼¼åº¦ï¼ˆç®€å•å®ç°ï¼‰
        words1 = set(desc1_lower.split())
        words2 = set(desc2_lower.split())

        if len(words1) == 0 or len(words2) == 0:
            return 0.5

        intersection = words1.intersection(words2)
        union = words1.union(words2)

        similarity = len(intersection) / len(union)

        # è½¬åœºå¼ºåº¦ = 1 - ç›¸ä¼¼åº¦
        return 1.0 - similarity

    async def _optimize_storyboard_enhanced(self,
                                          request: VideoStoryboardRequest,
                                          preprocessed_segments: List[Dict]) -> Dict:
        """ç¬¬2æ­¥ï¼šå¢å¼ºçš„VGPä¼˜åŒ–"""

        print("\n[ç¬¬2æ­¥] ğŸ“‹ å¢å¼ºVGPä¼˜åŒ–...")

        # è°ƒç”¨VGPä¼˜åŒ–ï¼Œä½†ä¼ å…¥é¢„å¤„ç†çš„æ®µè½ä¿¡æ¯
        optimization_result = await self.vgp_optimization_node.optimize_storyboard_sequence(
            raw_segments=preprocessed_segments,
            product_info=request.product_info,
            total_duration_ms=request.duration_seconds * 1000
        )

        # æ ¹æ®è½¬åœºå¼ºåº¦è°ƒæ•´ç”Ÿæˆç­–ç•¥
        frames = optimization_result['optimized_frames']

        for i, frame in enumerate(frames):
            if hasattr(frame, 'segment_id') and frame.segment_id < len(preprocessed_segments):
                segment_info = preprocessed_segments[frame.segment_id]

                if segment_info.get("needs_hard_cut", False):
                    # å¼ºåˆ¶ä½¿ç”¨ç‹¬ç«‹ç”Ÿæˆï¼Œä¸å¤ç”¨
                    frame.force_independent = True

        optimization_result['optimized_frames'] = frames

        return optimization_result

    async def _generate_keyframes_with_priority(self, storyboard_plan: Dict) -> List[Dict]:
        """
        ç¬¬3æ­¥ï¼šæ™ºèƒ½å›¾åƒç”Ÿæˆç­–ç•¥

        "ä¼˜å…ˆæ€§æ˜¯åˆ¤æ–­æ˜¯å¦ä¸ºåŒä¸€ç‰©ä½“ï¼Œè‹¥æ˜¯åŒä¸€ç‰©ä½“åˆ™å¯ç›´æ¥ä½¿ç”¨å›¾ç”Ÿå›¾ï¼Œ
        è‹¥ä¸æ˜¯è€Œç”»é¢ä¸­æœ‰äº§å“åˆ™ä½¿ç”¨åŸäº§å“å›¾è¿›è¡Œå›¾ç”Ÿå›¾"
        """

        print("\n[ç¬¬3æ­¥] ğŸ¨ æ™ºèƒ½å›¾åƒç”Ÿæˆç­–ç•¥...")

        optimized_frames = storyboard_plan['optimized_frames']

        # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
        frame_groups = self._group_frames_by_priority(optimized_frames)

        generated_keyframes = []

        # ä¼˜å…ˆçº§1: äº§å“å¸§ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if "product_frames" in frame_groups:
            print("  ğŸ¥‡ ä¼˜å…ˆçº§1: ç”Ÿæˆäº§å“å¸§...")
            product_keyframes = await self._generate_product_frames(frame_groups["product_frames"])
            generated_keyframes.extend(product_keyframes)

        # ä¼˜å…ˆçº§2: åŒä¸€ç‰©ä½“çš„è¿ç»­å¸§ï¼ˆå›¾ç”Ÿå›¾ï¼‰
        if "same_object_frames" in frame_groups:
            print("  ğŸ¥ˆ ä¼˜å…ˆçº§2: åŒä¸€ç‰©ä½“å›¾ç”Ÿå›¾...")
            object_keyframes = await self._generate_same_object_frames(
                frame_groups["same_object_frames"],
                generated_keyframes
            )
            generated_keyframes.extend(object_keyframes)

        # ä¼˜å…ˆçº§3: åœºæ™¯è¿ç»­å¸§
        if "scene_continuous_frames" in frame_groups:
            print("  ğŸ¥‰ ä¼˜å…ˆçº§3: åœºæ™¯è¿ç»­å¸§...")
            scene_keyframes = await self._generate_scene_continuous_frames(
                frame_groups["scene_continuous_frames"],
                generated_keyframes
            )
            generated_keyframes.extend(scene_keyframes)

        # ä¼˜å…ˆçº§4: ç‹¬ç«‹å¸§ï¼ˆæ–‡ç”Ÿå›¾ï¼‰
        if "independent_frames" in frame_groups:
            print("  ğŸ†• ä¼˜å…ˆçº§4: ç‹¬ç«‹ç”Ÿæˆå¸§...")
            independent_keyframes = await self._generate_independent_frames(
                frame_groups["independent_frames"]
            )
            generated_keyframes.extend(independent_keyframes)

        # å¤„ç†å¸§å¤ç”¨é€»è¾‘ï¼ˆè€ƒè™‘å¼ºè½¬åœºï¼‰
        processed_keyframes = self._apply_enhanced_frame_reuse(generated_keyframes, optimized_frames)

        return processed_keyframes

    def _group_frames_by_priority(self, frames: List) -> Dict[str, List]:
        """æŒ‰ä¼˜å…ˆçº§åˆ†ç»„å¸§"""

        groups = {
            "product_frames": [],
            "same_object_frames": [],
            "scene_continuous_frames": [],
            "independent_frames": []
        }

        for i, frame in enumerate(frames):
            # æ£€æŸ¥æ˜¯å¦åŒ…å«äº§å“
            if self._frame_contains_product(frame):
                groups["product_frames"].append(frame)
            # æ£€æŸ¥æ˜¯å¦ä¸å‰ä¸€å¸§æ˜¯åŒä¸€ç‰©ä½“
            elif i > 0 and self._is_same_object(frames[i-1], frame):
                groups["same_object_frames"].append(frame)
            # æ£€æŸ¥æ˜¯å¦åœºæ™¯è¿ç»­
            elif i > 0 and self._is_scene_continuous(frames[i-1], frame):
                groups["scene_continuous_frames"].append(frame)
            else:
                groups["independent_frames"].append(frame)

        return groups

    def _frame_contains_product(self, frame) -> bool:
        """æ£€æŸ¥å¸§æ˜¯å¦åŒ…å«äº§å“"""
        description = getattr(frame, 'description', '').lower()
        product_keywords = [
            'product', 'watch', 'smartwatch', 'device', 'gadget',
            'äº§å“', 'æ‰‹è¡¨', 'è®¾å¤‡'
        ]
        return any(keyword in description for keyword in product_keywords)

    def _is_same_object(self, frame1, frame2) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºåŒä¸€ç‰©ä½“"""

        # æå–ç‰©ä½“å…³é”®è¯
        object_keywords = [
            'watch', 'phone', 'computer', 'product', 'device',
            'person', 'man', 'woman', 'user',
            'æ‰‹è¡¨', 'æ‰‹æœº', 'ç”µè„‘', 'äº§å“', 'äººç‰©'
        ]

        desc1 = getattr(frame1, 'description', '').lower()
        desc2 = getattr(frame2, 'description', '').lower()

        # æ‰¾å‡ºä¸¤å¸§ä¸­çš„ç‰©ä½“
        objects1 = [kw for kw in object_keywords if kw in desc1]
        objects2 = [kw for kw in object_keywords if kw in desc2]

        # æ£€æŸ¥æ˜¯å¦æœ‰å…±åŒç‰©ä½“
        return bool(set(objects1).intersection(set(objects2)))

    def _is_scene_continuous(self, frame1, frame2) -> bool:
        """åˆ¤æ–­åœºæ™¯æ˜¯å¦è¿ç»­"""

        # åœºæ™¯å…³é”®è¯
        scene_keywords = [
            'office', 'home', 'studio', 'gym', 'park', 'street',
            'åŠå…¬å®¤', 'å®¶é‡Œ', 'å·¥ä½œå®¤', 'å¥èº«æˆ¿', 'å…¬å›­'
        ]

        desc1 = getattr(frame1, 'description', '').lower()
        desc2 = getattr(frame2, 'description', '').lower()

        scenes1 = [kw for kw in scene_keywords if kw in desc1]
        scenes2 = [kw for kw in scene_keywords if kw in desc2]

        return bool(set(scenes1).intersection(set(scenes2)))

    async def _generate_product_frames(self, frames: List) -> List[Dict]:
        """ç”Ÿæˆäº§å“å¸§ï¼ˆä½¿ç”¨äº§å“å‚è€ƒå›¾ï¼‰"""

        keyframes = []

        for frame in frames:
            # ä½¿ç”¨äº§å“å¼•å¯¼ç”Ÿæˆ
            image_result = await self.image_generation_node.generate_single_image(
                prompt=self._build_product_prompt(frame),
                style="product_photography",
                quality="high",
                provider="dalle"
            )

            if image_result:
                keyframes.append({
                    "frame_id": frame.frame_id,
                    "segment_id": frame.segment_id,
                    "image_path": image_result.image_path,
                    "generation_mode": "product_guided",
                    "is_reused": False,
                    "priority": "product"
                })

        return keyframes

    async def _generate_same_object_frames(self, frames: List, existing_keyframes: List) -> List[Dict]:
        """ç”ŸæˆåŒä¸€ç‰©ä½“å¸§ï¼ˆå›¾ç”Ÿå›¾ï¼‰"""

        keyframes = []

        for frame in frames:
            # æ‰¾åˆ°å‚è€ƒå¸§
            reference_frame = self._find_reference_frame(frame, existing_keyframes)

            if reference_frame:
                # ä½¿ç”¨å›¾ç”Ÿå›¾
                image_result = await self._img2img_generate(frame, reference_frame["image_path"])
            else:
                # é™çº§åˆ°æ–‡ç”Ÿå›¾
                image_result = await self.image_generation_node.generate_single_image(
                    prompt=self._build_frame_prompt(frame),
                    style="realistic",
                    quality="high"
                )

            if image_result:
                keyframes.append({
                    "frame_id": frame.frame_id,
                    "segment_id": frame.segment_id,
                    "image_path": image_result.image_path if hasattr(image_result, 'image_path') else image_result,
                    "generation_mode": "img2img" if reference_frame else "txt2img",
                    "is_reused": False,
                    "priority": "same_object"
                })

        return keyframes

    async def _generate_scene_continuous_frames(self, frames: List, existing_keyframes: List) -> List[Dict]:
        """ç”Ÿæˆåœºæ™¯è¿ç»­å¸§"""

        keyframes = []

        for frame in frames:
            reference_frame = self._find_scene_reference(frame, existing_keyframes)

            if reference_frame:
                image_result = await self._img2img_generate(frame, reference_frame["image_path"])
            else:
                image_result = await self.image_generation_node.generate_single_image(
                    prompt=self._build_frame_prompt(frame),
                    style="realistic",
                    quality="high"
                )

            if image_result:
                keyframes.append({
                    "frame_id": frame.frame_id,
                    "segment_id": frame.segment_id,
                    "image_path": image_result.image_path if hasattr(image_result, 'image_path') else image_result,
                    "generation_mode": "img2img" if reference_frame else "txt2img",
                    "is_reused": False,
                    "priority": "scene_continuous"
                })

        return keyframes

    async def _generate_independent_frames(self, frames: List) -> List[Dict]:
        """ç”Ÿæˆç‹¬ç«‹å¸§ï¼ˆæ–‡ç”Ÿå›¾ï¼‰"""

        keyframes = []

        for frame in frames:
            image_result = await self.image_generation_node.generate_single_image(
                prompt=self._build_frame_prompt(frame),
                style="realistic",
                quality="high"
            )

            if image_result:
                keyframes.append({
                    "frame_id": frame.frame_id,
                    "segment_id": frame.segment_id,
                    "image_path": image_result.image_path,
                    "generation_mode": "txt2img",
                    "is_reused": False,
                    "priority": "independent"
                })

        return keyframes

    def _apply_enhanced_frame_reuse(self, keyframes: List[Dict], original_frames: List) -> List[Dict]:
        """å¢å¼ºçš„å¸§å¤ç”¨é€»è¾‘ï¼ˆè€ƒè™‘å¼ºè½¬åœºï¼‰"""

        processed = []

        for i, keyframe in enumerate(keyframes):
            processed.append(keyframe)

            # æ£€æŸ¥å¯¹åº”çš„åŸå§‹å¸§æ˜¯å¦è¦æ±‚å¼ºåˆ¶ç‹¬ç«‹
            original_frame = next((f for f in original_frames
                                 if f.frame_id == keyframe["frame_id"]), None)

            if original_frame and getattr(original_frame, 'force_independent', False):
                # å¼ºè½¬åœºï¼Œä¸å¤ç”¨
                continue

            # æ­£å¸¸çš„å¤ç”¨é€»è¾‘...
            # (ä½¿ç”¨ä¹‹å‰å®ç°çš„é€»è¾‘)

        return processed

    async def _vl_validate_keyframes(self, keyframes: List[Dict]) -> Dict[str, Any]:
        """
        ç¬¬4æ­¥ï¼šVLè§†è§‰éªŒè¯

        "ä½¿ç”¨vlè¿›è¡Œæ£€æŸ¥æ—¶ä¹Ÿä¸€æ ·ï¼Œé‡ç‚¹ä»å›¾ç‰‡å«ä¹‰è§’åº¦æ¥çœ‹æ˜¯å¦æ»¡è¶³ï¼Œæ˜¯å¦æœ‰å¼‚å¸¸ç‚¹"
        """

        print("\n[ç¬¬4æ­¥] ğŸ‘ï¸ VLè§†è§‰éªŒè¯...")

        validation_results = {
            "passed": True,
            "total_frames": len(keyframes),
            "passed_frames": 0,
            "failed_frames": [],
            "issues": []
        }

        for keyframe in keyframes:
            if keyframe.get("image_path"):
                # è°ƒç”¨VLæ¨¡å‹éªŒè¯
                vl_result = await self._vl_validate_single_frame(keyframe)

                if vl_result["passed"]:
                    validation_results["passed_frames"] += 1
                else:
                    validation_results["failed_frames"].append({
                        "frame_id": keyframe["frame_id"],
                        "issues": vl_result["issues"]
                    })
                    validation_results["issues"].extend(vl_result["issues"])

        # æ•´ä½“é€šè¿‡ç‡
        pass_rate = validation_results["passed_frames"] / validation_results["total_frames"]
        validation_results["passed"] = pass_rate >= 0.8  # 80%é€šè¿‡ç‡
        validation_results["pass_rate"] = pass_rate

        print(f"  ğŸ“Š éªŒè¯ç»“æœ: {validation_results['passed_frames']}/{validation_results['total_frames']} é€šè¿‡ ({pass_rate:.1%})")

        if not validation_results["passed"]:
            print(f"  âš ï¸ å‘ç° {len(validation_results['failed_frames'])} ä¸ªé—®é¢˜å¸§")

        return validation_results

    async def _vl_validate_single_frame(self, keyframe: Dict) -> Dict:
        """VLéªŒè¯å•å¸§"""

        # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„VLæ¨¡å‹
        # æš‚æ—¶æ¨¡æ‹ŸéªŒè¯é€»è¾‘

        issues = []

        # æ¨¡æ‹Ÿæ£€æŸ¥äº§å“ä¸€è‡´æ€§
        if keyframe.get("priority") == "product":
            # äº§å“å¸§éœ€è¦ä¸¥æ ¼éªŒè¯
            if "product" not in keyframe.get("frame_id", ""):
                issues.append("äº§å“æ˜¾ç¤ºä¸æ¸…æ™°")

        # æ¨¡æ‹Ÿæ£€æŸ¥å›¾åƒè´¨é‡
        # å®é™…åº”è¯¥æ£€æŸ¥æ¨¡ç³Šã€å¤±çœŸã€å¼‚å¸¸å…ƒç´ ç­‰

        return {
            "passed": len(issues) == 0,
            "issues": issues,
            "confidence": 0.9 if len(issues) == 0 else 0.3
        }

    async def _regenerate_failed_frames(self, keyframes: List[Dict], validation_result: Dict) -> List[Dict]:
        """é‡æ–°ç”Ÿæˆå¤±è´¥çš„å¸§"""

        print("  ğŸ”„ é‡æ–°ç”Ÿæˆå¤±è´¥å¸§...")

        for failed_frame in validation_result["failed_frames"]:
            frame_id = failed_frame["frame_id"]

            # æ‰¾åˆ°å¤±è´¥çš„å¸§
            for i, keyframe in enumerate(keyframes):
                if keyframe["frame_id"] == frame_id:
                    # é‡æ–°ç”Ÿæˆ
                    print(f"    é‡æ–°ç”Ÿæˆå¸§: {frame_id}")
                    # è¿™é‡Œåº”è¯¥å®ç°é‡æ–°ç”Ÿæˆé€»è¾‘
                    break

        return keyframes

    async def _generate_video_clips_enhanced(self, keyframes: List[Dict]) -> List[str]:
        """
        ç¬¬5æ­¥ï¼šæ™ºèƒ½è§†é¢‘ç”Ÿæˆï¼ˆä¸¤ç§æ¨¡å¼ï¼‰

        "æ ¹æ®è¿ç»­æ€§æ˜¯å¦è¦é¦–å°¾å¸§ç”Ÿæˆè¿˜æ˜¯ä»…é¦–å¸§ç”Ÿæˆåˆ†åˆ«ä½¿ç”¨é¦–å°¾å¸§ç”Ÿæˆï¼ˆä¸¤ç§è§†é¢‘ç”Ÿæˆæ–¹å¼ï¼‰"
        """

        print("\n[ç¬¬5æ­¥] ğŸ¥ æ™ºèƒ½è§†é¢‘ç”Ÿæˆï¼ˆä¸¤ç§æ¨¡å¼ï¼‰...")

        # åˆ†ææ¯ä¸ªç‰‡æ®µçš„ç”Ÿæˆæ¨¡å¼
        video_clips = []

        # æŒ‰æ®µè½é…å¯¹å¸§
        segments = self._group_keyframes_by_segment(keyframes)

        for segment_id, segment_frames in segments.items():
            if len(segment_frames) >= 2:
                start_frame = segment_frames[0]
                end_frame = segment_frames[1]

                # åˆ¤æ–­ä½¿ç”¨å“ªç§ç”Ÿæˆæ¨¡å¼
                generation_mode = self._determine_video_generation_mode(start_frame, end_frame)

                if generation_mode == "first_last_frame":
                    # é¦–å°¾å¸§ç”Ÿæˆï¼ˆ5ç§’è§†é¢‘ï¼‰
                    clip_path = await self._generate_first_last_video(start_frame, end_frame, segment_id)
                else:
                    # ä»…é¦–å¸§ç”Ÿæˆï¼ˆæ‰©å±•ç”Ÿæˆï¼‰
                    clip_path = await self._generate_first_frame_only_video(start_frame, segment_id)

                if clip_path:
                    video_clips.append(clip_path)
                    print(f"  âœ… ç”Ÿæˆç‰‡æ®µ{segment_id}: {generation_mode}")

        return video_clips

    def _determine_video_generation_mode(self, start_frame: Dict, end_frame: Dict) -> str:
        """åˆ¤æ–­è§†é¢‘ç”Ÿæˆæ¨¡å¼"""

        # å¦‚æœå°¾å¸§æ˜¯å¤ç”¨çš„ï¼Œä½¿ç”¨ä»…é¦–å¸§æ¨¡å¼
        if end_frame.get("is_reused", False):
            return "first_frame_only"

        # å¦‚æœé¦–å°¾å¸§å·®å¼‚å¾ˆå¤§ï¼Œä½¿ç”¨é¦–å°¾å¸§æ¨¡å¼
        start_prompt = start_frame.get("prompt", "")
        end_prompt = end_frame.get("prompt", "")

        if self._calculate_prompt_similarity(start_prompt, end_prompt) < 0.5:
            return "first_last_frame"

        # é»˜è®¤ä½¿ç”¨é¦–å°¾å¸§æ¨¡å¼
        return "first_last_frame"

    async def _generate_first_last_video(self, start_frame: Dict, end_frame: Dict, segment_id: int) -> str:
        """é¦–å°¾å¸§ç”Ÿæˆ5ç§’è§†é¢‘"""
        return await self.video_processor.generate_video_from_frames(
            start_frame["image_path"],
            end_frame["image_path"],
            duration_seconds=5.0
        )

    async def _generate_first_frame_only_video(self, start_frame: Dict, segment_id: int) -> str:
        """ä»…é¦–å¸§ç”Ÿæˆè§†é¢‘ï¼ˆéœ€è¦å®ç°æ‰©å±•ç”Ÿæˆï¼‰"""
        # è¿™é‡Œéœ€è¦è°ƒç”¨æ”¯æŒå•å¸§æ‰©å±•çš„API
        # æš‚æ—¶ä½¿ç”¨é¦–å¸§ä½œä¸ºé¦–å°¾å¸§
        return await self.video_processor.generate_video_from_frames(
            start_frame["image_path"],
            start_frame["image_path"],  # ä½¿ç”¨åŒä¸€å¸§
            duration_seconds=5.0
        )

    # è¾…åŠ©æ–¹æ³•
    def _build_product_prompt(self, frame) -> str:
        """æ„å»ºäº§å“æç¤ºè¯"""
        base_prompt = getattr(frame, 'description', '')
        return f"product photography, {base_prompt}, high quality, professional lighting"

    def _build_frame_prompt(self, frame) -> str:
        """æ„å»ºæ™®é€šå¸§æç¤ºè¯"""
        return getattr(frame, 'description', '')

    def _find_reference_frame(self, frame, existing_keyframes: List) -> Optional[Dict]:
        """æ‰¾åˆ°å‚è€ƒå¸§"""
        # ç®€åŒ–å®ç°ï¼šæ‰¾åˆ°æœ€è¿‘çš„åŒç±»å‹å¸§
        for kf in reversed(existing_keyframes):
            if kf.get("priority") == "product" and self._frame_contains_product(frame):
                return kf
        return None

    def _find_scene_reference(self, frame, existing_keyframes: List) -> Optional[Dict]:
        """æ‰¾åˆ°åœºæ™¯å‚è€ƒå¸§"""
        # ç®€åŒ–å®ç°
        return existing_keyframes[-1] if existing_keyframes else None

    async def _img2img_generate(self, frame, reference_image_path: str) -> str:
        """å›¾ç”Ÿå›¾ç”Ÿæˆ"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„img2img API
        # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿè·¯å¾„
        return f"/tmp/img2img_{frame.frame_id}.png"

    def _group_keyframes_by_segment(self, keyframes: List[Dict]) -> Dict[int, List[Dict]]:
        """æŒ‰æ®µè½åˆ†ç»„å…³é”®å¸§"""
        segments = {}
        for kf in keyframes:
            seg_id = kf["segment_id"]
            if seg_id not in segments:
                segments[seg_id] = []
            segments[seg_id].append(kf)
        return segments

    def _calculate_prompt_similarity(self, prompt1: str, prompt2: str) -> float:
        """è®¡ç®—æç¤ºè¯ç›¸ä¼¼åº¦"""
        words1 = set(prompt1.lower().split())
        words2 = set(prompt2.lower().split())

        if not words1 or not words2:
            return 0.0

        intersection = words1.intersection(words2)
        union = words1.union(words2)

        return len(intersection) / len(union)


# ä½¿ç”¨ç¤ºä¾‹
async def enhanced_demo():
    """å¢å¼ºç‰ˆæ¼”ç¤º"""

    config = {
        "qwen_api_key": "your_qwen_key",
        "openai_api_key": "your_openai_key",
        "work_dir": "/tmp/enhanced_video",
        "vl_validation": True,
        "era_preference": "modern"
    }

    orchestrator = EnhancedVideoOrchestrator(config)

    request = VideoStoryboardRequest(
        text_description="""
        åŠå…¬å®¤åœºæ™¯ï¼šå±•ç¤ºæ™ºèƒ½æ‰‹è¡¨çš„æ•´ä½“å¤–è§‚ã€‚
        ç‰¹å†™é•œå¤´ï¼šèšç„¦è¡¨ç›˜æ˜¾ç¤ºç•Œé¢ã€‚
        åˆ‡æ¢åˆ°æˆ·å¤–ï¼šç”¨æˆ·è·‘æ­¥æ—¶çš„è¿åŠ¨è¿½è¸ªã€‚
        å›åˆ°å®¤å†…ï¼šå……ç”µåœºæ™¯å±•ç¤ºã€‚
        """,
        duration_seconds=20,
        product_info={
            "name": "SmartWatch Pro",
            "constraints": ["ä¿æŒäº§å“ä¸€è‡´æ€§"],
            "reference_images": ["product.jpg"]
        }
    )

    result = await orchestrator.process_video_request(request)

    print(f"\nğŸ‰ å¢å¼ºç‰ˆç”Ÿæˆ{'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}!")
    if result["success"]:
        print(f"ğŸ“ è§†é¢‘: {result['video_path']}")
        print(f"âœ… VLéªŒè¯: {'é€šè¿‡' if result['validation_passed'] else 'å¤±è´¥'}")

if __name__ == "__main__":
    asyncio.run(enhanced_demo())