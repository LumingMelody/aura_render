"""
éŸ³é¢‘TTSé›†æˆ - å°†å­—å¹•è½¬æ¢ä¸ºè¯­éŸ³å¹¶æ·»åŠ åˆ°è§†é¢‘

è¿™ä¸ªæ¨¡å—æä¾›äº†å°†subtitle_sequenceè½¬æ¢ä¸ºTTSéŸ³é¢‘çš„åŠŸèƒ½ï¼Œ
å¯ä»¥ç›´æ¥é›†æˆåˆ°IMS timelineçš„AudioTracksä¸­
"""

import asyncio
import logging
from typing import Dict, List, Optional

# ä½¿ç”¨é¡¹ç›®æ—¥å¿—ç³»ç»Ÿ
try:
    from utils.logger import get_logger, LogCategory
    logger = get_logger("audio_tts_integration").with_context(category=LogCategory.SYSTEM)
except ImportError:
    logger = logging.getLogger(__name__)


async def generate_tts_audio_track(
    subtitle_sequence: Dict,
    voice: str = "Cherry",  # âœ… ä½¿ç”¨é˜¿é‡Œäº‘Qwen3-TTSæ”¯æŒçš„éŸ³è‰²ï¼ˆèŠŠæ‚¦-å¥³å£°ï¼‰
    speed: float = 1.0,
    upload_to_oss: bool = True,
    use_segmented: bool = True  # âœ¨ æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨åˆ†æ®µç”Ÿæˆï¼ˆæ¨èTrueï¼Œå®ç°éŸ³ç”»åŒæ­¥ï¼‰
) -> Optional[Dict]:
    """
    æ ¹æ®å­—å¹•åºåˆ—ç”ŸæˆTTSéŸ³é¢‘è½¨é“

    Args:
        subtitle_sequence: subtitle_nodeç”Ÿæˆçš„å­—å¹•åºåˆ—
        voice: åƒé—®TTSéŸ³è‰²
        speed: è¯­é€Ÿ
        upload_to_oss: æ˜¯å¦ä¸Šä¼ åˆ°OSSï¼ˆæ¨èTrueï¼Œè·å–æ°¸ä¹…URLï¼‰
        use_segmented: æ˜¯å¦ä½¿ç”¨åˆ†æ®µç”Ÿæˆï¼ˆTrue=æ¯ä¸ªå­—å¹•ç‹¬ç«‹ç”ŸæˆéŸ³é¢‘ï¼Œå®ç°ç²¾ç¡®åŒæ­¥ï¼‰

    Returns:
        éŸ³é¢‘è½¨é“ä¿¡æ¯ï¼Œæ ¼å¼ï¼š
        {
            "audio_clips": [  # éŸ³é¢‘ç‰‡æ®µåˆ—è¡¨ï¼ˆåˆ†æ®µæ¨¡å¼ï¼‰
                {
                    "audio_url": "https://...",
                    "timeline_in": 0.0,
                    "timeline_out": 3.0,
                    "text": "æ¬¢è¿æ¥åˆ°"
                },
                ...
            ],
            "total_duration": 10.5,
            "mode": "segmented" | "merged"
        }
        æˆ–ï¼ˆæ—§æ ¼å¼ï¼Œå‘åå…¼å®¹ï¼‰ï¼š
        {
            "audio_url": "https://...",  # åˆå¹¶æ¨¡å¼
            "duration": 10.5
        }

    Example:
        >>> subtitle_seq = {
        ...     "clips": [
        ...         {"start": 0.0, "end": 3.0, "text": "æ¬¢è¿æ¥åˆ°"},
        ...         {"start": 3.0, "end": 6.0, "text": "æœºå™¨å­¦ä¹ çš„ä¸–ç•Œ"}
        ...     ]
        ... }
        >>> audio_track = await generate_tts_audio_track(subtitle_seq, use_segmented=True)
        >>> print(f"ç”Ÿæˆäº† {len(audio_track['audio_clips'])} ä¸ªéŸ³é¢‘ç‰‡æ®µ")
    """
    try:
        from core.cliptemplate.qwen import get_qwen_tts_generator

        if not subtitle_sequence or "clips" not in subtitle_sequence:
            logger.warning("âš ï¸ å­—å¹•åºåˆ—ä¸ºç©ºï¼Œè·³è¿‡TTSç”Ÿæˆ")
            return None

        clips = subtitle_sequence.get("clips", [])
        if not clips:
            logger.warning("âš ï¸ å­—å¹•åºåˆ—æ— æœ‰æ•ˆç‰‡æ®µ")
            return None

        logger.info(f"ğŸ¤ å¼€å§‹ç”ŸæˆTTSéŸ³é¢‘ï¼Œå…± {len(clips)} ä¸ªå­—å¹•ç‰‡æ®µ")
        logger.info(f"   æ¨¡å¼: {'åˆ†æ®µç”Ÿæˆï¼ˆç²¾ç¡®åŒæ­¥ï¼‰' if use_segmented else 'åˆå¹¶ç”Ÿæˆï¼ˆæ—§æ¨¡å¼ï¼‰'}")

        tts_generator = get_qwen_tts_generator()

        # ========== æ–¹æ¡ˆ1: åˆ†æ®µç”Ÿæˆï¼ˆæ¨èï¼‰ ==========
        if use_segmented:
            return await _generate_segmented_audio(
                clips,
                tts_generator,
                voice,
                speed,
                upload_to_oss
            )

        # ========== æ–¹æ¡ˆ2: åˆå¹¶ç”Ÿæˆï¼ˆæ—§é€»è¾‘ï¼Œä¿æŒå‘åå…¼å®¹ï¼‰ ==========
        else:
            return await _generate_merged_audio(
                clips,
                tts_generator,
                voice,
                speed,
                upload_to_oss
            )

    except Exception as e:
        logger.error(f"âŒ TTSéŸ³é¢‘ç”Ÿæˆå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return None


async def _generate_segmented_audio(
    clips: List[Dict],
    tts_generator,
    voice: str,
    speed: float,
    upload_to_oss: bool
) -> Dict:
    """
    åˆ†æ®µç”ŸæˆTTSéŸ³é¢‘ï¼ˆæ¯ä¸ªå­—å¹•ç‹¬ç«‹ç”Ÿæˆï¼‰

    ä¼˜ç‚¹ï¼šéŸ³ç”»å®Œç¾åŒæ­¥ï¼Œæ”¯æŒå­—å¹•é—´åœé¡¿
    """
    logger.info(f"ğŸ“Š åˆ†æ®µç”Ÿæˆæ¨¡å¼ï¼šå°†ä¸ºæ¯ä¸ªå­—å¹•ç‰‡æ®µç”Ÿæˆç‹¬ç«‹éŸ³é¢‘")

    audio_clips = []
    successful_count = 0
    failed_count = 0

    # å¹¶å‘æ§åˆ¶ï¼šåŒæ—¶æœ€å¤š3ä¸ªè¯·æ±‚ï¼Œé¿å…APIé™æµ
    semaphore = asyncio.Semaphore(3)

    async def generate_single_clip(clip_index: int, clip: Dict):
        """ç”Ÿæˆå•ä¸ªå­—å¹•çš„TTSéŸ³é¢‘"""
        nonlocal successful_count, failed_count

        async with semaphore:
            text = clip.get("text", "").strip()
            if not text:
                logger.warning(f"   âš ï¸ ç‰‡æ®µ {clip_index + 1} æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡")
                return None

            start_time = clip.get("start", 0.0)
            end_time = clip.get("end", start_time + clip.get("duration", 0.0))

            try:
                logger.info(f"   ğŸµ ç”Ÿæˆç‰‡æ®µ {clip_index + 1}/{len(clips)}: \"{text[:20]}...\" ({start_time:.1f}s - {end_time:.1f}s)")

                # è°ƒç”¨åƒé—®TTS
                audio_url = await tts_generator.generate_speech(
                    text=text,
                    voice=voice,
                    speed=speed,
                    upload_to_oss=upload_to_oss
                )

                if audio_url:
                    successful_count += 1
                    logger.info(f"      âœ… ç‰‡æ®µ {clip_index + 1} ç”ŸæˆæˆåŠŸ")
                    return {
                        "audio_url": audio_url,
                        "timeline_in": start_time,
                        "timeline_out": end_time,
                        "text": text,
                        "duration": end_time - start_time
                    }
                else:
                    failed_count += 1
                    logger.warning(f"      âŒ ç‰‡æ®µ {clip_index + 1} ç”Ÿæˆå¤±è´¥ï¼ˆAPIè¿”å›ç©ºï¼‰")
                    return None

            except Exception as e:
                failed_count += 1
                logger.error(f"      âŒ ç‰‡æ®µ {clip_index + 1} ç”Ÿæˆå¼‚å¸¸: {e}")
                return None

    # å¹¶å‘ç”Ÿæˆæ‰€æœ‰éŸ³é¢‘ç‰‡æ®µ
    tasks = [generate_single_clip(i, clip) for i, clip in enumerate(clips)]
    results = await asyncio.gather(*tasks)

    # è¿‡æ»¤æˆåŠŸçš„ç»“æœ
    audio_clips = [r for r in results if r is not None]

    # è®¡ç®—æ€»æ—¶é•¿
    total_duration = 0.0
    if clips:
        last_clip = clips[-1]
        total_duration = last_clip.get("end", last_clip.get("start", 0.0) + last_clip.get("duration", 0.0))

    logger.info(f"âœ… åˆ†æ®µç”Ÿæˆå®Œæˆ:")
    logger.info(f"   æˆåŠŸ: {successful_count}/{len(clips)} ä¸ªç‰‡æ®µ")
    logger.info(f"   å¤±è´¥: {failed_count}/{len(clips)} ä¸ªç‰‡æ®µ")
    logger.info(f"   æ€»æ—¶é•¿: {total_duration:.1f}ç§’")

    if not audio_clips:
        logger.error("âŒ æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µç”Ÿæˆå¤±è´¥")
        return None

    return {
        "audio_clips": audio_clips,
        "total_duration": total_duration,
        "mode": "segmented",
        "voice": voice,
        "speed": speed,
        "source": "qwen_tts"
    }


async def _generate_merged_audio(
    clips: List[Dict],
    tts_generator,
    voice: str,
    speed: float,
    upload_to_oss: bool
) -> Dict:
    """
    åˆå¹¶ç”ŸæˆTTSéŸ³é¢‘ï¼ˆæ—§é€»è¾‘ï¼Œä¿æŒå‘åå…¼å®¹ï¼‰

    ç¼ºç‚¹ï¼šéŸ³ç”»å¯èƒ½ä¸åŒæ­¥
    """
    # åˆå¹¶æ‰€æœ‰å­—å¹•æ–‡æœ¬ï¼ˆç®€å•æ–¹æ¡ˆï¼šä¸€æ¬¡æ€§åˆæˆæ•´æ®µè¯­éŸ³ï¼‰
    full_text = " ".join([clip.get("text", "") for clip in clips if clip.get("text")])

    if not full_text.strip():
        logger.warning("âš ï¸ å­—å¹•æ–‡æœ¬ä¸ºç©º")
        return None

    logger.info(f"ğŸ“ åˆå¹¶å­—å¹•æ–‡æœ¬: {full_text[:100]}...")
    logger.info(f"   æ€»é•¿åº¦: {len(full_text)} å­—ç¬¦")

    # è®¡ç®—è§†é¢‘æ€»æ—¶é•¿ï¼ˆä»å­—å¹•åºåˆ—ï¼‰
    total_duration = 0.0
    if clips:
        last_clip = clips[-1]
        total_duration = last_clip.get("end", last_clip.get("start", 0.0) + last_clip.get("duration", 0.0))

    # âœ¨ æ™ºèƒ½è°ƒæ•´è¯­é€Ÿï¼šæ ¹æ®æ–‡æœ¬é•¿åº¦å’Œè§†é¢‘æ—¶é•¿è‡ªåŠ¨è®¡ç®—åˆé€‚çš„è¯­é€Ÿ
    # æ­£å¸¸è¯­é€Ÿä¸‹ï¼Œä¸­æ–‡çº¦ä¸º 4-5 å­—ç¬¦/ç§’
    if speed == 1.0 and total_duration > 0:  # åªåœ¨é»˜è®¤è¯­é€Ÿæ—¶è‡ªåŠ¨è°ƒæ•´
        normal_chars_per_second = 4.5  # æ­£å¸¸è¯­é€Ÿï¼šæ¯ç§’çº¦4.5ä¸ªæ±‰å­—
        estimated_duration = len(full_text) / normal_chars_per_second

        # å¦‚æœé¢„ä¼°æ—¶é•¿ä¸è§†é¢‘æ—¶é•¿å·®è·è¾ƒå¤§ï¼Œè°ƒæ•´è¯­é€Ÿ
        if estimated_duration > 0:
            speed_ratio = estimated_duration / total_duration

            # è¯­é€ŸèŒƒå›´é™åˆ¶åœ¨ 0.5-2.0 ä¹‹é—´ï¼ˆé˜¿é‡Œäº‘TTSé™åˆ¶ï¼‰
            # å¦‚æœéŸ³é¢‘å¤ªçŸ­ï¼Œæ”¾æ…¢è¯­é€Ÿï¼ˆæœ€æ…¢0.6å€ï¼Œé¿å…å¤ªæ…¢ï¼‰
            # å¦‚æœéŸ³é¢‘å¤ªé•¿ï¼ŒåŠ å¿«è¯­é€Ÿï¼ˆæœ€å¿«1.5å€ï¼Œé¿å…å¤ªå¿«å¬ä¸æ¸…ï¼‰
            if speed_ratio < 1.0:  # éŸ³é¢‘ä¼šå¤ªçŸ­ï¼Œéœ€è¦æ”¾æ…¢
                speed = max(0.6, speed_ratio)
            elif speed_ratio > 1.0:  # éŸ³é¢‘ä¼šå¤ªé•¿ï¼Œéœ€è¦åŠ å¿«
                speed = min(1.5, speed_ratio)

            logger.info(f"ğŸ¯ æ™ºèƒ½è¯­é€Ÿè°ƒæ•´:")
            logger.info(f"   è§†é¢‘æ—¶é•¿: {total_duration:.1f}ç§’")
            logger.info(f"   æ–‡æœ¬é•¿åº¦: {len(full_text)}å­—ç¬¦")
            logger.info(f"   é¢„ä¼°æ—¶é•¿: {estimated_duration:.1f}ç§’ (æ­£å¸¸è¯­é€Ÿ)")
            logger.info(f"   è°ƒæ•´è¯­é€Ÿ: {speed:.2f}x (åŸå§‹: {speed_ratio:.2f}x)")

    # è°ƒç”¨åƒé—®TTSç”Ÿæˆè¯­éŸ³
    audio_url = await tts_generator.generate_speech(
        text=full_text,
        voice=voice,
        speed=speed,
        upload_to_oss=upload_to_oss
    )

    if not audio_url:
        logger.error("âŒ TTSéŸ³é¢‘ç”Ÿæˆå¤±è´¥")
        return None

    logger.info(f"âœ… TTSéŸ³é¢‘ç”ŸæˆæˆåŠŸ")
    logger.info(f"   éŸ³é¢‘URL: {audio_url}")
    logger.info(f"   è§†é¢‘æ—¶é•¿: {total_duration}ç§’")
    logger.info(f"   å®é™…è¯­é€Ÿ: {speed:.2f}x")

    return {
        "audio_url": audio_url,
        "duration": total_duration,
        "mode": "merged",
        "voice": voice,
        "speed": speed,
        "source": "qwen_tts"
    }


def build_ims_audio_tracks(audio_track_info: Dict) -> List[Dict]:
    """
    æ„å»ºIMS AudioTracksæ ¼å¼ï¼ˆæ”¯æŒåˆ†æ®µå’Œåˆå¹¶ä¸¤ç§æ¨¡å¼ï¼‰

    Args:
        audio_track_info: generate_tts_audio_trackè¿”å›çš„éŸ³é¢‘è½¨é“ä¿¡æ¯
            åˆ†æ®µæ¨¡å¼: {"audio_clips": [...], "mode": "segmented"}
            åˆå¹¶æ¨¡å¼: {"audio_url": "...", "mode": "merged"}

    Returns:
        IMS AudioTracksæ•°ç»„

    Example:
        >>> # åˆ†æ®µæ¨¡å¼ï¼ˆæ¨èï¼‰
        >>> audio_info = {
        ...     "audio_clips": [
        ...         {"audio_url": "https://...", "timeline_in": 0.0, "timeline_out": 3.0},
        ...         {"audio_url": "https://...", "timeline_in": 3.0, "timeline_out": 6.0}
        ...     ],
        ...     "mode": "segmented"
        ... }
        >>> audio_tracks = build_ims_audio_tracks(audio_info)
        >>>
        >>> # åˆå¹¶æ¨¡å¼ï¼ˆæ—§æ ¼å¼ï¼‰
        >>> audio_info = {"audio_url": "https://...", "duration": 10.5, "mode": "merged"}
        >>> audio_tracks = build_ims_audio_tracks(audio_info)
    """
    if not audio_track_info:
        return []

    mode = audio_track_info.get("mode", "merged")  # é»˜è®¤ä¸ºåˆå¹¶æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰

    # ========== åˆ†æ®µæ¨¡å¼ï¼šæ¯ä¸ªå­—å¹•å¯¹åº”ç‹¬ç«‹çš„éŸ³é¢‘ç‰‡æ®µ ==========
    if mode == "segmented" and "audio_clips" in audio_track_info:
        audio_clips = audio_track_info["audio_clips"]

        if not audio_clips:
            logger.warning("âš ï¸ åˆ†æ®µæ¨¡å¼ä¸‹audio_clipsä¸ºç©º")
            return []

        # æ„å»ºIMS AudioTrackClips
        ims_clips = []
        for clip in audio_clips:
            ims_clip = {
                "MediaURL": clip["audio_url"],
                "TimelineIn": round(clip["timeline_in"], 2),   # âœ¨ å…³é”®ï¼šè®¾ç½®éŸ³é¢‘å…¥ç‚¹
                "TimelineOut": round(clip["timeline_out"], 2)  # âœ¨ å…³é”®ï¼šè®¾ç½®éŸ³é¢‘å‡ºç‚¹
            }
            ims_clips.append(ims_clip)

        audio_tracks = [
            {
                "AudioTrackClips": ims_clips
            }
        ]

        logger.info(f"ğŸ“Š å·²æ„å»ºIMS AudioTracks (åˆ†æ®µæ¨¡å¼):")
        logger.info(f"   ç‰‡æ®µæ•°é‡: {len(ims_clips)}")
        logger.info(f"   æ—¶é—´èŒƒå›´: {ims_clips[0]['TimelineIn']:.1f}s - {ims_clips[-1]['TimelineOut']:.1f}s")
        return audio_tracks

    # ========== åˆå¹¶æ¨¡å¼ï¼šå•ä¸ªå®Œæ•´éŸ³é¢‘ï¼ˆæ—§é€»è¾‘ï¼Œå‘åå…¼å®¹ï¼‰ ==========
    elif "audio_url" in audio_track_info:
        audio_url = audio_track_info["audio_url"]

        audio_tracks = [
            {
                "AudioTrackClips": [
                    {
                        "MediaURL": audio_url
                        # ä¸è®¾ç½®TimelineIn/TimelineOutï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å¯¹é½åˆ°è§†é¢‘å¼€å¤´
                    }
                ]
            }
        ]

        logger.info(f"ğŸ“Š å·²æ„å»ºIMS AudioTracks (åˆå¹¶æ¨¡å¼): {audio_url[:80]}...")
        return audio_tracks

    else:
        logger.warning("âš ï¸ éŸ³é¢‘è½¨é“ä¿¡æ¯æ ¼å¼ä¸æ­£ç¡®ï¼Œç¼ºå°‘audio_clipsæˆ–audio_url")
        return []


async def integrate_tts_to_timeline(
    timeline: Dict,
    subtitle_sequence: Dict,
    voice: str = "Cherry",  # âœ… ä½¿ç”¨é˜¿é‡Œäº‘Qwen3-TTSæ”¯æŒçš„éŸ³è‰²ï¼ˆèŠŠæ‚¦-å¥³å£°ï¼‰
    speed: float = 1.0,
    upload_to_oss: bool = True,
    use_segmented: bool = True  # âœ¨ æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨åˆ†æ®µç”Ÿæˆï¼ˆæ¨èTrueï¼Œå®ç°éŸ³ç”»åŒæ­¥ï¼‰
) -> Dict:
    """
    ä¾¿æ·å‡½æ•°ï¼šç›´æ¥å°†TTSéŸ³é¢‘é›†æˆåˆ°IMS timeline

    Args:
        timeline: IMS timelineå­—å…¸ï¼ˆä¼šè¢«ä¿®æ”¹ï¼‰
        subtitle_sequence: å­—å¹•åºåˆ—
        voice: TTSéŸ³è‰²
        speed: è¯­é€Ÿ
        upload_to_oss: æ˜¯å¦ä¸Šä¼ åˆ°OSS
        use_segmented: æ˜¯å¦ä½¿ç”¨åˆ†æ®µç”Ÿæˆï¼ˆTrue=æ¯ä¸ªå­—å¹•ç‹¬ç«‹ç”ŸæˆéŸ³é¢‘ï¼Œå®ç°ç²¾ç¡®åŒæ­¥ï¼‰

    Returns:
        ä¿®æ”¹åçš„timelineï¼ˆåŸåœ°ä¿®æ”¹+è¿”å›ï¼‰

    Example:
        >>> timeline = {
        ...     "VideoTracks": [...],
        ...     "SubtitleTracks": [...]
        ... }
        >>> subtitle_seq = {...}
        >>> # æ¨èï¼šä½¿ç”¨åˆ†æ®µæ¨¡å¼å®ç°éŸ³ç”»åŒæ­¥
        >>> timeline = await integrate_tts_to_timeline(timeline, subtitle_seq, use_segmented=True)
        >>> # æˆ–è€…ï¼šä½¿ç”¨åˆå¹¶æ¨¡å¼ï¼ˆæ—§é€»è¾‘ï¼‰
        >>> timeline = await integrate_tts_to_timeline(timeline, subtitle_seq, use_segmented=False)
    """
    logger.info("ğŸµ å¼€å§‹é›†æˆTTSéŸ³é¢‘åˆ°timeline...")

    # ç”ŸæˆTTSéŸ³é¢‘
    audio_track_info = await generate_tts_audio_track(
        subtitle_sequence,
        voice=voice,
        speed=speed,
        upload_to_oss=upload_to_oss,
        use_segmented=use_segmented
    )

    if not audio_track_info:
        logger.warning("âš ï¸ TTSéŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡AudioTracks")
        return timeline

    # æ„å»ºAudioTracks
    audio_tracks = build_ims_audio_tracks(audio_track_info)

    if audio_tracks:
        timeline["AudioTracks"] = audio_tracks
        logger.info("âœ… AudioTrackså·²æ·»åŠ åˆ°timeline")
    else:
        logger.warning("âš ï¸ æœªèƒ½æ„å»ºAudioTracks")

    return timeline


# ========== ä½¿ç”¨ç¤ºä¾‹ ==========

async def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""

    # å‡è®¾ä»subtitle_nodeè·å–çš„å­—å¹•åºåˆ—
    subtitle_sequence = {
        "clips": [
            {"start": 0.0, "end": 3.0, "text": "æ¬¢è¿æ¥åˆ°"},
            {"start": 3.0, "end": 6.0, "text": "æœºå™¨å­¦ä¹ çš„ä¸–ç•Œ"},
            {"start": 6.0, "end": 10.0, "text": "è®©æˆ‘ä»¬å¼€å§‹æ¢ç´¢å§"}
        ]
    }

    # æ–¹æ¡ˆ1: å•ç‹¬ç”ŸæˆTTSéŸ³é¢‘
    audio_track_info = await generate_tts_audio_track(subtitle_sequence)
    if audio_track_info:
        print(f"éŸ³é¢‘URL: {audio_track_info['audio_url']}")

    # æ–¹æ¡ˆ2: ç›´æ¥é›†æˆåˆ°timeline
    timeline = {
        "VideoTracks": [{
            "VideoTrackClips": [
                {"MediaURL": "https://example.com/video1.mp4"}
            ]
        }],
        "SubtitleTracks": [...]
    }

    timeline = await integrate_tts_to_timeline(timeline, subtitle_sequence)
    print(f"Timeline: {timeline}")


if __name__ == "__main__":
    asyncio.run(example_usage())
