"""
ç»Ÿä¸€è§†é¢‘ç”ŸæˆAPI - /generate æ¥å£
æ”¯æŒå¤šç§è¾“å…¥æ–¹å¼ï¼šçº¯æ–‡æœ¬ã€å›¾ç‰‡ã€å›¾ç‰‡+æè¿°
"""
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, field
from pathlib import Path
import asyncio

from video_generate_protocol.nodes.enhanced_video_orchestrator import EnhancedVideoOrchestrator
from video_generate_protocol.nodes.image_to_video_orchestrator import ImageToVideoOrchestrator
from video_generate_protocol.nodes.image_description_to_video import ImageDescriptionToVideoOrchestrator


@dataclass
class UnifiedVideoGenerateRequest:
    """
    ç»Ÿä¸€çš„è§†é¢‘ç”Ÿæˆè¯·æ±‚ä½“

    æ”¯æŒä¸‰ç§æ¨¡å¼ï¼š
    1. çº¯æ–‡æœ¬æ¨¡å¼ï¼šåªæœ‰ text_description
    2. çº¯å›¾ç‰‡æ¨¡å¼ï¼šåªæœ‰ image_pathï¼ˆæˆ– imagesï¼‰
    3. å›¾ç‰‡+æè¿°æ¨¡å¼ï¼šimage_path + text_description
    """

    # è¾“å…¥å†…å®¹ï¼ˆè‡³å°‘éœ€è¦ä¸€ä¸ªï¼‰
    text_description: Optional[str] = None  # æ–‡æœ¬æè¿°
    image_path: Optional[str] = None  # å•å¼ å›¾ç‰‡è·¯å¾„
    images: Optional[List[str]] = None  # å¤šå¼ å›¾ç‰‡è·¯å¾„

    # è§†é¢‘å‚æ•°
    duration_seconds: int = 30  # è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰

    # VGPç³»ç»Ÿå¿…éœ€çš„IDå‚æ•°
    theme_id: Optional[str] = None  # ä¸»é¢˜ID
    keywords_id: Optional[str] = None  # å…³é”®è¯ID
    target_duration_id: Optional[str] = None  # ç›®æ ‡æ—¶é•¿ID
    user_description_id: Optional[str] = None  # ç”¨æˆ·æè¿°ID

    # å¯é€‰ï¼šåˆ†é•œæè¿°ï¼ˆé…åˆimagesä½¿ç”¨ï¼‰
    storyboard_descriptions: Optional[List[str]] = None

    # äº§å“ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    product_info: Optional[Dict[str, Any]] = None

    # ç”Ÿæˆé…ç½®
    generation_config: Dict[str, Any] = field(default_factory=lambda: {
        "style": "realistic",
        "quality": "high",
        "motion_intensity": "medium",
        "transition_type": "smooth"
    })

    # é«˜çº§é€‰é¡¹
    auto_detect_mode: bool = True  # è‡ªåŠ¨æ£€æµ‹æœ€ä½³ç”Ÿæˆæ¨¡å¼
    use_vl_validation: bool = True  # ä½¿ç”¨VLéªŒè¯
    enable_frame_reuse: bool = True  # å¯ç”¨å¸§å¤ç”¨ä¼˜åŒ–

    # è¾“å‡ºé…ç½®
    output_path: Optional[str] = None
    save_intermediate: bool = False


@dataclass
class UnifiedVideoGenerateResponse:
    """ç»Ÿä¸€çš„è§†é¢‘ç”Ÿæˆå“åº”"""
    success: bool
    video_path: Optional[str] = None

    # åŸºæœ¬ä¿¡æ¯
    duration_seconds: int = 0
    generation_mode: str = ""  # å®é™…ä½¿ç”¨çš„ç”Ÿæˆæ¨¡å¼

    # ç”Ÿæˆç»Ÿè®¡
    segments_count: int = 0
    keyframes_count: int = 0

    # è€—æ—¶å’Œæˆæœ¬
    total_time_ms: int = 0
    total_cost: float = 0.0

    # é”™è¯¯ä¿¡æ¯
    error_code: Optional[str] = None
    error_message: Optional[str] = None

    # è¯¦ç»†ä¿¡æ¯
    metadata: Dict[str, Any] = field(default_factory=dict)


class UnifiedVideoGenerator:
    """
    ç»Ÿä¸€è§†é¢‘ç”Ÿæˆå™¨
    å•ä¸€ /generate æ¥å£ï¼Œæ™ºèƒ½é€‰æ‹©ç”Ÿæˆæ¨¡å¼
    """

    def __init__(self, config: Dict[str, Any]):
        self.config = config

        # åˆå§‹åŒ–å„ç§ç”Ÿæˆå™¨
        self.text_orchestrator = EnhancedVideoOrchestrator(config)
        self.image_orchestrator = ImageToVideoOrchestrator(config)
        self.image_desc_orchestrator = ImageDescriptionToVideoOrchestrator(config)

        self.work_dir = Path(config.get("work_dir", "/tmp/unified_video"))
        self.work_dir.mkdir(parents=True, exist_ok=True)

    async def generate(self, request: UnifiedVideoGenerateRequest) -> UnifiedVideoGenerateResponse:
        """
        ç»Ÿä¸€çš„ç”Ÿæˆæ¥å£ - /generate
        æ ¹æ®è¾“å…¥è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç”Ÿæˆæ¨¡å¼
        """

        print("\n" + "="*60)
        print("ğŸ¬ ç»Ÿä¸€è§†é¢‘ç”Ÿæˆæ¥å£ /generate")
        print("="*60)

        try:
            # æ£€æµ‹ç”Ÿæˆæ¨¡å¼
            generation_mode = self._detect_generation_mode(request)
            print(f"\nğŸ“‹ æ£€æµ‹åˆ°ç”Ÿæˆæ¨¡å¼: {generation_mode}")

            # æ ¹æ®æ¨¡å¼è°ƒç”¨å¯¹åº”çš„ç”Ÿæˆå™¨
            if generation_mode == "text_only":
                return await self._generate_from_text(request)

            elif generation_mode == "image_only":
                return await self._generate_from_image(request)

            elif generation_mode == "image_with_description":
                return await self._generate_from_image_and_description(request)

            elif generation_mode == "multi_images":
                return await self._generate_from_storyboard(request)

            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ç”Ÿæˆæ¨¡å¼: {generation_mode}")

        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
            return UnifiedVideoGenerateResponse(
                success=False,
                error_code="GENERATION_FAILED",
                error_message=str(e)
            )

    def _detect_generation_mode(self, request: UnifiedVideoGenerateRequest) -> str:
        """
        è‡ªåŠ¨æ£€æµ‹æœ€ä½³ç”Ÿæˆæ¨¡å¼
        """

        has_text = bool(request.text_description)
        has_single_image = bool(request.image_path)
        has_multi_images = bool(request.images and len(request.images) > 1)

        if has_multi_images:
            return "multi_images"  # å¤šå¼ å›¾ç‰‡ï¼ˆåˆ†é•œï¼‰
        elif has_single_image and has_text:
            return "image_with_description"  # å›¾ç‰‡+æè¿°
        elif has_single_image:
            return "image_only"  # ä»…å›¾ç‰‡
        elif has_text:
            return "text_only"  # ä»…æ–‡æœ¬
        else:
            raise ValueError("è¯·æä¾›è‡³å°‘ä¸€ç§è¾“å…¥ï¼štext_description æˆ– image_path æˆ– images")

    async def _generate_from_text(self, request: UnifiedVideoGenerateRequest) -> UnifiedVideoGenerateResponse:
        """
        çº¯æ–‡æœ¬ç”Ÿæˆæ¨¡å¼
        """

        print("\n[æ¨¡å¼] ğŸ“ çº¯æ–‡æœ¬ç”Ÿæˆ")
        print(f"  æè¿°: {request.text_description[:100]}...")
        print(f"  æ—¶é•¿: {request.duration_seconds}ç§’")

        # è°ƒç”¨æ–‡æœ¬è§†é¢‘ç”Ÿæˆå™¨
        from video_generate_protocol.nodes.video_storyboard_orchestrator import VideoStoryboardRequest

        storyboard_request = VideoStoryboardRequest(
            text_description=request.text_description,
            duration_seconds=request.duration_seconds,
            product_info=request.product_info,
            style_config=request.generation_config,
            output_path=request.output_path,
            theme_id=request.theme_id,
            keywords_id=request.keywords_id,
            target_duration_id=request.target_duration_id,
            user_description_id=request.user_description_id
        )

        result = await self.text_orchestrator.process_video_request(storyboard_request)

        if result["success"]:
            return UnifiedVideoGenerateResponse(
                success=True,
                video_path=result["video_path"],
                duration_seconds=request.duration_seconds,
                generation_mode="text_only",
                segments_count=result.get("segments_count", 0),
                keyframes_count=result.get("keyframes_count", 0),
                metadata={
                    "input_type": "text",
                    "storyboard_plan": result.get("storyboard_plan")
                }
            )
        else:
            return UnifiedVideoGenerateResponse(
                success=False,
                generation_mode="text_only",
                error_message=result.get("error", "æ–‡æœ¬ç”Ÿæˆå¤±è´¥")
            )

    async def _generate_from_image(self, request: UnifiedVideoGenerateRequest) -> UnifiedVideoGenerateResponse:
        """
        çº¯å›¾ç‰‡ç”Ÿæˆæ¨¡å¼
        """

        print("\n[æ¨¡å¼] ğŸ–¼ï¸ çº¯å›¾ç‰‡ç”Ÿæˆ")
        print(f"  å›¾ç‰‡: {request.image_path}")
        print(f"  æ—¶é•¿: {request.duration_seconds}ç§’")
        print(f"  è¿åŠ¨å¼ºåº¦: {request.generation_config.get('motion_intensity', 'medium')}")

        # è°ƒç”¨å›¾ç‰‡è§†é¢‘ç”Ÿæˆå™¨
        from video_generate_protocol.nodes.image_to_video_orchestrator import ImageToVideoRequest

        image_request = ImageToVideoRequest(
            image_path=request.image_path,
            duration_seconds=request.duration_seconds,
            motion_intensity=request.generation_config.get("motion_intensity", "medium"),
            style=request.generation_config.get("style", "realistic"),
            output_path=request.output_path
        )

        result = await self.image_orchestrator.process_image_to_video(image_request)

        if result.success:
            return UnifiedVideoGenerateResponse(
                success=True,
                video_path=result.video_path,
                duration_seconds=result.duration_seconds,
                generation_mode="image_only",
                segments_count=result.segments_count,
                metadata={
                    "input_type": "image",
                    "motion_intensity": request.generation_config.get("motion_intensity")
                }
            )
        else:
            return UnifiedVideoGenerateResponse(
                success=False,
                generation_mode="image_only",
                error_message=result.error_message
            )

    async def _generate_from_image_and_description(self,
                                                  request: UnifiedVideoGenerateRequest) -> UnifiedVideoGenerateResponse:
        """
        å›¾ç‰‡+æè¿°ç”Ÿæˆæ¨¡å¼
        """

        print("\n[æ¨¡å¼] ğŸ–¼ï¸+ğŸ“ å›¾ç‰‡+æè¿°ç”Ÿæˆ")
        print(f"  å›¾ç‰‡: {request.image_path}")
        print(f"  æè¿°: {request.text_description[:100]}...")
        print(f"  æ—¶é•¿: {request.duration_seconds}ç§’")

        # è°ƒç”¨å›¾ç‰‡+æè¿°ç”Ÿæˆå™¨
        from video_generate_protocol.nodes.image_description_to_video import ImageDescriptionToVideoRequest

        img_desc_request = ImageDescriptionToVideoRequest(
            image_path=request.image_path,
            description=request.text_description,
            total_duration_seconds=request.duration_seconds,
            product_info=request.product_info,
            style_config=request.generation_config,
            use_vl_validation=request.use_vl_validation,
            output_path=request.output_path,
            theme_id=request.theme_id,
            keywords_id=request.keywords_id,
            target_duration_id=request.target_duration_id,
            user_description_id=request.user_description_id
        )

        result = await self.image_desc_orchestrator.process_request(img_desc_request)

        if result["success"]:
            return UnifiedVideoGenerateResponse(
                success=True,
                video_path=result["video_path"],
                duration_seconds=request.duration_seconds,
                generation_mode="image_with_description",
                segments_count=result.get("segments_count", 0),
                metadata={
                    "input_type": "image_with_description",
                    "segment_plans": result.get("segment_plans")
                }
            )
        else:
            return UnifiedVideoGenerateResponse(
                success=False,
                generation_mode="image_with_description",
                error_message=result.get("error", "å›¾ç‰‡+æè¿°ç”Ÿæˆå¤±è´¥")
            )

    async def _generate_from_storyboard(self, request: UnifiedVideoGenerateRequest) -> UnifiedVideoGenerateResponse:
        """
        å¤šå›¾åˆ†é•œç”Ÿæˆæ¨¡å¼
        """

        print("\n[æ¨¡å¼] ğŸ¬ å¤šå›¾åˆ†é•œç”Ÿæˆ")
        print(f"  å›¾ç‰‡æ•°: {len(request.images)}")
        print(f"  æ—¶é•¿: {request.duration_seconds}ç§’")

        # æ„å»ºåˆ†é•œé¡¹
        storyboard_items = []
        for i, image_path in enumerate(request.images):
            description = ""
            if request.storyboard_descriptions and i < len(request.storyboard_descriptions):
                description = request.storyboard_descriptions[i]
            else:
                description = f"åœºæ™¯ {i+1}"

            storyboard_items.append({
                "image": image_path,
                "description": description
            })

        # è°ƒç”¨åˆ†é•œç”Ÿæˆå™¨
        from video_generate_protocol.nodes.image_description_to_video import ImageDescriptionToVideoRequest

        storyboard_request = ImageDescriptionToVideoRequest(
            storyboard_items=storyboard_items,
            total_duration_seconds=request.duration_seconds,
            product_info=request.product_info,
            style_config=request.generation_config,
            output_path=request.output_path,
            theme_id=request.theme_id,
            keywords_id=request.keywords_id,
            target_duration_id=request.target_duration_id,
            user_description_id=request.user_description_id
        )

        result = await self.image_desc_orchestrator.process_request(storyboard_request)

        if result["success"]:
            return UnifiedVideoGenerateResponse(
                success=True,
                video_path=result["video_path"],
                duration_seconds=request.duration_seconds,
                generation_mode="multi_images",
                segments_count=result.get("segments_count", 0),
                metadata={
                    "input_type": "storyboard",
                    "images_count": len(request.images)
                }
            )
        else:
            return UnifiedVideoGenerateResponse(
                success=False,
                generation_mode="multi_images",
                error_message=result.get("error", "åˆ†é•œç”Ÿæˆå¤±è´¥")
            )


# ç»Ÿä¸€APIæ¥å£
async def generate_video(
    # è¾“å…¥ï¼ˆè‡³å°‘éœ€è¦ä¸€ä¸ªï¼‰
    text_description: Optional[str] = None,
    image_path: Optional[str] = None,
    images: Optional[List[str]] = None,

    # å¿…å¡«
    duration_seconds: int = 30,

    # VGPç³»ç»Ÿå¿…éœ€çš„IDå‚æ•°
    theme_id: Optional[str] = None,
    keywords_id: Optional[str] = None,
    target_duration_id: Optional[str] = None,
    user_description_id: Optional[str] = None,

    # å¯é€‰
    product_info: Optional[Dict] = None,
    style: str = "realistic",
    motion_intensity: str = "medium",
    output_path: Optional[str] = None,

    # é…ç½®
    config: Optional[Dict] = None
) -> UnifiedVideoGenerateResponse:
    """
    ç»Ÿä¸€çš„è§†é¢‘ç”ŸæˆAPI - /generate æ¥å£

    æ”¯æŒå¤šç§è¾“å…¥æ–¹å¼ï¼š
    1. çº¯æ–‡æœ¬ï¼šåªä¼  text_description
    2. çº¯å›¾ç‰‡ï¼šåªä¼  image_path
    3. å›¾ç‰‡+æè¿°ï¼šä¼  image_path + text_description
    4. å¤šå›¾åˆ†é•œï¼šä¼  images åˆ—è¡¨

    è¿”å›:
        UnifiedVideoGenerateResponse
    """

    if not config:
        config = {
            "qwen_api_key": "your_qwen_api_key",
            "openai_api_key": "your_openai_api_key",
            "work_dir": "/tmp/unified_video"
        }

    generator = UnifiedVideoGenerator(config)

    request = UnifiedVideoGenerateRequest(
        text_description=text_description,
        image_path=image_path,
        images=images,
        duration_seconds=duration_seconds,
        theme_id=theme_id,
        keywords_id=keywords_id,
        target_duration_id=target_duration_id,
        user_description_id=user_description_id,
        product_info=product_info,
        generation_config={
            "style": style,
            "motion_intensity": motion_intensity
        },
        output_path=output_path
    )

    return await generator.generate(request)


# ä½¿ç”¨ç¤ºä¾‹
async def demo_unified_api():
    """æ¼”ç¤ºç»Ÿä¸€APIçš„å„ç§ç”¨æ³•"""

    config = {
        "qwen_api_key": "your_actual_key",
        "openai_api_key": "your_actual_key",
        "work_dir": "/tmp/demo"
    }

    # ç¤ºä¾‹1ï¼šåªæœ‰æ–‡æœ¬
    print("\nğŸ“ ç¤ºä¾‹1: çº¯æ–‡æœ¬ç”Ÿæˆ")
    result1 = await generate_video(
        text_description="å±•ç¤ºæ™ºèƒ½æ‰‹è¡¨çš„å®Œæ•´åŠŸèƒ½ï¼Œä»å¤–è§‚åˆ°ä½¿ç”¨åœºæ™¯",
        duration_seconds=20,
        config=config
    )
    print(f"ç»“æœ: {result1.generation_mode} - {'æˆåŠŸ' if result1.success else 'å¤±è´¥'}")

    # ç¤ºä¾‹2ï¼šåªæœ‰å›¾ç‰‡
    print("\nğŸ–¼ï¸ ç¤ºä¾‹2: çº¯å›¾ç‰‡ç”Ÿæˆ")
    result2 = await generate_video(
        image_path="/path/to/product.jpg",
        duration_seconds=10,
        motion_intensity="low",
        config=config
    )
    print(f"ç»“æœ: {result2.generation_mode} - {'æˆåŠŸ' if result2.success else 'å¤±è´¥'}")

    # ç¤ºä¾‹3ï¼šå›¾ç‰‡+æè¿°
    print("\nğŸ–¼ï¸+ğŸ“ ç¤ºä¾‹3: å›¾ç‰‡+æè¿°ç”Ÿæˆ")
    result3 = await generate_video(
        image_path="/path/to/product.jpg",
        text_description="äº§å“ä»é™æ€å±•ç¤ºåˆ°åŠ¨æ€ä½¿ç”¨çš„è½¬å˜",
        duration_seconds=15,
        config=config
    )
    print(f"ç»“æœ: {result3.generation_mode} - {'æˆåŠŸ' if result3.success else 'å¤±è´¥'}")

    # ç¤ºä¾‹4ï¼šå¤šå›¾åˆ†é•œ
    print("\nğŸ¬ ç¤ºä¾‹4: å¤šå›¾åˆ†é•œç”Ÿæˆ")
    result4 = await generate_video(
        images=[
            "/path/to/scene1.jpg",
            "/path/to/scene2.jpg",
            "/path/to/scene3.jpg"
        ],
        duration_seconds=15,
        config=config
    )
    print(f"ç»“æœ: {result4.generation_mode} - {'æˆåŠŸ' if result4.success else 'å¤±è´¥'}")


if __name__ == "__main__":
    asyncio.run(demo_unified_api())