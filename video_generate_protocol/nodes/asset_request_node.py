# nodes/asset_request_node.py
"""
ç´ æè¯·æ±‚ä¸ç”ŸæˆèŠ‚ç‚¹ (Node 5 in VGP Workflow)

è¿™æ˜¯è§†é¢‘ç”Ÿæˆæµç¨‹ä¸­çš„æ ¸å¿ƒç´ æèŠ‚ç‚¹ï¼Œè´Ÿè´£ï¼š
1. å¯¹æ¥ç´ æä¾›ç»™ç³»ç»Ÿï¼ˆmaterials_suppliesï¼‰
2. æ™ºèƒ½åŒ¹é…å¹¶ç”Ÿæˆæ‰€æœ‰ç±»å‹çš„ç´ æï¼ˆè§†é¢‘ã€å›¾ç‰‡ã€éŸ³é¢‘ç­‰ï¼‰
3. å°†ç”Ÿæˆçš„ç´ æä¿¡æ¯ä¼ é€’ç»™åç»­èŠ‚ç‚¹è¿›è¡Œå¤„ç†

å·¥ä½œæµä½ç½®ï¼š
- è¾“å…¥ï¼šæ¥è‡ª node_3_shot_blocks (åˆ†é•œå—ç”ŸæˆèŠ‚ç‚¹)
- è¾“å‡ºï¼šä¼ é€’ç»™ node_6_filter_application (æ»¤é•œåº”ç”¨èŠ‚ç‚¹)

é‡è¦è¯´æ˜ï¼š
- æ­¤èŠ‚ç‚¹æ˜¯æ•´ä¸ªå·¥ä½œæµä¸­ç´ æç”Ÿæˆçš„æ ¸å¿ƒç¯èŠ‚
- è°ƒç”¨ match_intelligent_video() è¿›è¡Œæ™ºèƒ½ç´ æåŒ¹é…
- åç»­èŠ‚ç‚¹ï¼ˆ6-8ï¼‰åŸºäºç”Ÿæˆçš„ç´ æè¿›è¡Œå„ç§å¤„ç†ï¼ˆæ»¤é•œã€æ•ˆæœã€è½¬åœºï¼‰
- èŠ‚ç‚¹9-15åªè´Ÿè´£ç”Ÿæˆå¯¹åº”ç±»å‹çš„ç´ æï¼Œä¸è¿›è¡Œæœ€ç»ˆåˆæˆ
- æœ€ç»ˆåˆæˆåœ¨ node_16_timeline_integration ä¸­å®Œæˆ
"""

from video_generate_protocol import BaseNode
import logging

logger = logging.getLogger(__name__)

from typing import Dict, List, Any
import requests
import uuid
import time
from datetime import datetime
import asyncio

from materials_supplies import match_intelligent_video

# TTS è¯­é€Ÿï¼ˆå­—/ç§’ï¼‰
CHARS_PER_SECOND = 4.0


class AssetRequestNode(BaseNode):
    """
    ç´ æè¯·æ±‚ä¸ç”ŸæˆèŠ‚ç‚¹

    è¿™æ˜¯VGPå·¥ä½œæµä¸­çš„æ ¸å¿ƒç´ æèŠ‚ç‚¹ï¼ˆNode 5ï¼‰ï¼Œè´Ÿè´£ï¼š
    1. æ¥æ”¶åˆ†é•œå—åˆ—è¡¨ï¼ˆshot_blocksï¼‰
    2. ä¼°ç®—æ¯ä¸ªåˆ†é•œçš„æ—¶é•¿
    3. è°ƒç”¨ç´ æä¾›ç»™ç³»ç»Ÿæ™ºèƒ½åŒ¹é…ç´ æ
    4. è¿”å›åŒ…å«ç´ æä¿¡æ¯çš„åˆæ­¥åºåˆ—

    æ­¤èŠ‚ç‚¹ç”Ÿæˆçš„ç´ æå°†è¢«åç»­èŠ‚ç‚¹ä½¿ç”¨å’Œå¤„ç†ã€‚
    """
    required_inputs = [
        {
            "name": "shot_blocks_id",
            "label": "åˆ†é•œå—åˆ—è¡¨",
            "type": list,
            "required": True,
            "desc": "åŒ…å«åˆ†é•œæè¿°çš„ç»“æ„åŒ–åˆ—è¡¨",
            "field_type": "json"
        },
        {
            "name": "user_description_id",
            "label": "ç”¨æˆ·åŸå§‹è¾“å…¥",
            "type": str,
            "required": True,
            "default": "",
            "desc": "ç”¨æˆ·åŸå§‹è¾“å…¥",
            "field_type": "textarea"
        },
        {
            "name": "tts_text_id",
            "label": "è¯­éŸ³æ–‡æœ¬ï¼ˆç”¨äºæ—¶é•¿ä¼°ç®—ï¼‰",
            "type": str,
            "required": False,
            "desc": "ç”¨äºä¼°ç®—é•œå¤´æ—¶é•¿çš„å®Œæ•´è¯­éŸ³æ–‡æœ¬",
            "field_type": "text"
        },
        ##TODO:è¿™é‡Œè§†é¢‘æè¿°è¦å…¼å®¹é“¾æ¥
        {
            "name": "video_description_id",
            "label": "ç”¨æˆ·è§†é¢‘æè¿°ï¼ˆå¯é€‰ï¼‰",
            "type": str,
            "required": False,
            "desc": "å¦‚æœç”¨æˆ·ä¸Šä¼ äº†å‚è€ƒè§†é¢‘ï¼Œæä¾›å…¶å†…å®¹æè¿°ï¼Œç”¨äºä¼˜å…ˆåŒ¹é…",
            "field_type": "text"
        }
    ]

    output_schema=[
         {
            "name": "preliminary_sequence_id",
            "label": "åˆ†é•œå—åˆ—è¡¨",
            "type": list,
            "required": True,
            "desc": "åŒ…å«é•œå¤´ä¿¡æ¯çš„å‰ªè¾‘åºåˆ—ï¼Œå¦‚ [{'shot_id': 's1', 'shot_type': 'å…¨æ™¯', 'pacing': 'å¿«å‰ª', 'emotion_hint': 'æ¿€æ˜‚'}]",
            "field_type": "json"
        },
        {
            "name": "total_main_duration_id",
            "label": "è§†é¢‘ä¸»ç‰‡æ®µæ€»æ—¶é•¿",
            "type": float,
            "required": True,
            "desc": "è§†é¢‘ä¸»ç‰‡æ®µæ€»æ—¶é•¿",
            "field_type": "number"
        }
    ]

    system_parameters = {
        "default_duration": 5.0,
        "use_tts_duration": True,
        "apply_default_transition": True,
        "transition_duration": 0.5,
        "match_user_video_strategy": "all"  # æˆ– "keyword_based" ç­‰ç­–ç•¥
    }

    def __init__(self, node_id: str, name: str = "ç´ æéœ€æ±‚è§£æ"):
        super().__init__(node_id=node_id, node_type="asset", name=name)


    

    async def generate(self, context: Dict[str, Any]) -> Dict[str, Any]:
        self.validate_context(context)

        # æå–è¾“å…¥
        shot_blocks = context.get("shot_blocks_id", [])
        tts_text = context.get("tts_text_id", "").strip()
        video_description = context.get("video_description_id", "").strip() or None

        if not shot_blocks:
            raise ValueError("ç¼ºå°‘è¾“å…¥ï¼šshot_blocks ä¸èƒ½ä¸ºç©º")

        # === ç¬¬ä¸€æ­¥ï¼šé¢„ä¼°æ¯ä¸ªåˆ†é•œçš„æ—¶é•¿ï¼Œå¹¶å¤„ç†ç”¨æˆ·è§†é¢‘åŒ¹é…æ ‡è®° ===
        processed_shot_blocks = []
        current_time = 0.0

        for idx, block in enumerate(shot_blocks):
            block = block.copy()  # é¿å…ä¿®æ”¹åŸ context
            description = block.get("visual_description", "").strip()
            if not description:
                continue

            # --- 1. è®¡ç®— duration ---
            if "duration" in block:
                duration = float(block["duration"])
            elif self.system_parameters["use_tts_duration"] and tts_text:
                total_chars = len(tts_text)
                block_chars = len(description)
                estimated_duration = (block_chars / max(total_chars, 1)) * (len(tts_text) / CHARS_PER_SECOND)
                duration = max(2.0, estimated_duration)
            else:
                duration = self.system_parameters["default_duration"]

            block["duration"] = duration

            # --- 2. åˆ¤æ–­æ˜¯å¦è¦å¼ºåˆ¶åŒ¹é…ç”¨æˆ·ä¸Šä¼ è§†é¢‘ ---
            # è¿™é‡Œå¯ä»¥æ ¹æ®ç­–ç•¥å†³å®šï¼šæ¯”å¦‚å…¨éƒ¨åŒ¹é…ã€æˆ–åªåŒ¹é…åŒ…å«æŸäº›å…³é”®è¯çš„
            should_match_user_video = False
            strategy = self.system_parameters.get("match_user_video_strategy", "none")

            if video_description and strategy == "all":
                should_match_user_video = True
            # elif strategy == "keyword_based":
            #     should_match_user_video = any(kw in description for kw in ["æˆ‘æ‹æ‘„", "æˆ‘çš„è§†é¢‘", "å®æ‹"])

            if should_match_user_video:
                block["asset_status"] = "matched"
                block["scheduled_asset"] = {
                    "source": "user_upload",
                    "description": video_description,
                    "reason": f"Forced by video_description match (block {idx})"
                }

            processed_shot_blocks.append(block)

            current_time += duration
            if (self.system_parameters["apply_default_transition"] and
                    idx < len(processed_shot_blocks) - 1):
                current_time += self.system_parameters["transition_duration"]

        # === ç¬¬äºŒæ­¥ï¼šå°†å¤„ç†åçš„ shot_blocks å†™å› contextï¼Œä¼ ç»™ match_intelligent_video ===
        # æ³¨æ„ï¼šmatch_intelligent_video æ¥æ”¶çš„æ˜¯å®Œæ•´ contextï¼Œä¸æ˜¯å•ç‹¬ shot_list
        enhanced_context = context.copy()
        enhanced_context["shot_blocks_id"] = processed_shot_blocks
        # å¯é€‰ï¼šæ·»åŠ  metadata
        enhanced_context["asset_request_metadata"] = {
            "node_id": self.node_id,
            "processed_at": datetime.now().isoformat(),
            "total_blocks": len(processed_shot_blocks)
        }

        # === ç¬¬ä¸‰æ­¥ï¼šè°ƒç”¨å¼‚æ­¥æ™ºèƒ½åŒ¹é…ï¼ˆä¼ å…¥å®Œæ•´ contextï¼‰===
        try:
            match_result = await match_intelligent_video(enhanced_context)
        except Exception as e:
            logger.info(f"âŒ è°ƒç”¨ match_intelligent_video å¤±è´¥: {str(e)}")
            match_result = {"success": False}

        if not match_result or not match_result.get("success"):
            logger.info(f"âš ï¸ æ™ºèƒ½ç´ æåŒ¹é…å¤±è´¥ï¼Œä½¿ç”¨å ä½ç¬¦åºåˆ—")
            preliminary_sequence = self._create_placeholder_sequence(processed_shot_blocks)
        else:
            preliminary_sequence = match_result.get("data", {}).get("clips", [])
            # å¯é€‰ï¼šæ ¡éªŒè¿”å›ç»“æ„

        # === ç¬¬å››æ­¥ï¼šæ ¹æ®ç›®æ ‡æ—¶é•¿è®¡ç®—éœ€è¦çš„è§†é¢‘æ®µæ•° ===
        import os
        import sys
        import math
        from urllib.parse import quote
        sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

        # è·å–ç›®æ ‡æ—¶é•¿
        target_duration = context.get("target_duration_id", 60)

        video_clips = []
        keyframes = []

        try:
            # âœ… ä½¿ç”¨ä¸‡ç›¸å›¾ç”Ÿè§†é¢‘ API ç”Ÿæˆï¼ˆOSSé¢„å­˜è§†é¢‘å·²æ³¨é‡Šï¼Œç”¨äºèŠ‚çœæˆæœ¬ï¼‰
            # ========== OSS é¢„å­˜è§†é¢‘éƒ¨åˆ†ï¼ˆå·²æ³¨é‡Šï¼‰ ==========
            # oss_base_url = "https://ai-movie-cloud-v2.oss-cn-shanghai.aliyuncs.com/aura_render_temp/"
            # available_oss_videos = 6
            # use_oss_videos = available_oss_videos > 0
            # if use_oss_videos:
            #     logger.info(f"âœ… [Node 5] ä½¿ç”¨ OSS è§†é¢‘ç´ æï¼Œå…± {available_oss_videos} ä¸ªå¯ç”¨")
            #     current_time = 0.0
            #     for idx in range(videos_needed):
            #         video_idx = (idx % available_oss_videos) + 1
            #         video_filename = f"è§†é¢‘{video_idx}.mp4"
            #         video_url = oss_base_url + quote(video_filename)
            #         video_clip = {...}
            #         video_clips.append(video_clip)
            # ========== OSS éƒ¨åˆ†ç»“æŸ ==========

            # âœ… ä½¿ç”¨å®Œæ•´çš„ä¸€è‡´æ€§å·¥ä½œæµï¼ˆNode 4A/4B/4C + å›¾ç”Ÿè§†é¢‘ï¼‰
            # ä½¿ç”¨æ‰€æœ‰ç”Ÿæˆçš„é•œå¤´ï¼Œä¸è¦æˆªæ–­ï¼ˆæ¯ä¸ªé•œå¤´ç”Ÿæˆä¸€æ®µ5ç§’è§†é¢‘ï¼‰
            selected_shot_blocks = processed_shot_blocks

            logger.info(f"ğŸ¯ [Node 5] ç›®æ ‡æ—¶é•¿ {target_duration}ç§’")
            logger.info(f"ğŸ¨ [Node 5] ä½¿ç”¨æ‰€æœ‰ {len(selected_shot_blocks)} ä¸ªé•œå¤´ç”Ÿæˆè§†é¢‘ï¼ˆå«ä¸€è‡´æ€§ä¿éšœï¼‰")
            logger.info(f"ğŸ“Š [Node 5] é¢„è®¡ç”Ÿæˆ {len(selected_shot_blocks)} æ®µè§†é¢‘ï¼Œæ€»æ—¶é•¿çº¦ {len(selected_shot_blocks) * 5}ç§’")

            # === æ­¥éª¤1: Node 4A - æå–å…¨å±€è§†è§‰åŸºå›  ===
            from video_generate_protocol.nodes.visual_dna_node import VisualDNANode

            node_4a = VisualDNANode(node_id="node_4a", name="å…¨å±€è§†è§‰åŸºå› æå–")
            visual_dna_context = {
                "user_description_id": context.get("user_description_id", ""),
                "shot_blocks_id": selected_shot_blocks,
                "reference_media": context.get("reference_media", {})  # âœ… ä¼ é€’äº§å“å›¾ç‰‡
            }
            visual_dna_result = await node_4a.generate(visual_dna_context)
            visual_dna = visual_dna_result["visual_dna_id"]

            # === æ­¥éª¤2: Node 4B - é¦–å¸§ç»†åŒ– ===
            from video_generate_protocol.nodes.keyframe_refinement_node import KeyframeRefinementNode

            node_4b = KeyframeRefinementNode(node_id="node_4b", name="é¦–å¸§ç»†åŒ–")
            keyframe_context = {
                "shot_blocks_id": selected_shot_blocks,
                "visual_dna_id": visual_dna
            }
            keyframe_result = await node_4b.generate(keyframe_context)
            refined_keyframes = keyframe_result["refined_keyframes_id"]

            # === æ­¥éª¤3: Node 4C - ä¸€è‡´æ€§æ£€æŸ¥ ===
            from video_generate_protocol.nodes.consistency_check_node import ConsistencyCheckNode

            node_4c = ConsistencyCheckNode(node_id="node_4c", name="ä¸€è‡´æ€§æ£€æŸ¥")
            consistency_context = {
                "refined_keyframes_id": refined_keyframes,
                "reference_media": context.get("reference_media", {})  # âœ… ä¼ é€’äº§å“å›¾ç‰‡
            }
            consistency_result = await node_4c.generate(consistency_context)
            keyframes_with_strategy = consistency_result["keyframes_with_strategy_id"]

            # === æ­¥éª¤4: æå–äº§å“å›¾ç‰‡URLï¼ˆå¦‚æœæœ‰ï¼‰===
            product_image_url = None
            reference_media = context.get("reference_media", {})
            if reference_media:
                product_images = reference_media.get("product_images", [])
                if product_images and len(product_images) > 0:
                    product_image_url = product_images[0].get("url")
                    logger.info(f"ğŸ“¦ [Node 5] æ£€æµ‹åˆ°äº§å“å‚è€ƒå›¾: {product_image_url}")

            # === æ­¥éª¤5: ä½¿ç”¨ä¸‡ç›¸å›¾ç”Ÿè§†é¢‘ï¼ˆæ”¯æŒå›¾ç”Ÿå›¾ï¼‰ ===
            from video_generate_protocol.nodes.qwen_integration import StoryboardToVideoProcessor

            qwen_key = os.getenv('DASHSCOPE_API_KEY') or os.getenv('AI__DASHSCOPE_API_KEY')
            if not qwen_key:
                raise ValueError("ç¼ºå°‘åƒé—®APIå¯†é’¥")

            video_processor = StoryboardToVideoProcessor(qwen_key)

            logger.info(f"ğŸ¥ [Node 5] Generating {len(keyframes_with_strategy)} video clips with consistency...")
            video_clips = await video_processor.process_keyframes_with_consistency(
                keyframes_with_strategy,
                f"/tmp/video_clips_node5_{uuid.uuid4().hex[:8]}",
                product_image_url=product_image_url  # ä¼ é€’äº§å“å›¾ç‰‡
            )
            logger.info(f"âœ… [Node 5] Generated {len(video_clips)} video clips from {len(selected_shot_blocks)} shots (target duration: {target_duration}s)")

            # ä¿å­˜å…³é”®å¸§ä¿¡æ¯ï¼ˆä¾›è°ƒè¯•ï¼‰
            keyframes = keyframes_with_strategy

            # æ‰“å°æ‰€æœ‰è§†é¢‘ç‰‡æ®µURLæ±‡æ€»
            if video_clips:
                logger.info(f"\n{'='*80}")
                logger.info(f"ğŸ“¹ ç”Ÿæˆçš„è§†é¢‘ç‰‡æ®µURLæ±‡æ€» (å…±{len(video_clips)}ä¸ª):")
                logger.info(f"{'='*80}")
                for idx, clip in enumerate(video_clips, 1):
                    logger.info(f"{idx}. {clip.get('url', 'N/A')}")
                logger.info(f"{'='*80}\n")

        except Exception as e:
            logger.info(f"âŒ [Node 5] Video generation failed: {e}")
            import traceback
            traceback.print_exc()
            # è§†é¢‘ç”Ÿæˆå¤±è´¥æ—¶ï¼Œç»§ç»­è¿”å›åŒ¹é…ç»“æœï¼Œä½†æ ‡è®°å¤±è´¥
            video_clips = []
            keyframes = []

        return {
            "preliminary_sequence_id": preliminary_sequence,
            "total_main_duration_id": current_time,
            "video_clips": video_clips,  # ç”Ÿæˆçš„è§†é¢‘ç‰‡æ®µåˆ—è¡¨
            "keyframes": keyframes,  # ç”Ÿæˆçš„å…³é”®å¸§åˆ—è¡¨
            "video_generation_success": len(video_clips) > 0,  # è§†é¢‘ç”Ÿæˆæ˜¯å¦æˆåŠŸ
            # "timestamp_id": datetime.now().isoformat(),
            # "processed_shot_blocks": processed_shot_blocks,  # è°ƒè¯•ç”¨
            # "video_description_matched": bool(video_description)  # æ—¥å¿—æ ‡è®°
        }

    def _create_placeholder_sequence(self, shot_blocks: List[Dict]) -> List[Dict]:
        """ç”Ÿæˆå ä½åºåˆ—ï¼ˆç”¨äº fallbackï¼‰"""
        sequence = []
        current_time = 0.0
        transition_dur = self.system_parameters["transition_duration"] if self.system_parameters["apply_default_transition"] else 0

        for idx, block in enumerate(shot_blocks):
            duration = block["duration"]
            clip = {
                "id": f"clip_{uuid.uuid4().hex[:8]}",
                "index": idx,
                "asset_id": f"placeholder_{idx}",
                "source_url": "https://example.com/assets/placeholder.mp4",
                "start": round(current_time, 3),
                "end": round(current_time + duration, 3),
                "duration": round(duration, 3),
                "source": {"in": 0.0, "out": round(duration, 3)},
                "transition_in": {
                    "type": "cross_dissolve",
                    "duration": transition_dur if idx > 0 else 0
                },
                "transition_out": {
                    "type": "cross_dissolve",
                    "duration": transition_dur if idx < len(shot_blocks) - 1 else 0
                },
                "metadata": {
                    "description": block.get("visual_description", "")[:100],
                    "provider": "system_placeholder",
                    "original_block": block
                },
                "transform": {"scale": 1.0, "position": "center"}
            }
            sequence.append(clip)
            current_time += duration
            if idx < len(shot_blocks) - 1:
                current_time += transition_dur

        return sequence

    # regenerate å¯åç»­æ”¹ä¸º asyncï¼Œæˆ–ä»…ç”¨äºè°ƒè¯•
    def regenerate(self, context: Dict[str, Any], user_intent: Dict[str, Any]) -> Dict[str, Any]:
        logger.info(f"âš ï¸ regenerate æš‚ä¸æ”¯æŒå¼‚æ­¥æµç¨‹ï¼Œå»ºè®®åœ¨ä¸Šå±‚ç»Ÿä¸€ä½¿ç”¨ async generate")
        return self._create_placeholder_sequence(context.get("shot_blocks_id", []))