#!/usr/bin/env python3
"""
VGP Data Transformer - èŠ‚ç‚¹é—´æ•°æ®è½¬æ¢å’Œæ˜ å°„
è§£å†³èŠ‚ç‚¹é—´æ•°æ®ä¼ é€’ä¸å…¼å®¹çš„é—®é¢˜
"""

import logging
from typing import Dict, Any, List, Optional
from dataclasses import dataclass

logger = logging.getLogger(__name__)

# =============================
# èŠ‚ç‚¹è¾“å‡ºå­—æ®µæ˜ å°„å®šä¹‰
# =============================

class VGPDataMapper:
    """VGPèŠ‚ç‚¹æ•°æ®æ˜ å°„å™¨ - ç¡®ä¿èŠ‚ç‚¹é—´æ•°æ®æ­£ç¡®ä¼ é€’"""

    # å®šä¹‰æ¯ä¸ªèŠ‚ç‚¹åº”è¯¥è¾“å‡ºçš„æ ‡å‡†å­—æ®µ
    NODE_OUTPUT_SCHEMA = {
        'conversation_context': {
            'required': ['conversation_id', 'user_description', 'theme', 'keywords', 'target_duration'],
            'optional': ['context_metadata', 'conversation_history']
        },
        'video_type_identification': {
            'required': ['video_type_id', 'structure_template_id'],
            'optional': ['confidence_score', 'sub_type']
        },
        'emotion_analysis': {
            'required': ['emotions_id', 'emotion_curve', 'primary_emotion'],
            'optional': ['emotion_intensity', 'emotion_transitions']
        },
        'shot_block_generation': {
            'required': ['shot_blocks_id'],
            'optional': ['shot_transitions', 'shot_metadata']
        },
        'bgm_anchor_planning': {
            'required': ['bgm_anchors', 'bgm_timeline', 'bgm_segments'],
            'optional': ['bgm_mood_curve', 'bgm_energy_levels']
        },
        'bgm_composition': {
            'required': ['bgm_composition_id', 'bgm_file_path', 'bgm_duration'],
            'optional': ['bgm_metadata', 'bgm_tags']
        },
        'asset_request': {
            'required': ['assets', 'asset_timeline', 'asset_count'],
            'optional': ['asset_categories', 'asset_priorities']
        },
        'audio_processing': {
            'required': ['audio_track_id', 'audio_file_path', 'audio_duration'],
            'optional': ['audio_metadata', 'audio_effects']
        },
        'sfx_integration': {
            'required': ['sfx_track_id', 'sfx_timeline', 'sfx_effects'],
            'optional': ['sfx_metadata', 'sfx_volume_curve']
        },
        'transition_selection': {
            'required': ['transitions', 'transition_timeline', 'transition_types'],
            'optional': ['transition_durations', 'transition_parameters']
        },
        'filter_application': {
            'required': ['filters', 'filter_timeline', 'filter_parameters'],
            'optional': ['filter_intensity', 'filter_metadata']
        },
        'dynamic_effects': {
            'required': ['effects', 'effect_timeline', 'effect_parameters'],
            'optional': ['effect_layers', 'effect_priorities']
        },
        'aux_media_insertion': {
            'required': ['aux_media', 'aux_media_timeline', 'aux_media_types'],
            'optional': ['aux_media_metadata', 'aux_media_sources']
        },
        'aux_text_insertion': {
            'required': ['text_overlays', 'text_timeline', 'text_styles'],
            'optional': ['text_animations', 'text_metadata']
        },
        'subtitle_generation': {
            'required': ['subtitles', 'subtitle_timeline', 'subtitle_text'],
            'optional': ['subtitle_styles', 'subtitle_languages']
        },
        'intro_outro': {
            'required': ['intro_data', 'outro_data', 'intro_outro_duration'],
            'optional': ['intro_style', 'outro_style', 'branding_elements']
        },
        'timeline_integration': {
            'required': ['final_timeline', 'timeline_data', 'total_duration'],
            'optional': ['timeline_metadata', 'timeline_validation']
        }
    }

    # èŠ‚ç‚¹é—´æ•°æ®ä¾èµ–æ˜ å°„
    NODE_DEPENDENCIES = {
        'audio_processing': {
            'bgm_composition': ['bgm_composition_id', 'bgm_file_path'],
            'sfx_integration': ['sfx_track_id', 'sfx_timeline']
        },
        'shot_block_generation': {
            'video_type_identification': ['video_type_id', 'structure_template_id'],
            'emotion_analysis': ['emotions_id']
        },
        'asset_request': {
            'shot_block_generation': ['scheduled_shots', 'shot_blocks_id']  # ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„å­—æ®µå shot_blocks_id
        },
        'timeline_integration': {
            'asset_request': ['assets', 'asset_timeline', 'video_clips', 'keyframes'],  # æ·»åŠ  video_clips å’Œ keyframes
            'audio_processing': ['audio_tracks'],  # æ·»åŠ éŸ³é¢‘è½¨é“
            'transition_selection': ['transitions', 'transition_timeline'],
            'filter_application': ['filters', 'filter_timeline'],
            'subtitle_generation': ['subtitles', 'subtitle_timeline'],
            'intro_outro': ['intro_outro_sequence']  # æ·»åŠ ç‰‡å¤´ç‰‡å°¾
        }
    }

    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.VGPDataMapper")

    def transform_node_output(self, node_type: str, raw_output: Dict[str, Any]) -> Dict[str, Any]:
        """
        è½¬æ¢èŠ‚ç‚¹è¾“å‡ºä¸ºæ ‡å‡†æ ¼å¼

        Args:
            node_type: èŠ‚ç‚¹ç±»å‹
            raw_output: åŸå§‹è¾“å‡ºæ•°æ®

        Returns:
            æ ‡å‡†åŒ–çš„è¾“å‡ºæ•°æ®
        """
        if node_type not in self.NODE_OUTPUT_SCHEMA:
            self.logger.warning(f"Unknown node type: {node_type}")
            return raw_output

        schema = self.NODE_OUTPUT_SCHEMA[node_type]
        transformed = {}

        # ç¡®ä¿å¿…éœ€å­—æ®µå­˜åœ¨
        for field in schema['required']:
            if field in raw_output:
                transformed[field] = raw_output[field]
            else:
                # ç”Ÿæˆé»˜è®¤å€¼
                transformed[field] = self._generate_default_value(node_type, field)
                self.logger.warning(f"Missing required field '{field}' for {node_type}, using default")

        # å¤åˆ¶å¯é€‰å­—æ®µ
        for field in schema.get('optional', []):
            if field in raw_output:
                transformed[field] = raw_output[field]

        # ä¿ç•™å…¶ä»–å­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
        for key, value in raw_output.items():
            if key not in transformed:
                transformed[key] = value

        return transformed

    def prepare_node_input(self, node_type: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä¸ºèŠ‚ç‚¹å‡†å¤‡è¾“å…¥æ•°æ®ï¼Œä»ä¸Šä¸‹æ–‡ä¸­æå–æ‰€éœ€çš„ä¾èµ–æ•°æ®

        Args:
            node_type: èŠ‚ç‚¹ç±»å‹
            context: åŒ…å«æ‰€æœ‰èŠ‚ç‚¹è¾“å‡ºçš„ä¸Šä¸‹æ–‡

        Returns:
            å‡†å¤‡å¥½çš„è¾“å…¥æ•°æ®
        """
        input_data = {}

        # å¦‚æœèŠ‚ç‚¹æœ‰ä¾èµ–
        if node_type in self.NODE_DEPENDENCIES:
            deps = self.NODE_DEPENDENCIES[node_type]

            for dep_node, dep_fields in deps.items():
                # æ£€æŸ¥ä¾èµ–èŠ‚ç‚¹çš„è¾“å‡ºæ˜¯å¦å­˜åœ¨
                if dep_node in context:
                    dep_output = context[dep_node]

                    # æå–æ‰€éœ€å­—æ®µ
                    for field in dep_fields:
                        if field in dep_output:
                            input_data[field] = dep_output[field]
                        else:
                            # å°è¯•ä»å…¶ä»–å¯èƒ½çš„ä½ç½®æŸ¥æ‰¾
                            value = self._find_field_in_context(field, context)
                            if value is not None:
                                input_data[field] = value
                            else:
                                # ç”Ÿæˆé»˜è®¤å€¼
                                input_data[field] = self._generate_default_value(dep_node, field)
                                self.logger.warning(
                                    f"Missing dependency field '{field}' from {dep_node} for {node_type}"
                                )

        # æ·»åŠ åŸºç¡€ä¸Šä¸‹æ–‡ä¿¡æ¯ - å¤„ç†å‚æ•°åæ˜ å°„
        # é€šç”¨çš„æ ‡å‡†å­—æ®µååˆ°å¸¦_idåç¼€å­—æ®µåçš„æ˜ å°„
        field_mappings = {
            'theme': 'theme_id',
            'keywords': 'keywords_id',
            'target_duration': 'target_duration_id',
            'user_description': 'user_description_id'
        }

        # é¦–å…ˆå°è¯•ç›´æ¥åŒ¹é…å¸¦_idåç¼€çš„å­—æ®µ
        for key in ['theme_id', 'keywords_id', 'target_duration_id', 'user_description_id']:
            if key in context:
                input_data[key] = context[key]

        # ç„¶åå°è¯•ä»æ ‡å‡†å­—æ®µåæ˜ å°„åˆ°_idå­—æ®µå
        for standard_name, id_name in field_mappings.items():
            if id_name not in input_data:  # å¦‚æœè¿˜æ²¡æœ‰æ‰¾åˆ°å¸¦_idçš„å­—æ®µ
                # å…ˆæŸ¥æ‰¾æ ‡å‡†åç§°
                value = self._find_field_in_context(standard_name, context)
                if value is not None:
                    input_data[id_name] = value
                    self.logger.info(f"æ˜ å°„å­—æ®µ {standard_name} -> {id_name}: {value}")
                # å¦‚æœåœ¨conversation_contextä¸­æœ‰è¯¥å­—æ®µ
                elif 'conversation_context' in context and isinstance(context['conversation_context'], dict):
                    conv_context = context['conversation_context']
                    if standard_name in conv_context:
                        input_data[id_name] = conv_context[standard_name]
                        self.logger.info(f"ä»conversation_contextæ˜ å°„å­—æ®µ {standard_name} -> {id_name}: {conv_context[standard_name]}")

        # ç¡®ä¿å¯¹äºconversation_contextèŠ‚ç‚¹ï¼Œä¹Ÿè¦è¾“å‡ºæ ‡å‡†å­—æ®µå
        if node_type == 'conversation_context':
            # conversation_contextèŠ‚ç‚¹éœ€è¦è¾“å‡ºæ ‡å‡†å­—æ®µå
            for standard_name in field_mappings.keys():
                value = self._find_field_in_context(standard_name, context)
                if value is not None and standard_name not in input_data:
                    input_data[standard_name] = value

        return input_data

    def _find_field_in_context(self, field: str, context: Dict[str, Any]) -> Any:
        """åœ¨æ•´ä¸ªä¸Šä¸‹æ–‡ä¸­æŸ¥æ‰¾å­—æ®µ"""
        # ç›´æ¥åœ¨é¡¶å±‚æŸ¥æ‰¾
        if field in context:
            return context[field]

        # åœ¨æ‰€æœ‰èŠ‚ç‚¹è¾“å‡ºä¸­æŸ¥æ‰¾
        for node_name, node_output in context.items():
            if isinstance(node_output, dict) and field in node_output:
                return node_output[field]

        return None

    def _generate_default_value(self, node_type: str, field: str) -> Any:
        """ç”Ÿæˆå­—æ®µçš„é»˜è®¤å€¼"""
        # ç‰¹å®šå­—æ®µçš„é»˜è®¤å€¼
        default_values = {
            # åŸºç¡€è¾“å…¥å‚æ•°é»˜è®¤å€¼
            'theme_id': 'é€šç”¨è§†é¢‘',
            'keywords_id': ['è§†é¢‘', 'å†…å®¹'],
            'target_duration_id': 30,
            'user_description_id': 'ç”¨æˆ·è¾“å…¥æè¿°',
            'conversation_id': 'default_conversation_001',
            'user_description': 'é»˜è®¤ç”¨æˆ·æè¿°',
            'theme': 'é€šç”¨ä¸»é¢˜',
            'keywords': ['é»˜è®¤', 'å…³é”®è¯'],
            'target_duration': 30,
            # èŠ‚ç‚¹è¾“å‡ºé»˜è®¤å€¼
            'bgm_composition_id': 'default_bgm_001',
            'sfx_track_id': 'default_sfx_001',
            'scheduled_shots': [],
            'shot_blocks': [],
            'assets': [],
            'emotions_id': {'emotions': {'primary': 'neutral', 'secondary': 'calm'}},
            'emotion_curve': ['neutral'] * 10,
            'video_type_id': 'general',
            'structure_template_id': {'intro': '', 'body': '', 'conclusion': ''},
            'bgm_anchors': [],
            'transitions': [],
            'filters': [],
            'effects': [],
            'subtitles': [],
            'audio_tracks': [],  # âœ… æ–°å¢ï¼šaudio_tracksé»˜è®¤ä¸ºç©ºåˆ—è¡¨ï¼Œç¡®ä¿ç±»å‹æ­£ç¡®
            'audio_track_id': 'default_audio_001',
            'audio_file_path': '/tmp/default_audio.mp3',
            'bgm_file_path': '/tmp/default_bgm.mp3',
            'timeline_data': {},
            'final_timeline': {},
            'total_duration': 30,
            'bgm_duration': 30,
            'audio_duration': 30
        }

        if field in default_values:
            return default_values[field]

        # æ ¹æ®å­—æ®µåæ¨¡å¼ç”Ÿæˆé»˜è®¤å€¼
        if field.endswith('_id'):
            return f"default_{field}"
        elif field.endswith('_timeline'):
            return []
        elif field.endswith('_count'):
            return 0
        elif field.endswith('_duration'):
            return 30
        elif field.endswith('_path'):
            return f"/tmp/default_{field}.tmp"
        else:
            return {}

    def validate_node_chain(self, nodes: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        éªŒè¯å¹¶ä¿®å¤èŠ‚ç‚¹é“¾çš„æ•°æ®ä¼ é€’

        Args:
            nodes: èŠ‚ç‚¹åˆ—è¡¨

        Returns:
            ä¿®å¤åçš„èŠ‚ç‚¹åˆ—è¡¨
        """
        context = {}
        fixed_nodes = []

        for node in nodes:
            node_type = node.get('node_type', '')

            # å‡†å¤‡è¾“å…¥æ•°æ®
            if 'input_data' not in node or not node['input_data']:
                node['input_data'] = self.prepare_node_input(node_type, context)

            # è½¬æ¢è¾“å‡ºæ•°æ®
            if 'output_data' in node and node['output_data']:
                node['output_data'] = self.transform_node_output(node_type, node['output_data'])

                # æ›´æ–°ä¸Šä¸‹æ–‡
                context[node_type] = node['output_data']

            fixed_nodes.append(node)

        return fixed_nodes

# =============================
# VGP Data Fixer - ä¿®å¤ç°æœ‰æ•°æ®é—®é¢˜
# =============================

class VGPDataFixer:
    """ä¿®å¤VGPèŠ‚ç‚¹æ•°æ®ä¼ é€’é—®é¢˜"""

    def __init__(self):
        self.mapper = VGPDataMapper()
        self.logger = logging.getLogger(f"{__name__}.VGPDataFixer")

    def fix_bgm_composition_output(self, output_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä¿®å¤bgm_compositionèŠ‚ç‚¹è¾“å‡º"""
        # ç¡®ä¿æœ‰bgm_composition_id
        if 'bgm_composition_id' not in output_data:
            if 'bgm_id' in output_data:
                output_data['bgm_composition_id'] = output_data['bgm_id']
            elif 'composition_id' in output_data:
                output_data['bgm_composition_id'] = output_data['composition_id']
            else:
                output_data['bgm_composition_id'] = 'bgm_comp_' + str(hash(str(output_data)))[:8]

        # ç¡®ä¿æœ‰bgm_file_path
        if 'bgm_file_path' not in output_data:
            if 'file_path' in output_data:
                output_data['bgm_file_path'] = output_data['file_path']
            elif 'bgm_path' in output_data:
                output_data['bgm_file_path'] = output_data['bgm_path']
            else:
                output_data['bgm_file_path'] = f"/tmp/bgm_{output_data['bgm_composition_id']}.mp3"

        return output_data

    def fix_sfx_integration_output(self, output_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä¿®å¤sfx_integrationèŠ‚ç‚¹è¾“å‡º"""
        # ç¡®ä¿æœ‰sfx_track_id
        if 'sfx_track_id' not in output_data:
            if 'sfx_id' in output_data:
                output_data['sfx_track_id'] = output_data['sfx_id']
            elif 'track_id' in output_data:
                output_data['sfx_track_id'] = output_data['track_id']
            else:
                output_data['sfx_track_id'] = 'sfx_track_' + str(hash(str(output_data)))[:8]

        # ç¡®ä¿æœ‰sfx_timeline
        if 'sfx_timeline' not in output_data:
            if 'timeline' in output_data:
                output_data['sfx_timeline'] = output_data['timeline']
            elif 'sfx_events' in output_data:
                output_data['sfx_timeline'] = output_data['sfx_events']
            else:
                output_data['sfx_timeline'] = []

        return output_data

    def fix_shot_block_generation_output(self, output_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä¿®å¤shot_block_generationèŠ‚ç‚¹è¾“å‡º"""
        # ç¡®ä¿æœ‰scheduled_shots
        if 'scheduled_shots' not in output_data:
            if 'shots' in output_data:
                output_data['scheduled_shots'] = output_data['shots']
            elif 'shot_list' in output_data:
                output_data['scheduled_shots'] = output_data['shot_list']
            elif 'shot_blocks_id' in output_data:  # ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„å­—æ®µå shot_blocks_id
                # ä»shot_blocks_idç”Ÿæˆscheduled_shots
                output_data['scheduled_shots'] = [
                    {
                        'shot_id': f"shot_{i}",
                        'duration': block.get('duration', 2),
                        'description': block.get('description', ''),
                        'type': block.get('type', 'normal')
                    }
                    for i, block in enumerate(output_data['shot_blocks_id'])
                ]
            elif 'shot_blocks' in output_data:  # ä¿ç•™å…¼å®¹æ€§
                # ä»shot_blocksç”Ÿæˆscheduled_shots
                output_data['scheduled_shots'] = [
                    {
                        'shot_id': f"shot_{i}",
                        'duration': block.get('duration', 2),
                        'description': block.get('description', ''),
                        'type': block.get('type', 'normal')
                    }
                    for i, block in enumerate(output_data['shot_blocks'])
                ]
            else:
                output_data['scheduled_shots'] = []

        return output_data

    def fix_all_node_outputs(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ä¿®å¤æ‰€æœ‰èŠ‚ç‚¹è¾“å‡ºæ•°æ®,åŒæ—¶ä¿ç•™éèŠ‚ç‚¹çš„åŸå§‹æ•°æ®"""
        fixed_context = {}

        # å®šä¹‰å·²çŸ¥çš„VGPèŠ‚ç‚¹ç±»å‹
        known_node_types = {
            'video_type_identification', 'emotion_analysis', 'shot_block_generation',
            'bgm_anchor_planning', 'bgm_composition', 'asset_request',
            'audio_processing', 'sfx_integration', 'transition_selection',
            'filter_application', 'dynamic_effects', 'aux_media_insertion',
            'aux_text_insertion', 'subtitle_generation', 'intro_outro',
            'timeline_integration', 'multimodal_fusion', 'conversation_context'
        }

        for key, value in context.items():
            # å¦‚æœæ˜¯å·²çŸ¥èŠ‚ç‚¹ç±»å‹ä¸”æ˜¯ dict,è¿›è¡Œä¿®å¤å’Œè½¬æ¢
            if key in known_node_types and isinstance(value, dict):
                # åº”ç”¨ç‰¹å®šèŠ‚ç‚¹çš„ä¿®å¤
                if key == 'bgm_composition':
                    value = self.fix_bgm_composition_output(value)
                elif key == 'sfx_integration':
                    value = self.fix_sfx_integration_output(value)
                elif key == 'shot_block_generation':
                    value = self.fix_shot_block_generation_output(value)

                # åº”ç”¨é€šç”¨è½¬æ¢
                value = self.mapper.transform_node_output(key, value)

            # ä¿ç•™æ‰€æœ‰æ•°æ®(åŒ…æ‹¬åŸå§‹è¾“å…¥å‚æ•°å¦‚ theme_id, keywords_idç­‰)
            fixed_context[key] = value

        return fixed_context

# =============================
# é›†æˆåˆ°ä¸»æµç¨‹çš„è¾…åŠ©å‡½æ•°
# =============================

def create_data_transformer() -> VGPDataMapper:
    """åˆ›å»ºæ•°æ®è½¬æ¢å™¨å®ä¾‹"""
    return VGPDataMapper()

def create_data_fixer() -> VGPDataFixer:
    """åˆ›å»ºæ•°æ®ä¿®å¤å™¨å®ä¾‹"""
    return VGPDataFixer()

def prepare_context_for_node(node_type: str, raw_context: Dict[str, Any]) -> Dict[str, Any]:
    """
    ä¸ºç‰¹å®šèŠ‚ç‚¹å‡†å¤‡è¾“å…¥ä¸Šä¸‹æ–‡

    Args:
        node_type: èŠ‚ç‚¹ç±»å‹
        raw_context: åŸå§‹ä¸Šä¸‹æ–‡æ•°æ®

    Returns:
        å‡†å¤‡å¥½çš„è¾“å…¥æ•°æ®
    """
    transformer = create_data_transformer()
    fixer = create_data_fixer()

    # å…ˆä¿®å¤æ‰€æœ‰èŠ‚ç‚¹çš„è¾“å‡º
    fixed_context = fixer.fix_all_node_outputs(raw_context)

    # ç„¶åå‡†å¤‡èŠ‚ç‚¹è¾“å…¥
    input_data = transformer.prepare_node_input(node_type, fixed_context)

    # åˆå¹¶åŸå§‹ä¸Šä¸‹æ–‡ä¸­çš„åŸºç¡€ä¿¡æ¯
    # é€šç”¨çš„æ ‡å‡†å­—æ®µååˆ°å¸¦_idåç¼€å­—æ®µåçš„æ˜ å°„
    field_mappings = {
        'theme': 'theme_id',
        'keywords': 'keywords_id',
        'target_duration': 'target_duration_id',
        'user_description': 'user_description_id'
    }

    # DEBUG: æ‰“å° raw_context çš„å…³é”®å­—æ®µ
    print(f"\n{'='*80}")
    print(f"ğŸ” [prepare_context_for_node] node_type={node_type}")
    print(f"ğŸ” [prepare_context_for_node] raw_context keys={list(raw_context.keys())}")
    print(f"ğŸ” [prepare_context_for_node] input_data (before)={list(input_data.keys())}")
    logger.info(f"prepare_context_for_node: node_type={node_type}, raw_context keys={list(raw_context.keys())}")

    # å…ˆå¤„ç†ç›´æ¥åŒ¹é…çš„_idå­—æ®µ
    for key in ['theme_id', 'keywords_id', 'target_duration_id', 'user_description_id']:
        if key in raw_context:
            print(f"ğŸ” [prepare_context_for_node] å‘ç°å­—æ®µ {key} in raw_context: {raw_context[key]}")
            if key not in input_data:
                input_data[key] = raw_context[key]
                print(f"âœ… [prepare_context_for_node] å¤åˆ¶å­—æ®µ {key}: {raw_context[key]}")
                logger.info(f"prepare_context_for_node: ä» raw_context å¤åˆ¶å­—æ®µ {key}: {raw_context[key]}")
        else:
            print(f"âŒ [prepare_context_for_node] å­—æ®µ {key} NOT in raw_context")

    # ç„¶åå¤„ç†æ ‡å‡†å­—æ®µååˆ°_idå­—æ®µçš„æ˜ å°„
    for standard_name, id_name in field_mappings.items():
        if id_name not in input_data and standard_name in raw_context:
            input_data[id_name] = raw_context[standard_name]
            logger.info(f"prepare_context_for_node: æ˜ å°„å­—æ®µ {standard_name} -> {id_name}: {raw_context[standard_name]}")

    # DEBUG: æ‰“å°æœ€ç»ˆçš„ input_data
    print(f"ğŸ” [prepare_context_for_node] input_data (after)={list(input_data.keys())}")
    print(f"ğŸ” [prepare_context_for_node] Final values:")
    for key in ['theme_id', 'keywords_id', 'target_duration_id', 'user_description_id']:
        print(f"    {key}: {input_data.get(key, 'NOT_FOUND')}")
    print(f"{'='*80}\n")
    logger.info(f"prepare_context_for_node: æœ€ç»ˆå‡†å¤‡çš„ input_data keys={list(input_data.keys())}")

    # å¯¹äºconversation_contextèŠ‚ç‚¹ï¼Œç¡®ä¿è¾“å‡ºæ ‡å‡†å­—æ®µå
    if node_type == 'conversation_context':
        for standard_name in field_mappings.keys():
            if standard_name in raw_context and standard_name not in input_data:
                input_data[standard_name] = raw_context[standard_name]

    return input_data

def transform_node_result(node_type: str, raw_output: Dict[str, Any]) -> Dict[str, Any]:
    """
    è½¬æ¢èŠ‚ç‚¹è¾“å‡ºä¸ºæ ‡å‡†æ ¼å¼

    Args:
        node_type: èŠ‚ç‚¹ç±»å‹
        raw_output: åŸå§‹è¾“å‡º

    Returns:
        æ ‡å‡†åŒ–çš„è¾“å‡º
    """
    transformer = create_data_transformer()
    return transformer.transform_node_output(node_type, raw_output)

# æµ‹è¯•å‡½æ•°
def test_data_transformer():
    """æµ‹è¯•æ•°æ®è½¬æ¢å™¨"""
    transformer = create_data_transformer()
    fixer = create_data_fixer()

    # æ¨¡æ‹ŸèŠ‚ç‚¹è¾“å‡º
    context = {
        'bgm_composition': {
            'composition_id': 'bgm_123',
            'file_path': '/tmp/bgm.mp3'
        },
        'sfx_integration': {
            'sfx_id': 'sfx_456',
            'timeline': [{'time': 0, 'effect': 'boom'}]
        },
        'shot_block_generation': {
            'shot_blocks': [
                {'duration': 3, 'description': 'Opening shot'},
                {'duration': 2, 'description': 'Main content'}
            ]
        }
    }

    # ä¿®å¤æ•°æ®
    fixed_context = fixer.fix_all_node_outputs(context)

    print("Fixed context:")
    print(json.dumps(fixed_context, indent=2, ensure_ascii=False))

    # å‡†å¤‡audio_processingçš„è¾“å…¥
    audio_input = transformer.prepare_node_input('audio_processing', fixed_context)

    print("\nAudio processing input:")
    print(json.dumps(audio_input, indent=2, ensure_ascii=False))

    return fixed_context

if __name__ == "__main__":
    import json
    logging.basicConfig(level=logging.INFO)
    test_data_transformer()