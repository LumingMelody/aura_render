#!/usr/bin/env python3
"""
Aura Render FastAPI Application

Main FastAPI application with proper configuration management,
error handling, and API endpoints for the video generation pipeline.
"""

import sys
from pathlib import Path

# Add project root to path for imports
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

# åŠ è½½ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿æ‰€æœ‰æ¨¡å—éƒ½èƒ½è®¿é—®
from dotenv import load_dotenv
from pathlib import Path

# è·å–é¡¹ç›®æ ¹ç›®å½•å¹¶åŠ è½½.envæ–‡ä»¶
project_root = Path(__file__).parent
env_path = project_root / '.env'
load_dotenv(dotenv_path=env_path)

# éªŒè¯å…³é”®ç¯å¢ƒå˜é‡å·²åŠ è½½
import os
if not os.getenv('OSS_ACCESS_KEY_ID'):
    print("âš ï¸ è­¦å‘Š: OSSé…ç½®æœªåŠ è½½ï¼Œå›¾ç”Ÿè§†é¢‘å°†ä½¿ç”¨base64æ–¹å¼")

import asyncio
import json
import logging
import os
import uuid
from typing import Dict, Any, Optional, List
from datetime import datetime
from contextlib import asynccontextmanager

from fastapi import FastAPI, BackgroundTasks, HTTPException, Depends, status
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field, model_validator
from sqlalchemy.orm import Session
import httpx

from config import settings, get_settings
from database import get_db, init_db, TaskService, TaskStatus
from materials_api import materials_router
# from ai_api import ai_router  # âŒ å·²åˆ é™¤ /ai/generate æ¥å£
from render_api import render_router

# Import Celery task management
from api.task_endpoints import router as task_router
from task_queue.task_manager import get_task_manager

# Import system management APIs (ä¿ç•™æœ‰ç”¨çš„ç³»ç»Ÿç®¡ç†æ¥å£)
# from api.image_endpoints import router as image_router  # âŒ å·²åˆ é™¤ /image/generate æ¥å£
from api.templates_endpoints import router as templates_router
from api.analytics_endpoints import router as analytics_router
# from api.batch_endpoints import router as batch_router  # âŒ å·²åˆ é™¤æ‰¹é‡å¤„ç†æ¥å£
from api.auth_endpoints import router as auth_router
from api.export_endpoints import router as export_router
from api.websocket_endpoints import router as websocket_router
# from api.ai_optimization_endpoints import router as ai_optimization_router  # âŒ å·²åˆ é™¤AIä¼˜åŒ–æ¥å£

# =============================
# æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–ï¼ˆå¿…é¡»åœ¨å…¶ä»–å¯¼å…¥ä¹‹å‰é…ç½®ï¼‰
# =============================
from utils.logger import setup_logging, get_logger, LogCategory
from pathlib import Path

# âš ï¸ é‡è¦ï¼šå…ˆé…ç½®ç¬¬ä¸‰æ–¹åº“æ—¥å¿—çº§åˆ«ï¼Œå†åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
logging.getLogger("sqlalchemy.engine").setLevel(logging.WARNING)  # åªè®°å½•è­¦å‘Šå’Œé”™è¯¯
logging.getLogger("sqlalchemy.pool").setLevel(logging.WARNING)
logging.getLogger("sqlalchemy.dialects").setLevel(logging.WARNING)
logging.getLogger("sqlalchemy.orm").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("uvicorn.access").setLevel(logging.WARNING)  # å‡å°‘è®¿é—®æ—¥å¿—

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
log_dir = Path(__file__).parent / "logs"
setup_logging(
    log_dir=log_dir,
    log_level=logging.INFO if not settings.is_development else logging.DEBUG,
    enable_console=True,
    enable_json=True,
    enable_performance=True,
    max_file_size=100 * 1024 * 1024  # 100MB
)

# ä½¿ç”¨å¢å¼ºçš„æ—¥å¿—ç³»ç»Ÿ
logger = get_logger("aura_render.app").with_context(category=LogCategory.SYSTEM)

# =============================
# Application Lifespan Events
# =============================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan events"""
    # Startup
    logger.info("ğŸš€ Aura Render API starting up...")
    logger.info(f"ğŸ“ Environment: {'Development' if settings.is_development else 'Production'}")
    # logger.info(f"ğŸ”§ AI Model: {settings.ai.qwen_model_name}")

    # Initialize database
    try:
        init_db()
        logger.info("âœ… Database initialized")
    except Exception as e:
        logger.error(f"âŒ Database initialization failed: {e}")

    # âš ï¸ ä¸å†åœ¨ startup æ—¶åˆå§‹åŒ– VGP ç³»ç»Ÿ
    # VGP ç³»ç»Ÿå°†åœ¨ç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨åˆå§‹åŒ–ï¼ˆåœ¨åå°ä»»åŠ¡ä¸­ï¼‰
    # è¿™æ ·å¯ä»¥é¿å…é˜»å¡ç¬¬ä¸€æ¬¡ API è¯·æ±‚
    logger.info("â„¹ï¸  VGP workflow system will be initialized on first use")

    yield

    # Shutdown
    logger.info("ğŸ‘‹ Aura Render API shutting down...")

    # VGP workflow system shutdown (if initialized)
    try:
        from vgp_api import workflow_system
        if workflow_system:
            logger.info("ğŸ›‘ Shutting down VGP workflow system...")
            await workflow_system.shutdown()
            logger.info("âœ… VGP workflow system shutdown complete")
        else:
            logger.info("â„¹ï¸  VGP workflow system was not initialized, no shutdown needed")
    except Exception as e:
        logger.error(f"âŒ VGP workflow shutdown failed: {e}")

# =============================
# FastAPI App Configuration
# =============================

app = FastAPI(
    title=settings.api.title,
    description=settings.api.description,
    version=settings.api.version,
    docs_url=settings.api.docs_url if settings.is_development else None,
    redoc_url=settings.api.redoc_url if settings.is_development else None,
    lifespan=lifespan
)

# Add CORS middleware for development
if settings.is_development:
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],  # In production, specify exact origins
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

# Mount static files
app.mount("/static", StaticFiles(directory="static"), name="static")

# Include API routers
app.include_router(materials_router)
# app.include_router(ai_router)  # âŒ å·²åˆ é™¤
app.include_router(render_router)
app.include_router(task_router)  # Add Celery task management endpoints
# app.include_router(image_router)  # âŒ å·²åˆ é™¤ image generation endpoints
app.include_router(templates_router)  # Add templates system endpoints
app.include_router(analytics_router)  # Add analytics endpoints
# app.include_router(batch_router)  # âŒ å·²åˆ é™¤ batch processing endpoints
app.include_router(auth_router)  # Add authentication endpoints
app.include_router(export_router)  # Add export and cloud storage endpoints
app.include_router(websocket_router)  # Add WebSocket endpoints
# app.include_router(ai_optimization_router)  # âŒ å·²åˆ é™¤ AI optimization endpoints

# âœ¨ æ–°å¢ï¼šVGPæ–°å·¥ä½œæµAPI
try:
    from vgp_api import vgp_router
    app.include_router(vgp_router)  # Add VGP new workflow endpoints
    logger.info("âœ… VGPæ–°å·¥ä½œæµAPIå·²åŠ è½½: /vgp/generate")
except ImportError as e:
    logger.warning(f"âš ï¸ VGPæ–°å·¥ä½œæµAPIåŠ è½½å¤±è´¥: {e}")

# =============================
# Pydantic Models
# =============================

# æ–°å¢å¤šæ¨¡æ€è¾“å…¥æ¨¡å‹
class ReferenceMedia(BaseModel):
    """å‚è€ƒåª’ä½“è¾“å…¥æ¨¡å‹"""
    url: str = Field(..., description="åª’ä½“æ–‡ä»¶è·¯å¾„æˆ–URL")
    type: str = Field(..., description="åª’ä½“ç±»å‹ (style_reference, content_reference, etc.)")
    weight: float = Field(default=1.0, description="æƒé‡ (0.0-1.0)", ge=0.0, le=1.0)

class ReferenceMediaGroup(BaseModel):
    """å‚è€ƒåª’ä½“ç»„æ¨¡å‹"""
    reference_videos: Optional[List[ReferenceMedia]] = Field(default=None, description="å‚è€ƒè§†é¢‘åˆ—è¡¨", max_items=3)
    reference_images: Optional[List[ReferenceMedia]] = Field(default=None, description="å‚è€ƒå›¾ç‰‡åˆ—è¡¨", max_items=5)
    product_images: Optional[List[ReferenceMedia]] = Field(default=None, description="äº§å“å›¾ç‰‡åˆ—è¡¨", max_items=10)

class ConversationContext(BaseModel):
    """å¯¹è¯ä¸Šä¸‹æ–‡æ¨¡å‹"""
    conversation_id: str = Field(..., description="å¯¹è¯ID")
    message_id: str = Field(..., description="æ¶ˆæ¯ID")
    is_regeneration: bool = Field(default=False, description="æ˜¯å¦ä¸ºé‡æ–°ç”Ÿæˆ")
    previous_results: Optional[Dict[str, Any]] = Field(default=None, description="ä¹‹å‰çš„ç”Ÿæˆç»“æœ")

class VideoGenerationRequest(BaseModel):
    """Video generation request model - æ”¯æŒå¤šæ¨¡æ€è¾“å…¥"""
    # æ”¯æŒæ ‡å‡†å­—æ®µå
    theme: Optional[str] = Field(None, description="è§†é¢‘ä¸»é¢˜", min_length=1, max_length=200)
    keywords: Optional[List[str]] = Field(None, description="å…³é”®è¯åˆ—è¡¨", min_items=1, max_items=10)
    target_duration: Optional[int] = Field(None, description="ç›®æ ‡æ—¶é•¿ï¼ˆç§’ï¼‰", ge=5, le=3600)
    user_description: Optional[str] = Field(None, description="ç”¨æˆ·æè¿°", min_length=1, max_length=1000)

    # å‘åå…¼å®¹çš„_idå­—æ®µåï¼ˆå¯é€‰ï¼‰
    theme_id: Optional[str] = Field(None, description="è§†é¢‘ä¸»é¢˜ï¼ˆåˆ«åï¼‰", min_length=1, max_length=200)
    keywords_id: Optional[List[str]] = Field(None, description="å…³é”®è¯åˆ—è¡¨ï¼ˆåˆ«åï¼‰", min_items=1, max_items=10)
    target_duration_id: Optional[int] = Field(None, description="ç›®æ ‡æ—¶é•¿ï¼ˆç§’ï¼Œåˆ«åï¼‰", ge=5, le=3600)
    user_description_id: Optional[str] = Field(None, description="ç”¨æˆ·æè¿°ï¼ˆåˆ«åï¼‰", min_length=1, max_length=1000)
    template: Optional[str] = Field(default="vgp_new_pipeline", description="VGPç®¡é“")

    # æ–°å¢å¤šæ¨¡æ€è¾“å…¥æ”¯æŒ
    reference_media: Optional[ReferenceMediaGroup] = Field(default=None, description="å‚è€ƒåª’ä½“è¾“å…¥")
    conversation_context: Optional[ConversationContext] = Field(default=None, description="å¯¹è¯ä¸Šä¸‹æ–‡")

    @model_validator(mode='after')
    def validate_required_fields(self):
        """éªŒè¯å¿…éœ€å­—æ®µï¼Œç¡®ä¿æ¯å¯¹å­—æ®µè‡³å°‘æœ‰ä¸€ä¸ªå­˜åœ¨"""
        # éªŒè¯themeå­—æ®µ
        if not self.theme and not self.theme_id:
            raise ValueError("theme æˆ– theme_id å¿…é¡»æä¾›å…¶ä¸­ä¹‹ä¸€")

        # éªŒè¯keywordså­—æ®µ
        if not self.keywords and not self.keywords_id:
            raise ValueError("keywords æˆ– keywords_id å¿…é¡»æä¾›å…¶ä¸­ä¹‹ä¸€")

        # éªŒè¯target_durationå­—æ®µ
        if self.target_duration is None and self.target_duration_id is None:
            raise ValueError("target_duration æˆ– target_duration_id å¿…é¡»æä¾›å…¶ä¸­ä¹‹ä¸€")

        # éªŒè¯user_descriptionå­—æ®µ
        if not self.user_description and not self.user_description_id:
            raise ValueError("user_description æˆ– user_description_id å¿…é¡»æä¾›å…¶ä¸­ä¹‹ä¸€")

        # è§„èŒƒåŒ–å­—æ®µï¼šå¦‚æœæä¾›äº†æ ‡å‡†å­—æ®µåï¼Œè‡ªåŠ¨è®¾ç½®_idå­—æ®µ
        if self.theme and not self.theme_id:
            self.theme_id = self.theme
        elif self.theme_id and not self.theme:
            self.theme = self.theme_id

        if self.keywords and not self.keywords_id:
            self.keywords_id = self.keywords
        elif self.keywords_id and not self.keywords:
            self.keywords = self.keywords_id

        if self.target_duration is not None and self.target_duration_id is None:
            self.target_duration_id = self.target_duration
        elif self.target_duration_id is not None and self.target_duration is None:
            self.target_duration = self.target_duration_id

        if self.user_description and not self.user_description_id:
            self.user_description_id = self.user_description
        elif self.user_description_id and not self.user_description:
            self.user_description = self.user_description_id

        return self

    class Config:
        json_schema_extra = {
            "example": {
                "theme_id": "AIäº§å“å±•ç¤º",
                "keywords_id": ["äººå·¥æ™ºèƒ½", "åˆ›æ–°", "æŠ€æœ¯"],
                "target_duration_id": 60,
                "user_description_id": "åˆ¶ä½œä¸€ä¸ª60ç§’çš„AIäº§å“å®£ä¼ è§†é¢‘",
                "reference_media": {
                    "reference_videos": [
                        {"url": "path/to/reference.mp4", "type": "style_reference", "weight": 0.7}
                    ],
                    "reference_images": [
                        {"url": "path/to/style.jpg", "type": "style_guide", "weight": 0.8}
                    ],
                    "product_images": [
                        {"url": "path/to/product.jpg", "type": "main_product", "weight": 1.0}
                    ]
                },
                "conversation_context": {
                    "conversation_id": "conv_12345",
                    "message_id": "msg_001",
                    "is_regeneration": False,
                    "previous_results": None
                }
            }
        }


class TaskResponse(BaseModel):
    """Task response model"""
    task_id: str
    status: str
    message: str
    timestamp: datetime


class HealthResponse(BaseModel):
    """Health check response model"""
    status: str
    timestamp: datetime
    version: str
    environment: str


# =============================
# VGP Node Management System
# =============================

# Import VGP Protocol Tools
from video_generate_protocol.vgp_protocol import VGPProtocol, VGPDocument, VGPNodeData, NodeStatus
from video_generate_protocol.vgp_data_transformer import (
    VGPDataMapper, VGPDataFixer,
    prepare_context_for_node, transform_node_result
)

# Import VGP nodes (16ä¸ªæ ‡å‡†èŠ‚ç‚¹)
from video_generate_protocol.nodes.video_type_identification_node import VideoTypeIdentificationNode
from video_generate_protocol.nodes.emotion_analysis_node import EmotionAnalysisNode
from video_generate_protocol.nodes.shot_block_generation_node import ShotBlockGenerationNode
from video_generate_protocol.nodes.bgm_anchor_planning_node import BGMAanchorPlanningNode
from video_generate_protocol.nodes.bgm_composition_node import BGMCompositionNode
from video_generate_protocol.nodes.asset_request_node import AssetRequestNode
from video_generate_protocol.nodes.audio_processing_node import AudioProcessingNode
from video_generate_protocol.nodes.sfx_integration_node import SFXIntegrationNode
from video_generate_protocol.nodes.transition_selection_node import TransitionSelectionNode
from video_generate_protocol.nodes.filter_application_node import FilterApplicationNode
from video_generate_protocol.nodes.dynamic_effects_node import DynamicEffectsNode
from video_generate_protocol.nodes.aux_media_insertion_node import AuxMediaInsertionNode
from video_generate_protocol.nodes.aux_text_insertion_node import AuxTextInsertionNode
from video_generate_protocol.nodes.subtitle_node import SubtitleNode
from video_generate_protocol.nodes.intro_outro_node import IntroOutroNode
from video_generate_protocol.nodes.timeline_integration_node import TimelineIntegrationNode


def extract_node_outputs(node_id: str, node_output: dict) -> dict:
    """
    ä»èŠ‚ç‚¹è¾“å‡ºä¸­æå–ç‰¹å®šå­—æ®µï¼Œä¾›ä¸‹æ¸¸èŠ‚ç‚¹ä½¿ç”¨

    Args:
        node_id: èŠ‚ç‚¹ID
        node_output: èŠ‚ç‚¹è¾“å‡ºæ•°æ®

    Returns:
        æå–çš„è¾“å‡ºå­—æ®µå­—å…¸
    """
    extracted = {}

    # æ ¹æ®èŠ‚ç‚¹ç±»å‹æå–ç‰¹å®šè¾“å‡ºå­—æ®µ
    if node_id == "video_type_identification":
        # æå–è§†é¢‘ç±»å‹å’Œç»“æ„æ¨¡æ¿
        if "video_type_id" in node_output:
            extracted["video_type_id"] = node_output["video_type_id"]
        if "structure_template_id" in node_output:
            extracted["structure_template_id"] = node_output["structure_template_id"]

    elif node_id == "emotion_analysis":
        # æå–æƒ…æ„Ÿåˆ†æç»“æœ
        if "emotions_id" in node_output:
            extracted["emotions_id"] = node_output["emotions_id"]
        # ä¹Ÿå¯èƒ½åœ¨ä¸åŒçš„é”®ä¸‹
        if "emotions" in node_output:
            extracted["emotions_id"] = node_output["emotions"]

    elif node_id == "shot_block_generation":
        # æå–åˆ†é•œæ•°æ®
        if "shot_blocks_id" in node_output:
            extracted["shot_blocks_id"] = node_output["shot_blocks_id"]
        if "shot_blocks" in node_output:
            extracted["shot_blocks_id"] = node_output["shot_blocks"]

    elif node_id == "bgm_anchor_planning":
        if "bgm_anchors" in node_output:
            extracted["bgm_anchors"] = node_output["bgm_anchors"]
        if "bgm_timeline" in node_output:
            extracted["bgm_timeline"] = node_output["bgm_timeline"]

    elif node_id == "bgm_composition":
        if "bgm_tracks" in node_output:
            extracted["bgm_tracks"] = node_output["bgm_tracks"]
        if "bgm_tracks_id" in node_output:
            extracted["bgm_tracks_id"] = node_output["bgm_tracks_id"]
        if "bgm_composition_id" in node_output:
            extracted["bgm_composition_id"] = node_output["bgm_composition_id"]

    elif node_id == "audio_processing":
        if "audio_track_id" in node_output:
            extracted["audio_track_id"] = node_output["audio_track_id"]
        if "audio_file_path" in node_output:
            extracted["audio_file_path"] = node_output["audio_file_path"]

    elif node_id == "transition_selection":
        if "transitions" in node_output:
            extracted["transitions"] = node_output["transitions"]
        if "preliminary_sequence_id" in node_output:
            extracted["preliminary_sequence_id"] = node_output["preliminary_sequence_id"]

    elif node_id == "filter_application":
        if "filters" in node_output:
            extracted["filters"] = node_output["filters"]
        if "transition_sequence_id" in node_output:
            extracted["transition_sequence_id"] = node_output["transition_sequence_id"]

    elif node_id == "dynamic_effects":
        if "effects" in node_output:
            extracted["effects"] = node_output["effects"]
        if "filter_sequence_id" in node_output:
            extracted["filter_sequence_id"] = node_output["filter_sequence_id"]

    elif node_id == "timeline_integration":
        if "video_clips" in node_output:
            extracted["video_clips"] = node_output["video_clips"]
        if "audio_tracks" in node_output:
            extracted["audio_tracks"] = node_output["audio_tracks"]

    # é€šç”¨æå–ï¼šå¦‚æœè¾“å‡ºå­—æ®µä»¥_idç»“å°¾ï¼Œæå–å®ƒ
    for key, value in node_output.items():
        if key.endswith("_id") and key not in extracted:
            extracted[key] = value

    return extracted


class VGPNodeManager:
    """VGP Standard Node Manager - ç®¡ç†18ä¸ªæ ‡å‡†VGPèŠ‚ç‚¹"""

    def __init__(self):
        self.nodes = {}
        self.node_instances = {}
        self.vgp_protocol = VGPProtocol()  # VGPåè®®ç®¡ç†å™¨
        self.data_mapper = VGPDataMapper()  # æ•°æ®æ˜ å°„å™¨
        self.data_fixer = VGPDataFixer()  # æ•°æ®ä¿®å¤å™¨
        self._initialize_vgp_nodes()

    def _initialize_vgp_nodes(self):
        """åˆå§‹åŒ–æ‰€æœ‰VGPæ ‡å‡†èŠ‚ç‚¹å®ä¾‹"""
        # å®šä¹‰VGPèŠ‚ç‚¹æ‰§è¡Œé¡ºåºå’Œé…ç½®
        self.vgp_node_sequence = [
            ('video_type_identification', VideoTypeIdentificationNode, 'è§†é¢‘ç±»å‹è¯†åˆ«'),
            ('emotion_analysis', EmotionAnalysisNode, 'æƒ…æ„ŸåŸºè°ƒåˆ†æ'),
            ('shot_block_generation', ShotBlockGenerationNode, 'åˆ†é•œå—ç”Ÿæˆ'),
            ('bgm_anchor_planning', BGMAanchorPlanningNode, 'BGMé”šç‚¹è§„åˆ’'),
            ('bgm_composition', BGMCompositionNode, 'BGMåˆæˆæŸ¥æ‰¾'),
            ('asset_request', AssetRequestNode, 'ç´ æéœ€æ±‚è§£æ'),
            ('audio_processing', AudioProcessingNode, 'éŸ³é¢‘å¤„ç†'),
            ('sfx_integration', SFXIntegrationNode, 'éŸ³æ•ˆæ·»åŠ '),
            ('transition_selection', TransitionSelectionNode, 'è½¬åœºé€‰æ‹©'),
            ('filter_application', FilterApplicationNode, 'æ»¤é•œåº”ç”¨'),
            ('dynamic_effects', DynamicEffectsNode, 'åŠ¨æ€ç‰¹æ•ˆæ·»åŠ '),
            ('aux_media_insertion', AuxMediaInsertionNode, 'é¢å¤–åª’ä½“æ’å…¥'),
            ('aux_text_insertion', AuxTextInsertionNode, 'è£…é¥°æ–‡å­—æ’å…¥'),
            ('subtitle_generation', SubtitleNode, 'å­—å¹•ç”Ÿæˆ'),
            ('intro_outro', IntroOutroNode, 'ç‰‡å¤´ç‰‡å°¾ç”Ÿæˆ'),
            ('timeline_integration', TimelineIntegrationNode, 'æœ€ç»ˆæ—¶é—´çº¿æ•´åˆ')
        ]

        # åˆ›å»ºèŠ‚ç‚¹å®ä¾‹
        for node_id, node_class, description in self.vgp_node_sequence:
            try:
                # åˆ›å»ºèŠ‚ç‚¹å®ä¾‹
                instance = node_class(node_id=f"{node_id}_{uuid.uuid4().hex[:8]}", name=description)
                self.node_instances[node_id] = instance

                # æ³¨å†ŒèŠ‚ç‚¹ä¿¡æ¯
                self.nodes[node_id] = {
                    'name': node_class.__name__,
                    'description': description,
                    'status': 'available',
                    'instance': instance
                }
                logger.info(f"âœ… VGPèŠ‚ç‚¹å·²åŠ è½½: {node_id} - {description}")

            except Exception as e:
                logger.error(f"âŒ VGPèŠ‚ç‚¹åŠ è½½å¤±è´¥: {node_id} - {e}")
                self.nodes[node_id] = {
                    'name': node_class.__name__,
                    'description': f"{description} (åŠ è½½å¤±è´¥)",
                    'status': 'error',
                    'error': str(e)
                }

        logger.info(f"ğŸ¯ VGPèŠ‚ç‚¹ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ: {len(self.node_instances)}/{len(self.vgp_node_sequence)} ä¸ªèŠ‚ç‚¹å¯ç”¨")
        logger.info(f"âœ… Loaded {len(self.nodes)} nodes")
    
    def get_available_nodes(self) -> Dict[str, Any]:
        """Get list of available nodes"""
        return {k: v for k, v in self.nodes.items() if v['status'] == 'available'}
    
    async def execute_node(self, node_id: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒVGPæ ‡å‡†èŠ‚ç‚¹ - å¸¦æ•°æ®ä¿®å¤å’Œè½¬æ¢"""
        if node_id not in self.nodes:
            raise ValueError(f"VGPèŠ‚ç‚¹ä¸å­˜åœ¨: {node_id}")

        node_info = self.nodes[node_id]
        if node_info['status'] != 'available':
            raise RuntimeError(f"VGPèŠ‚ç‚¹ä¸å¯ç”¨: {node_id} - {node_info.get('error', 'æœªçŸ¥é”™è¯¯')}")

        logger.info(f"ğŸ¬ æ‰§è¡ŒVGPèŠ‚ç‚¹: {node_id} - {node_info['description']}")

        try:
            # è·å–èŠ‚ç‚¹å®ä¾‹
            node_instance = self.node_instances[node_id]

            # DEBUG: æ‰“å°è¾“å…¥ context
            print(f"\nğŸ¬ [execute_node] Starting node: {node_id}")
            print(f"ğŸ¬ [execute_node] Input context keys: {list(context.keys())}")
            for key in ['theme_id', 'keywords_id', 'target_duration_id', 'user_description_id']:
                if key in context:
                    print(f"ğŸ¬ [execute_node] context[{key}] = {context[key]}")

            # ä¿®å¤ä¸Šä¸‹æ–‡ä¸­çš„æ•°æ®é—®é¢˜
            fixed_context = self.data_fixer.fix_all_node_outputs(context)
            print(f"ğŸ¬ [execute_node] Fixed context keys: {list(fixed_context.keys())}")

            # ä¸ºèŠ‚ç‚¹å‡†å¤‡è¾“å…¥æ•°æ®
            prepared_input = prepare_context_for_node(node_id, fixed_context)
            print(f"ğŸ¬ [execute_node] Prepared input keys: {list(prepared_input.keys())}")

            # åˆå¹¶å‡†å¤‡å¥½çš„è¾“å…¥åˆ°ä¸Šä¸‹æ–‡
            execution_context = {**fixed_context, **prepared_input}
            print(f"ğŸ¬ [execute_node] Execution context keys: {list(execution_context.keys())}")
            for key in ['theme_id', 'keywords_id', 'target_duration_id', 'user_description_id']:
                if key in execution_context:
                    print(f"ğŸ¬ [execute_node] execution_context[{key}] = {execution_context[key]}")
            print(f"ğŸ¬ [execute_node] Calling node.generate()...\n")

            # æ‰§è¡ŒèŠ‚ç‚¹çš„generateæ–¹æ³•
            result = await node_instance.generate(execution_context)

            # è½¬æ¢è¾“å‡ºä¸ºæ ‡å‡†æ ¼å¼
            standardized_result = transform_node_result(node_id, result)

            logger.info(f"âœ… VGPèŠ‚ç‚¹æ‰§è¡ŒæˆåŠŸ: {node_id}")
            logger.debug(f"ğŸ“‹ èŠ‚ç‚¹è¾“å‡º: {standardized_result}")

            # è¿”å›æ ‡å‡†åŒ–çš„ç»“æœï¼ŒåŒ…å«èŠ‚ç‚¹IDæ ‡è¯†
            return {node_id: standardized_result}

        except Exception as e:
            error_msg = f"VGPèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥ {node_id}: {str(e)}"
            logger.error(error_msg)

            # è¿”å›é”™è¯¯ä¿¡æ¯ä½†ä¸é˜»æ–­æµç¨‹ï¼ˆæŸäº›èŠ‚ç‚¹å¤±è´¥å¯ä»¥ç»§ç»­ï¼‰
            return {
                node_id: {
                    'error': error_msg,
                    'node_id': node_id,
                    'status': 'failed'
                }
            }




# Global VGP node manager
node_manager = VGPNodeManager()

# =============================
# Utility Functions
# =============================

async def send_callback(task_id: str, node_index: int, status: str, message: str):
    """Send callback notification"""
    # Skip callback in development mode or when callback URL is not configured
    if settings.is_development or not settings.external.callback_url or \
       settings.external.callback_url.startswith("http://192.168.10.16"):
        logger.info(f"ğŸ“‹ Task {task_id} - Node {node_index}: {status} - {message}")
        return
    
    task_status = 3 if status == "failed" else 2
    
    payload = {
        "taskId": task_id,
        "taskStatus": task_status,
        "key": f"node{node_index}",
        "val": status,
        "remark": message
    }
    
    try:
        async with httpx.AsyncClient(timeout=settings.performance.http_timeout) as client:
            response = await client.post(settings.external.callback_url, json=payload)
            if response.status_code == 200:
                logger.info(f"âœ… Callback sent for task {task_id}")
            else:
                logger.warning(f"âš ï¸ Callback failed with status {response.status_code}")
    except Exception as e:
        logger.error(f"âŒ Callback error for task {task_id}: {e}")


# =============================
# API Endpoints
# =============================

@app.get("/")
async def read_index():
    """Serve main web application"""
    return FileResponse('static/index.html')

@app.get("/admin")
async def read_admin():
    """Serve admin dashboard"""
    return FileResponse('static/admin.html')

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint"""
    return HealthResponse(
        status="healthy",
        timestamp=datetime.now(),
        version=settings.api.version,
        environment="development" if settings.is_development else "production"
    )


@app.get("/nodes")
async def list_nodes():
    """List available processing nodes"""
    nodes = node_manager.get_available_nodes()
    return {
        "nodes": nodes,
        "count": len(nodes),
        "timestamp": datetime.now()
    }


@app.post("/generate", response_model=TaskResponse)
async def generate_video(
    request: VideoGenerationRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db),
    settings: Any = Depends(get_settings)
):
    """Generate video from user input"""
    try:
        # Create task in database
        task = TaskService.create_task(
            db=db,
            theme=request.theme_id,
            keywords=request.keywords_id,
            target_duration=request.target_duration_id,
            user_description=request.user_description_id
        )
        
        logger.info(f"ğŸš€ Starting video generation task: {task.task_id}")
        
        # Add background task for processing
        background_tasks.add_task(
            process_video_generation,
            task_id=task.task_id,
            request=request
        )
        
        return TaskResponse(
            task_id=task.task_id,
            status="started",
            message="è§†é¢‘ç”Ÿæˆä»»åŠ¡å·²å¯åŠ¨",
            timestamp=datetime.now()
        )
    except Exception as e:
        logger.error(f"âŒ Failed to create task: {e}")
        raise HTTPException(status_code=500, detail="Failed to create task")


@app.get("/task/{task_id}/status")
async def get_task_status(task_id: str, db: Session = Depends(get_db)):
    """Get task status from database"""
    task = TaskService.get_task_by_id(db, task_id)
    if not task:
        raise HTTPException(status_code=404, detail="Task not found")
    
    return task.to_dict()


@app.get("/tasks")
async def list_tasks(
    status: Optional[str] = None,
    limit: int = 20,
    db: Session = Depends(get_db)
):
    """List recent tasks, optionally filtered by status"""
    try:
        if status:
            # Convert string status to TaskStatus enum
            task_status = TaskStatus(status.lower())
            tasks = TaskService.get_tasks_by_status(db, task_status, limit)
        else:
            tasks = TaskService.get_recent_tasks(db, limit)
        
        return {
            "tasks": [task.to_dict() for task in tasks],
            "count": len(tasks),
            "timestamp": datetime.now()
        }
    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"Invalid status: {status}")


@app.get("/database/stats")
async def get_database_stats(db: Session = Depends(get_db)):
    """Get database statistics"""
    from database.base import get_db_stats
    from database.models import Task, Project
    
    try:
        total_tasks = db.query(Task).count()
        total_projects = db.query(Project).count()
        
        pending_tasks = db.query(Task).filter(Task.status == TaskStatus.PENDING).count()
        processing_tasks = db.query(Task).filter(Task.status == TaskStatus.PROCESSING).count()
        completed_tasks = db.query(Task).filter(Task.status == TaskStatus.COMPLETED).count()
        failed_tasks = db.query(Task).filter(Task.status == TaskStatus.FAILED).count()
        
        return {
            "database": get_db_stats(),
            "tasks": {
                "total": total_tasks,
                "pending": pending_tasks,
                "processing": processing_tasks,
                "completed": completed_tasks,
                "failed": failed_tasks
            },
            "projects": {
                "total": total_projects
            },
            "timestamp": datetime.now()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get stats: {e}")


# =============================
# Helper Functions
# =============================

def generate_vgp_summary(results: dict) -> dict:
    """ç”ŸæˆVGPåˆ†ææ‘˜è¦"""
    try:
        # å®‰å…¨æå–æ•°æ®ï¼Œå¤„ç†å¯èƒ½çš„å¤æ‚å¯¹è±¡
        def safe_extract(data, *keys, default=None):
            """å®‰å…¨æå–åµŒå¥—å­—å…¸æ•°æ®"""
            current = data
            for key in keys:
                if isinstance(current, dict) and key in current:
                    current = current[key]
                else:
                    return default
            return current

        summary = {
            "video_type": safe_extract(results, 'video_type_identification', 'video_type', default='æœªçŸ¥'),
            "emotions": safe_extract(results, 'emotion_analysis', 'emotions', default={}),
            "shot_count": len(safe_extract(results, 'shot_block_generation', 'shot_blocks', default=[])),
            "asset_count": len(safe_extract(results, 'asset_request', 'assets', default=[])),
            "subtitle_count": len(safe_extract(results, 'subtitle_generation', 'subtitles', default=[]))
        }
        return summary
    except Exception as e:
        print(f"ç”ŸæˆVGPæ‘˜è¦å¤±è´¥: {e}")
        return {"error": str(e)}

def serialize_results(results: dict) -> dict:
    """åºåˆ—åŒ–VGPç»“æœä¸ºå¯JSONåŒ–çš„æ ¼å¼"""
    visited = set()

    def serialize_object(obj):
        """é€’å½’åºåˆ—åŒ–å¯¹è±¡,é˜²æ­¢å¾ªç¯å¼•ç”¨"""
        # æ£€æµ‹å¾ªç¯å¼•ç”¨
        obj_id = id(obj)
        if obj_id in visited:
            return f"<circular_ref:{type(obj).__name__}@{hex(obj_id)[-6:]}>"

        # åŸºæœ¬ç±»å‹ç›´æ¥è¿”å›
        if isinstance(obj, (str, int, float, bool, type(None))):
            return obj

        # æ ‡è®°ä¸ºå·²è®¿é—®
        visited.add(obj_id)

        try:
            if hasattr(obj, '__dict__'):
                # å¦‚æœæ˜¯è‡ªå®šä¹‰å¯¹è±¡,è½¬æ¢ä¸ºå­—å…¸
                return {k: serialize_object(v) for k, v in obj.__dict__.items() if not k.startswith('_')}
            elif isinstance(obj, dict):
                return {k: serialize_object(v) for k, v in obj.items()}
            elif isinstance(obj, (list, tuple)):
                return [serialize_object(item) for item in obj]
            else:
                # å…¶ä»–ç±»å‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                return str(obj)
        finally:
            # å¤„ç†å®Œåç§»é™¤æ ‡è®°,å…è®¸åŒä¸€å¯¹è±¡åœ¨ä¸åŒåˆ†æ”¯ä¸­å‡ºç°
            visited.discard(obj_id)

    return serialize_object(results)


# =============================
# Multimodal Processing Functions
# =============================

async def process_reference_media(reference_media: ReferenceMediaGroup) -> List[Dict[str, Any]]:
    """å¤„ç†å‚è€ƒåª’ä½“è¾“å…¥"""
    from multimodal.analyzers.reference_video_analyzer import ReferenceVideoAnalyzer

    processed_media = []

    try:
        # åˆå§‹åŒ–åˆ†æå™¨
        video_analyzer = ReferenceVideoAnalyzer()

        # å¤„ç†å‚è€ƒè§†é¢‘
        if reference_media.reference_videos:
            logger.info(f"ğŸ¬ å¤„ç† {len(reference_media.reference_videos)} ä¸ªå‚è€ƒè§†é¢‘")

            for video_ref in reference_media.reference_videos:
                try:
                    analysis_result = await video_analyzer.analyze_reference_video(
                        video_ref.url,
                        video_ref.type,
                        video_ref.weight
                    )

                    processed_media.append({
                        "media_type": "video",
                        "original_input": video_ref.dict(),
                        "analysis_result": analysis_result,
                        "processing_status": "success"
                    })

                    logger.info(f"âœ… è§†é¢‘åˆ†æå®Œæˆ: {video_ref.url}")

                except Exception as e:
                    logger.error(f"âŒ è§†é¢‘åˆ†æå¤±è´¥ {video_ref.url}: {e}")
                    processed_media.append({
                        "media_type": "video",
                        "original_input": video_ref.dict(),
                        "error": str(e),
                        "processing_status": "failed"
                    })

        # å¤„ç†å‚è€ƒå›¾ç‰‡ - Day 2åŠŸèƒ½å®ç°
        if reference_media.reference_images:
            logger.info(f"ğŸ–¼ï¸  å¤„ç† {len(reference_media.reference_images)} ä¸ªå‚è€ƒå›¾ç‰‡")

            from multimodal.analyzers.reference_image_analyzer import ReferenceImageAnalyzer
            image_analyzer = ReferenceImageAnalyzer()

            for image_ref in reference_media.reference_images:
                try:
                    analysis_result = await image_analyzer.analyze_reference_image(
                        image_ref.url,
                        image_ref.type,
                        image_ref.weight
                    )

                    processed_media.append({
                        "media_type": "image",
                        "original_input": image_ref.dict(),
                        "analysis_result": analysis_result,
                        "processing_status": "success"
                    })

                    logger.info(f"âœ… å›¾ç‰‡åˆ†æå®Œæˆ: {image_ref.url}")

                except Exception as e:
                    logger.error(f"âŒ å›¾ç‰‡åˆ†æå¤±è´¥ {image_ref.url}: {e}")
                    processed_media.append({
                        "media_type": "image",
                        "original_input": image_ref.dict(),
                        "error": str(e),
                        "processing_status": "failed"
                    })

        # å¤„ç†äº§å“å›¾ç‰‡ - Day 2åŠŸèƒ½å®ç°
        if reference_media.product_images:
            logger.info(f"ğŸ“¦ å¤„ç† {len(reference_media.product_images)} ä¸ªäº§å“å›¾ç‰‡")

            # å¤ç”¨å›¾ç‰‡åˆ†æå™¨è¿›è¡Œäº§å“å›¾åˆ†æ
            if 'image_analyzer' not in locals():
                from multimodal.analyzers.reference_image_analyzer import ReferenceImageAnalyzer
                image_analyzer = ReferenceImageAnalyzer()

            for product_ref in reference_media.product_images:
                try:
                    analysis_result = await image_analyzer.analyze_reference_image(
                        product_ref.url,
                        product_ref.type,
                        product_ref.weight
                    )

                    processed_media.append({
                        "media_type": "product_image",
                        "original_input": product_ref.dict(),
                        "analysis_result": analysis_result,
                        "processing_status": "success"
                    })

                    logger.info(f"âœ… äº§å“å›¾åˆ†æå®Œæˆ: {product_ref.url}")

                except Exception as e:
                    logger.error(f"âŒ äº§å“å›¾åˆ†æå¤±è´¥ {product_ref.url}: {e}")
                    processed_media.append({
                        "media_type": "product_image",
                        "original_input": product_ref.dict(),
                        "error": str(e),
                        "processing_status": "failed"
                    })

        logger.info(f"ğŸ¯ å¤šæ¨¡æ€å¤„ç†å®Œæˆ: {len(processed_media)} ä¸ªåª’ä½“æ–‡ä»¶")
        return processed_media

    except Exception as e:
        logger.error(f"âŒ å¤šæ¨¡æ€å¤„ç†å¤±è´¥: {e}")
        return [{
            "error": str(e),
            "processing_status": "failed"
        }]

# =============================
# Background Tasks
# =============================

async def process_video_generation(task_id: str, request: VideoGenerationRequest):
    """Process video generation in background with database persistence"""
    from database.base import SessionLocal
    
    db = SessionLocal()
    try:
        # Update task status to processing
        TaskService.update_task_status(
            db, task_id, TaskStatus.PROCESSING, 
            progress=0.0, message="å¼€å§‹å¤„ç†è§†é¢‘ç”Ÿæˆä»»åŠ¡"
        )
        
        logger.info(f"ğŸš€ Starting background processing for task {task_id}")
        print(f"ğŸš€ Starting background processing for task {task_id}")
        
        # Convert request to context with multimodal support
        context = {
            "theme_id": request.theme_id,
            "keywords_id": request.keywords_id,
            "target_duration_id": request.target_duration_id,
            "user_description_id": request.user_description_id
        }

        # å¤„ç†å¤šæ¨¡æ€è¾“å…¥
        if request.reference_media:
            processed_media = await process_reference_media(request.reference_media)
            context["reference_media"] = processed_media
            logger.info(f"ğŸ¬ å¤šæ¨¡æ€è¾“å…¥å¤„ç†å®Œæˆ: {len(processed_media)} ä¸ªåª’ä½“æ–‡ä»¶")

            # Day 3: å¤šæ¨¡æ€èåˆå¤„ç†
            if processed_media:
                try:
                    from multimodal.fusion.multimodal_fusion_engine import MultiModalFusionEngine

                    fusion_engine = MultiModalFusionEngine()

                    # åˆ†ç±»åˆ†æç»“æœ
                    categorized_media = {
                        'video_analyses': [],
                        'image_analyses': [],
                        'product_analyses': []
                    }

                    for media in processed_media:
                        if media.get('processing_status') == 'success':
                            analysis_result = media.get('analysis_result')
                            if analysis_result:
                                media_type = media.get('media_type', '')
                                if media_type == 'video':
                                    categorized_media['video_analyses'].append(analysis_result)
                                elif media_type == 'image':
                                    categorized_media['image_analyses'].append(analysis_result)
                                elif media_type == 'product_image':
                                    categorized_media['product_analyses'].append(analysis_result)

                    # æ‰§è¡Œå¤šæ¨¡æ€èåˆ
                    fusion_result = await fusion_engine.fuse_multimodal_inputs(categorized_media)
                    context["multimodal_fusion"] = fusion_result

                    logger.info(f"ğŸ”„ å¤šæ¨¡æ€èåˆå®Œæˆï¼Œç½®ä¿¡åº¦: {fusion_result.get('confidence_score', 0):.2f}")

                    # æ›´æ–°ä»»åŠ¡è¿›åº¦
                    TaskService.update_task_status(
                        db, task_id, TaskStatus.PROCESSING,
                        progress=10.0, message=f"å¤šæ¨¡æ€èåˆå®Œæˆ (ç½®ä¿¡åº¦: {fusion_result.get('confidence_score', 0):.2f})"
                    )

                except Exception as e:
                    logger.error(f"âŒ å¤šæ¨¡æ€èåˆå¤±è´¥: {e}")
                    context["multimodal_fusion"] = {"error": str(e), "fallback": True}

        # å¤„ç†å¯¹è¯ä¸Šä¸‹æ–‡ - æ™ºèƒ½å¯¹è¯ä¿®æ”¹åŠŸèƒ½
        conversation_result = None
        if request.conversation_context:
            try:
                from conversation.conversation_manager import conversation_manager

                # å¤„ç†å¯¹è¯è¯·æ±‚ï¼Œè¿›è¡Œæ„å›¾åˆ†æ
                conversation_result = await conversation_manager.process_conversation_request(
                    {
                        "theme_id": request.theme_id,
                        "keywords_id": request.keywords_id,
                        "target_duration_id": request.target_duration_id,
                        "user_description_id": request.user_description_id
                    },
                    request.conversation_context.dict()
                )

                context["conversation_context"] = request.conversation_context.dict()
                context["is_regeneration"] = request.conversation_context.is_regeneration

                # å¦‚æœè¯†åˆ«åˆ°å¢é‡ä¿®æ”¹æ¨¡å¼
                if conversation_result.get("incremental_mode"):
                    logger.info(f"ğŸ”„ å¢é‡ä¿®æ”¹æ¨¡å¼: {conversation_result.get('intent_analysis')}")
                    context["incremental_mode"] = True
                    context["modifications"] = conversation_result.get("modifications")
                    context["nodes_to_update"] = conversation_result.get("nodes_to_update", [])
                    context["skip_nodes"] = conversation_result.get("skip_nodes", [])

                    # æ›´æ–°ä»»åŠ¡æ¶ˆæ¯
                    TaskService.update_task_status(
                        db, task_id, TaskStatus.PROCESSING,
                        progress=5.0,
                        message=f"æ™ºèƒ½å¯¹è¯åˆ†æ: {conversation_result.get('intent_analysis', {}).get('modification_type', 'è°ƒæ•´')}"
                    )
                else:
                    logger.info(f"ğŸ’¬ å¯¹è¯ä¸Šä¸‹æ–‡: {request.conversation_context.conversation_id}")

            except Exception as e:
                logger.warning(f"å¯¹è¯ç®¡ç†å™¨å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å¼: {e}")
                context["conversation_context"] = request.conversation_context.dict()
                context["is_regeneration"] = request.conversation_context.is_regeneration

        # å¦‚æœæ˜¯é‡æ–°ç”Ÿæˆä¸”æ²¡æœ‰å¢é‡ä¿®æ”¹ï¼ŒåŠ è½½ä¹‹å‰çš„ç»“æœ
        if context.get("is_regeneration") and not context.get("incremental_mode"):
            if request.conversation_context and request.conversation_context.previous_results:
                context.update(request.conversation_context.previous_results)
                logger.info("ğŸ”„ é‡æ–°ç”Ÿæˆæ¨¡å¼ï¼šå·²åŠ è½½ä¹‹å‰çš„ç»“æœ")
        
        logger.info(f"ğŸ¯ Task context: {context}")
        print(f"ğŸ¯ Processing request: {request.theme_id} - {request.target_duration_id}s")

        # åˆ›å»ºVGPæ–‡æ¡£æ¥è®°å½•æ•´ä¸ªæµç¨‹
        vgp_document = node_manager.vgp_protocol.create_document({
            'task_id': task_id,
            'theme': request.theme_id,
            'keywords': request.keywords_id,
            'duration': request.target_duration_id,
            'description': request.user_description_id
        })
        vgp_document.task_id = task_id

        # Execute VGP complete pipeline (expanded to 16-node pipeline)
        results = {}
        # ä½¿ç”¨å®Œæ•´çš„16ä¸ªVGPæ ‡å‡†èŠ‚ç‚¹åºåˆ—
        complete_vgp_nodes = [
            'video_type_identification',  # è§†é¢‘ç±»å‹è¯†åˆ«
            'emotion_analysis',          # æƒ…æ„ŸåŸºè°ƒåˆ†æ
            'shot_block_generation',     # åˆ†é•œå—ç”Ÿæˆ
            'bgm_anchor_planning',       # BGMé”šç‚¹è§„åˆ’
            'bgm_composition',           # BGMåˆæˆæŸ¥æ‰¾
            'asset_request',             # ç´ æéœ€æ±‚è§£æ
            'audio_processing',          # éŸ³é¢‘å¤„ç†
            'sfx_integration',           # éŸ³æ•ˆæ·»åŠ 
            'transition_selection',      # è½¬åœºé€‰æ‹©
            'filter_application',        # æ»¤é•œåº”ç”¨
            'dynamic_effects',           # åŠ¨æ€ç‰¹æ•ˆæ·»åŠ 
            'aux_media_insertion',       # é¢å¤–åª’ä½“æ’å…¥
            'aux_text_insertion',        # è£…é¥°æ–‡å­—æ’å…¥
            'subtitle_generation',       # å­—å¹•ç”Ÿæˆ
            'intro_outro',               # ç‰‡å¤´ç‰‡å°¾ç”Ÿæˆ
            'timeline_integration'       # æœ€ç»ˆæ—¶é—´çº¿æ•´åˆ
        ]
        
        # æ™ºèƒ½èŠ‚ç‚¹æ‰§è¡Œ - æ”¯æŒå¢é‡ä¿®æ”¹å’ŒèŠ‚ç‚¹è·³è¿‡
        nodes_to_execute = complete_vgp_nodes.copy()
        skip_nodes = context.get("skip_nodes", [])
        nodes_to_update = context.get("nodes_to_update", [])
        incremental_mode = context.get("incremental_mode", False)

        # å¦‚æœæ˜¯å¢é‡æ¨¡å¼ï¼Œè¿‡æ»¤èŠ‚ç‚¹åˆ—è¡¨
        if incremental_mode and skip_nodes:
            nodes_to_execute = [node for node in complete_vgp_nodes if node not in skip_nodes]
            logger.info(f"ğŸ”„ å¢é‡æ¨¡å¼ï¼šè·³è¿‡èŠ‚ç‚¹ {skip_nodes}")

        for i, node_id in enumerate(nodes_to_execute, 1):
            try:
                progress = (i - 1) / len(nodes_to_execute) * 100

                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ­¤èŠ‚ç‚¹
                node_status = "æ›´æ–°" if node_id in nodes_to_update else "æ‰§è¡Œ"
                status_msg = f"æ­£åœ¨{node_status}{node_id}"

                TaskService.update_task_status(
                    db, task_id, TaskStatus.PROCESSING,
                    progress=progress, message=status_msg
                )

                await send_callback(task_id, i, "processing", status_msg)
                print(f"âš¡ {node_status.title()} node {i}/{len(nodes_to_execute)}: {node_id}")

                # Update context with previous results
                context.update(results)

                # å¢é‡æ¨¡å¼ï¼šå¦‚æœæœ‰ä¹‹å‰çš„ç»“æœä¸”èŠ‚ç‚¹ä¸éœ€è¦æ›´æ–°ï¼Œå°è¯•å¤ç”¨
                if incremental_mode and node_id not in nodes_to_update:
                    previous_result = context.get("modifications", {}).get(node_id)
                    if previous_result:
                        logger.info(f"ğŸ”„ å¤ç”¨èŠ‚ç‚¹ç»“æœ: {node_id}")
                        results.update({node_id: previous_result})
                        continue

                # Execute node
                node_result = await node_manager.execute_node(node_id, context)
                results.update(node_result)

                # Extract node outputs to context for downstream nodes
                if node_id in node_result:
                    node_output = node_result[node_id]
                    if isinstance(node_output, dict):
                        # Extract specific output fields based on node type
                        extracted_outputs = extract_node_outputs(node_id, node_output)
                        logger.info(f"ğŸ” Node {node_id} extracted outputs: {list(extracted_outputs.keys())}")
                        print(f"ğŸ” Node {node_id} extracted outputs: {list(extracted_outputs.keys())}")
                        context.update(extracted_outputs)
                        logger.info(f"ğŸ¯ Context keys after {node_id}: {list(context.keys())}")
                        print(f"ğŸ¯ Context keys after {node_id}: {list(context.keys())}")

                # è®°å½•åˆ°VGPæ–‡æ¡£
                node_manager.vgp_protocol.add_node(
                    vgp_document,
                    node_type=node_id,
                    input_data=context.copy(),
                    output_data=node_result.get(node_id, {})
                )

                await send_callback(task_id, i, "completed", f"{node_id}æ‰§è¡Œå®Œæˆ")
                logger.info(f"âœ… Node {node_id} completed")
                print(f"âœ… Node {i}/{len(complete_vgp_nodes)} completed: {node_id}")
                
            except Exception as node_error:
                error_msg = f"èŠ‚ç‚¹{node_id}æ‰§è¡Œå¤±è´¥: {str(node_error)}"
                TaskService.update_task_status(
                    db, task_id, TaskStatus.FAILED,
                    error_message=error_msg
                )
                await send_callback(task_id, i, "failed", error_msg)
                logger.error(error_msg)
                print(f"âŒ Node {node_id} failed: {node_error}")
                raise

        # VGPåˆ†æå®Œæˆåï¼Œç”ŸæˆVGPåˆ†ææ‘˜è¦
        vgp_summary = generate_vgp_summary(results)
        print(f"ğŸ“‹ VGPåˆ†ææ‘˜è¦: {vgp_summary}")

        # è¿›åº¦æ›´æ–°ï¼šVGPåˆ†æå®Œæˆï¼Œå¼€å§‹è§†é¢‘ç”Ÿæˆ
        TaskService.update_task_status(
            db, task_id, TaskStatus.PROCESSING,
            progress=70.0, message="VGPåˆ†æå®Œæˆï¼Œå¼€å§‹è§†é¢‘ç”Ÿæˆ"
        )

        # ä½¿ç”¨VGPåˆ†æç»“æœç”Ÿæˆè§†é¢‘ - å®Œæ•´åˆ†é•œåˆ°è§†é¢‘æµç¨‹
        try:
            print("ğŸ¬ å¼€å§‹ä½¿ç”¨VGPåˆ†æç»“æœç”Ÿæˆè§†é¢‘...")

            # é˜¶æ®µ1: ä»åˆ†é•œå—ç”Ÿæˆå…³é”®å¸§å›¾ç‰‡
            shot_blocks = results.get('shot_block_generation', {}).get('shot_blocks_id', [])
            if not shot_blocks:
                raise ValueError("æœªæ‰¾åˆ°åˆ†é•œå—æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆå…³é”®å¸§")

            print(f"ğŸ“‹ æ‰¾åˆ° {len(shot_blocks)} ä¸ªåˆ†é•œå—ï¼Œå¼€å§‹ç”Ÿæˆå…³é”®å¸§...")

            # è¿›åº¦æ›´æ–°
            TaskService.update_task_status(
                db, task_id, TaskStatus.PROCESSING,
                progress=75.0, message=f"ç”Ÿæˆ {len(shot_blocks)} ä¸ªå…³é”®å¸§å›¾ç‰‡"
            )

            # ç”Ÿæˆå…³é”®å¸§
            keyframes = await generate_keyframes_from_shot_blocks(shot_blocks, context)
            print(f"ğŸ¨ ç”Ÿæˆäº† {len(keyframes)} ä¸ªå…³é”®å¸§å›¾ç‰‡")

            # é˜¶æ®µ2: å¤„ç†å¸§å¤ç”¨é€»è¾‘
            processed_keyframes = process_frame_reuse_logic(keyframes)
            print(f"ğŸ”„ å¤„ç†å¸§å¤ç”¨åå…± {len(processed_keyframes)} ä¸ªå¸§")

            # é˜¶æ®µ3: ä½¿ç”¨å…³é”®å¸§ç”Ÿæˆè§†é¢‘ç‰‡æ®µ
            from video_generate_protocol.nodes.qwen_integration import StoryboardToVideoProcessor

            # è·å–åƒé—®APIå¯†é’¥
            import os
            qwen_key = os.getenv('DASHSCOPE_API_KEY') or os.getenv('AI__DASHSCOPE_API_KEY')
            if not qwen_key:
                raise ValueError("ç¼ºå°‘åƒé—®APIå¯†é’¥ï¼Œè¯·è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")

            video_processor = StoryboardToVideoProcessor(qwen_key)

            # è¿›åº¦æ›´æ–°
            TaskService.update_task_status(
                db, task_id, TaskStatus.PROCESSING,
                progress=80.0, message="ä½¿ç”¨å…³é”®å¸§ç”Ÿæˆè§†é¢‘ç‰‡æ®µ"
            )

            # ç”Ÿæˆè§†é¢‘ç‰‡æ®µ
            video_clips = await video_processor.process_storyboard_frames(
                processed_keyframes,
                f"/tmp/video_clips_{task_id}"
            )
            print(f"ğŸ¥ ç”Ÿæˆäº† {len(video_clips)} ä¸ªè§†é¢‘ç‰‡æ®µ")

            # é˜¶æ®µ4: åˆå¹¶è§†é¢‘ç‰‡æ®µ
            if video_clips:
                TaskService.update_task_status(
                    db, task_id, TaskStatus.PROCESSING,
                    progress=90.0, message="ä½¿ç”¨IMSåˆå¹¶è§†é¢‘ç‰‡æ®µ"
                )

                final_video_path = f"/tmp/final_video_{task_id}.mp4"
                merge_result = await video_processor.merge_clips(video_clips, final_video_path)

                # merge_resultå¯èƒ½åŒ…å«video_url(IMS)æˆ–local_path(ffmpegé™çº§)
                video_output = merge_result.get("video_url") or merge_result.get("local_path")

                results['video_generation'] = {
                    "success": merge_result.get("success", False),
                    "video_url": merge_result.get("video_url"),  # IMSè¿”å›çš„URL
                    "video_path": merge_result.get("local_path"),  # ffmpegè¿”å›çš„æœ¬åœ°è·¯å¾„
                    "job_id": merge_result.get("job_id"),  # IMSä»»åŠ¡ID
                    "duration_seconds": int(request.target_duration_id),
                    "generation_mode": "storyboard_to_video_ims" if merge_result.get("video_url") else "storyboard_to_video_ffmpeg",
                    "segments_count": len(video_clips),
                    "keyframes_count": len(processed_keyframes),
                    "metadata": {
                        "vgp_analysis": results,
                        "shot_blocks": shot_blocks,
                        "keyframes": [kf.get('image_url') or kf.get('image_path') for kf in processed_keyframes],
                        "clips": video_clips
                    }
                }
                print(f"ğŸ‰ è§†é¢‘ç”Ÿæˆå®Œæˆ: {len(video_clips)} ä¸ªç‰‡æ®µåˆå¹¶ä¸ºæœ€ç»ˆè§†é¢‘")
                print(f"ğŸ“ è§†é¢‘è¾“å‡º: {video_output}")
            else:
                raise Exception("æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•è§†é¢‘ç‰‡æ®µ")

        except Exception as video_error:
            print(f"âš ï¸ è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œä½†VGPåˆ†ææˆåŠŸ: {video_error}")
            results['video_generation_error'] = str(video_error)

        # ä¿å­˜VGPæ–‡æ¡£åˆ°é¡¹ç›®æ ¹ç›®å½•
        vgp_dir = Path(__file__).parent / "vgp_documents"
        vgp_dir.mkdir(exist_ok=True)
        vgp_file_path = str(vgp_dir / f"{task_id}.vgp.json")

        # æ›´æ–°VGPæ–‡æ¡£çš„æœ€ç»ˆè¾“å‡º
        vgp_document.final_output = results.get('video_generation', {})

        # éªŒè¯å¹¶ä¿å­˜VGPæ–‡æ¡£
        try:
            node_manager.vgp_protocol.save(vgp_document, vgp_file_path)
            logger.info(f"ğŸ“„ VGP document saved: {vgp_file_path}")
            print(f"ğŸ“„ VGP document saved: {vgp_file_path}")
        except Exception as e:
            logger.warning(f"Failed to save VGP document: {e}")

        # åºåˆ—åŒ–ç»“æœä¸ºå¯JSONåŒ–çš„æ ¼å¼
        serialized_results = serialize_results(results)
        serialized_results['vgp_document_path'] = vgp_file_path

        # ä¿å­˜å¯¹è¯ç»“æœï¼ˆå¦‚æœæœ‰å¯¹è¯ä¸Šä¸‹æ–‡ï¼‰
        if request.conversation_context and conversation_result:
            try:
                from conversation.conversation_manager import conversation_manager
                conversation_manager.save_generation_result(
                    request.conversation_context.conversation_id,
                    task_id,
                    serialized_results
                )
                logger.info(f"ğŸ’¬ ä¿å­˜å¯¹è¯ç”Ÿæˆç»“æœ: {request.conversation_context.conversation_id}")
            except Exception as e:
                logger.warning(f"ä¿å­˜å¯¹è¯ç»“æœå¤±è´¥: {e}")

        # Task completed successfully
        TaskService.update_task_status(
            db, task_id, TaskStatus.COMPLETED,
            progress=100.0,
            message=f"ä»»åŠ¡å®Œæˆï¼š{'å¢é‡ä¿®æ”¹' if context.get('incremental_mode') else 'VGPåˆ†æ+è§†é¢‘ç”Ÿæˆ'}",
            result=serialized_results
        )
        
        # Final success callback
        await send_callback(task_id, 0, "completed", "è§†é¢‘ç”Ÿæˆä»»åŠ¡å®Œæˆ")
        logger.info(f"ğŸ‰ Task {task_id} completed successfully")
        print(f"ğŸ‰ Task {task_id} completed successfully!")
        print(f"ğŸ“Š Final results: {results}")
        
    except Exception as e:
        error_msg = f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}"
        TaskService.update_task_status(
            db, task_id, TaskStatus.FAILED,
            error_message=error_msg
        )
        await send_callback(task_id, 0, "failed", error_msg)
        logger.error(f"âŒ Task {task_id} failed: {e}")
        print(f"âŒ Task {task_id} failed: {e}")
    finally:
        db.close()


# =============================
# Exception Handlers
# =============================

@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    """Handle HTTP exceptions"""
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.detail,
            "timestamp": datetime.now().isoformat()
        }
    )


@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """Handle general exceptions"""
    logger.error(f"âŒ Unhandled exception: {exc}")
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={
            "error": "Internal server error" if not settings.is_development else str(exc),
            "timestamp": datetime.now().isoformat()
        }
    )


# Application events are now handled by the lifespan context manager above


# =============================
# è§†é¢‘ç”Ÿæˆè¾…åŠ©å‡½æ•°
# =============================

async def generate_keyframes_from_shot_blocks(shot_blocks: List[Dict], context: Dict) -> List[Dict]:
    """ä»åˆ†é•œå—ç”Ÿæˆå…³é”®å¸§å›¾ç‰‡"""
    try:
        # âœ… ä¼˜å…ˆæ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰å¯ç”¨çš„å…³é”®å¸§æ–‡ä»¶
        local_keyframe_dir = "/Users/luming/Downloads/aura_render/aura_render_temp"
        local_keyframes = []
        use_local_keyframes = False

        if os.path.exists(local_keyframe_dir):
            # æ£€æŸ¥æ˜¯å¦æœ‰å…³é”®å¸§1.pngåˆ°å…³é”®å¸§N.png
            for i in range(1, len(shot_blocks) + 1):
                keyframe_path = os.path.join(local_keyframe_dir, f"å…³é”®å¸§{i}.png")
                if os.path.exists(keyframe_path):
                    local_keyframes.append(keyframe_path)

            if len(local_keyframes) >= len(shot_blocks):
                use_local_keyframes = True
                print(f"âœ… å‘ç°æœ¬åœ°å…³é”®å¸§æ–‡ä»¶ {len(local_keyframes)} ä¸ªï¼Œå°†ç›´æ¥ä½¿ç”¨æœ¬åœ°å…³é”®å¸§")

        # å¦‚æœæœ‰è¶³å¤Ÿçš„æœ¬åœ°å…³é”®å¸§ï¼Œç›´æ¥ä½¿ç”¨
        if use_local_keyframes:
            keyframes = []
            for i, (shot_block, keyframe_path) in enumerate(zip(shot_blocks, local_keyframes[:len(shot_blocks)])):
                keyframe = {
                    "frame_id": f"frame_{i+1:03d}",
                    "segment_id": i,
                    "image_path": keyframe_path,  # ä½¿ç”¨æœ¬åœ°è·¯å¾„
                    "shot_block": shot_block,
                    "generation_mode": "local_file",  # æ ‡è®°æ¥æº
                    "is_reused": False,
                    "duration": shot_block.get('duration', 3.0)
                }
                keyframes.append(keyframe)
                print(f"âœ… åŠ è½½æœ¬åœ°å…³é”®å¸§ {i+1}/{len(shot_blocks)}: {keyframe_path}")

            print(f"\n{'='*80}")
            print(f"ğŸ–¼ï¸  ä½¿ç”¨çš„æœ¬åœ°å…³é”®å¸§ (å…±{len(keyframes)}ä¸ª):")
            print(f"{'='*80}")
            for idx, kf in enumerate(keyframes, 1):
                print(f"{idx}. {kf.get('image_path', 'N/A')}")
            print(f"{'='*80}\n")

            return keyframes

        # æ²¡æœ‰è¶³å¤Ÿçš„æœ¬åœ°å…³é”®å¸§ï¼Œéœ€è¦ç”Ÿæˆ
        print(f"âš ï¸ æœªæ‰¾åˆ°è¶³å¤Ÿçš„æœ¬åœ°å…³é”®å¸§æ–‡ä»¶ï¼Œå°†è°ƒç”¨APIç”Ÿæˆ")

        from video_generate_protocol.nodes.image_generation_node import (
            ImageGenerationNode,
            ImageGenerationTask,
            ImageGenerationNodeRequest
        )

        # åˆå§‹åŒ–å›¾åƒç”ŸæˆèŠ‚ç‚¹
        image_node = ImageGenerationNode({
            "dalle_api_key": os.getenv("OPENAI_API_KEY"),
            "stability_api_key": os.getenv("STABILITY_API_KEY")
        })

        # æå–å‚è€ƒå›¾ç‰‡ä¿¡æ¯
        reference_image = None
        reference_media = context.get("reference_media")

        # é€‚é…ä¸¤ç§æ•°æ®ç»“æ„ï¼š
        # 1. æ–°æ ¼å¼ï¼ˆæ¥è‡ª/vgp/generateï¼‰: {"product_images": [...], "videos": [...]}
        # 2. æ—§æ ¼å¼ï¼ˆæ¥è‡ª/generateï¼‰: [{media_type: ..., ...}, ...]

        all_media = []
        if reference_media:
            if isinstance(reference_media, dict):
                # æ–°æ ¼å¼ï¼šä»å­—å…¸ä¸­æå–æ‰€æœ‰åª’ä½“
                if "product_images" in reference_media:
                    product_images = reference_media.get("product_images", [])
                    if isinstance(product_images, list):
                        # å°†äº§å“å›¾ç‰‡æ·»åŠ åˆ°åª’ä½“åˆ—è¡¨ï¼Œå¹¶æ ‡è®°ç±»å‹
                        for img in product_images:
                            if isinstance(img, dict):
                                img_copy = img.copy()
                                img_copy["media_type"] = "product_image"
                                all_media.append(img_copy)

                if "videos" in reference_media:
                    videos = reference_media.get("videos", [])
                    if isinstance(videos, list):
                        for vid in videos:
                            if isinstance(vid, dict):
                                vid_copy = vid.copy()
                                vid_copy["media_type"] = "video"
                                all_media.append(vid_copy)

            elif isinstance(reference_media, list):
                # æ—§æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨åˆ—è¡¨
                all_media = reference_media

        # ä»æ‰€æœ‰åª’ä½“ä¸­æŸ¥æ‰¾äº§å“å›¾ç‰‡
        for media in all_media:
            if isinstance(media, dict):
                # æ–°æ ¼å¼ï¼šç›´æ¥ä»mediaä¸­è·å–url
                if media.get("media_type") == "product_image":
                    reference_image = media.get("url")
                    if reference_image:
                        print(f"âœ… ä½¿ç”¨äº§å“å‚è€ƒå›¾ç‰‡: {reference_image}")
                        break

                # æ—§æ ¼å¼ï¼šä»original_inputæˆ–å…¶ä»–å­—æ®µè·å–
                if media.get("media_type") == "product_image" and media.get("processing_status") == "success":
                    if "original_input" in media and "url" in media["original_input"]:
                        reference_image = media["original_input"]["url"]
                    else:
                        reference_image = media.get("original_url") or media.get("local_path")
                    if reference_image:
                        print(f"âœ… ä½¿ç”¨äº§å“å‚è€ƒå›¾ç‰‡: {reference_image}")
                        break

        keyframes = []
        tasks = []

        # ä¸ºæ¯ä¸ªåˆ†é•œå—åˆ›å»ºå›¾åƒç”Ÿæˆä»»åŠ¡
        for i, shot_block in enumerate(shot_blocks):
            visual_desc = shot_block.get('visual_description', 'ç”»é¢å†…å®¹')
            shot_type = shot_block.get('shot_type', 'ä¸­æ™¯')

            # æ„å»ºæç¤ºè¯ï¼Œç»“åˆå‚è€ƒå›¾ç‰‡ä¿¡æ¯
            if reference_image:
                prompt = f"{shot_type}é•œå¤´ï¼š{visual_desc}ï¼Œå‚è€ƒäº§å“å›¾ç‰‡çš„é£æ ¼å’Œå…ƒç´ "
            else:
                prompt = f"{shot_type}é•œå¤´ï¼š{visual_desc}ï¼Œé«˜è´¨é‡å•†ä¸šè§†é¢‘é£æ ¼"

            task = ImageGenerationTask(
                prompt=prompt,
                style="realistic",
                quality="high",
                aspect_ratio="3:2",
                reference_image=reference_image,
                metadata={
                    "shot_block_index": i,
                    "shot_type": shot_type,
                    "duration": shot_block.get('duration', 3.0)
                }
            )
            tasks.append(task)

        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„APIå¯†é’¥
        dashscope_key = os.getenv("DASHSCOPE_API_KEY") or os.getenv("AI__DASHSCOPE_API_KEY")
        openai_key = os.getenv("OPENAI_API_KEY")
        stability_key = os.getenv("STABILITY_API_KEY")

        has_api_key = bool(openai_key or stability_key or dashscope_key)

        if not has_api_key:
            print("âš ï¸ æœªé…ç½®å›¾ç‰‡ç”ŸæˆAPIå¯†é’¥(DASHSCOPE_API_KEY, OPENAI_API_KEY æˆ– STABILITY_API_KEY)")
            print("âš ï¸ å°†ä½¿ç”¨å ä½å›¾ç‰‡ç”Ÿæˆè§†é¢‘")

            # åˆ›å»ºå ä½å›¾ç‰‡
            import tempfile
            from PIL import Image, ImageDraw, ImageFont

            for i, shot_block in enumerate(shot_blocks):
                # åˆ›å»ºå ä½å›¾
                img = Image.new('RGB', (1280, 720), color=(30, 30, 30))
                draw = ImageDraw.Draw(img)

                # æ·»åŠ æ–‡æœ¬
                text = f"é•œå¤´ {i+1}\n{shot_block.get('shot_type', 'ä¸­æ™¯')}\n{shot_block.get('visual_description', '')[:50]}..."
                draw.text((640, 360), text, fill=(255, 255, 255), anchor='mm')

                # ä¿å­˜
                temp_path = tempfile.mktemp(suffix='.jpg', prefix='keyframe_')
                img.save(temp_path, quality=85)

                keyframe = {
                    "frame_id": f"frame_{i+1:03d}",
                    "segment_id": i,
                    "image_path": temp_path,
                    "shot_block": shot_block,
                    "generation_mode": "placeholder",
                    "is_reused": False,
                    "duration": shot_block.get('duration', 3.0)
                }
                keyframes.append(keyframe)
                print(f"ğŸ“ åˆ›å»ºå ä½å…³é”®å¸§ {i+1}: {temp_path}")
        elif dashscope_key:
            # ä½¿ç”¨é€šä¹‰ä¸‡ç›¸ç”Ÿæˆå›¾ç‰‡ - ç›´æ¥ä¿å­˜URLä¸ä¸‹è½½
            print("ğŸ¨ ä½¿ç”¨é€šä¹‰ä¸‡ç›¸(Wanx)ç”Ÿæˆå…³é”®å¸§å›¾ç‰‡...")
            try:
                import dashscope
                from dashscope import ImageSynthesis

                dashscope.api_key = dashscope_key

                for i, shot_block in enumerate(shot_blocks):
                    visual_desc = shot_block.get('visual_description', 'ç”»é¢å†…å®¹')
                    shot_type = shot_block.get('shot_type', 'ä¸­æ™¯')

                    # æ„å»ºæç¤ºè¯
                    if reference_image:
                        prompt = f"{shot_type}é•œå¤´ï¼š{visual_desc}ï¼Œå‚è€ƒäº§å“å›¾ç‰‡çš„é£æ ¼å’Œå…ƒç´ ï¼Œé«˜è´¨é‡å•†ä¸šè§†é¢‘é£æ ¼"
                    else:
                        prompt = f"{shot_type}é•œå¤´ï¼š{visual_desc}ï¼Œé«˜è´¨é‡å•†ä¸šè§†é¢‘é£æ ¼"

                    try:
                        # è°ƒç”¨é€šä¹‰ä¸‡ç›¸API
                        rsp = ImageSynthesis.call(
                            model='wanx-v1',
                            prompt=prompt,
                            n=1,
                            size='1280*720'
                        )

                        if rsp.status_code == 200 and rsp.output and rsp.output.results:
                            image_url = rsp.output.results[0].url

                            # ç›´æ¥ä¿å­˜URLï¼Œä¸ä¸‹è½½å›¾ç‰‡ï¼ˆä¸‡ç›¸URLå¯ç›´æ¥ç”¨äºå›¾ç”Ÿè§†é¢‘ï¼‰
                            keyframe = {
                                "frame_id": f"frame_{i+1:03d}",
                                "segment_id": i,
                                "image_url": image_url,  # ä¿å­˜URLè€Œéæœ¬åœ°è·¯å¾„
                                "shot_block": shot_block,
                                "generation_mode": "wanx_text_to_image",
                                "is_reused": False,
                                "duration": shot_block.get('duration', 3.0)
                            }
                            keyframes.append(keyframe)
                            print(f"âœ… é€šä¹‰ä¸‡ç›¸ç”Ÿæˆå…³é”®å¸§ {i+1}/{len(shot_blocks)}: {image_url}")
                        else:
                            print(f"âš ï¸ å…³é”®å¸§ {i+1} ç”Ÿæˆå¤±è´¥: {rsp.message}")
                    except Exception as e:
                        print(f"âŒ å…³é”®å¸§ {i+1} ç”Ÿæˆå¤±è´¥: {e}")

            except Exception as e:
                print(f"âŒ é€šä¹‰ä¸‡ç›¸å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {e}")
                logger.error(f"é€šä¹‰ä¸‡ç›¸å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
        else:
            # æ‰¹é‡ç”Ÿæˆå›¾ç‰‡
            request = ImageGenerationNodeRequest(
                tasks=tasks,
                provider_preference="dalle",  # ä¼˜å…ˆä½¿ç”¨DALL-E
                batch_mode=True
            )

            try:
                response = await image_node.process(request)

                # å¤„ç†ç”Ÿæˆç»“æœ
                for i, (shot_block, generated_image) in enumerate(zip(shot_blocks, response.generated_images)):
                    if generated_image and generated_image.image_path:
                        keyframe = {
                            "frame_id": f"frame_{i+1:03d}",
                            "segment_id": i,
                            "image_path": generated_image.image_path,
                            "shot_block": shot_block,
                            "generation_mode": "text_to_image",
                            "is_reused": False,
                            "duration": shot_block.get('duration', 3.0)
                        }
                        keyframes.append(keyframe)
                        print(f"âœ… ç”Ÿæˆå…³é”®å¸§ {i+1}: {generated_image.image_path}")
                    else:
                        print(f"âŒ å…³é”®å¸§ {i+1} ç”Ÿæˆå¤±è´¥")
            except Exception as e:
                print(f"âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {e}")
                logger.error(f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)

        return keyframes

    except Exception as e:
        print(f"âŒ å…³é”®å¸§ç”Ÿæˆå¤±è´¥: {e}")
        # è¿”å›ç©ºçš„å…³é”®å¸§åˆ—è¡¨ï¼Œæˆ–è€…ä½¿ç”¨fallbacké€»è¾‘
        return []


def process_frame_reuse_logic(keyframes: List[Dict]) -> List[Dict]:
    """å¤„ç†å¸§å¤ç”¨é€»è¾‘ - å°¾å¸§å¤ç”¨ä¸ºä¸‹ä¸€æ®µçš„é¦–å¸§"""
    if len(keyframes) <= 1:
        return keyframes

    processed_frames = []

    for i in range(len(keyframes)):
        frame = keyframes[i]
        processed_frames.append(frame)

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤ç”¨å½“å‰å¸§ä½œä¸ºä¸‹ä¸€æ®µçš„é¦–å¸§
        # é€»è¾‘ï¼šæ¯ä¸ªå¥‡æ•°ä½ç½®çš„å¸§ï¼ˆå³æ¯æ®µçš„å°¾å¸§ï¼‰å¤ç”¨ä¸ºä¸‹ä¸€æ®µçš„é¦–å¸§
        if i < len(keyframes) - 1 and i % 2 == 1:
            reused_frame = {
                "frame_id": f"{frame['frame_id']}_reused",
                "segment_id": frame["segment_id"] + 1,
                "shot_block": frame["shot_block"],
                "generation_mode": frame["generation_mode"],
                "is_reused": True,
                "source_frame_id": frame["frame_id"],
                "duration": keyframes[i+1].get('duration', 3.0) if i+1 < len(keyframes) else 3.0
            }

            # åŒæ—¶æ”¯æŒimage_urlå’Œimage_pathï¼ˆä¸‡ç›¸ç”¨URLï¼Œå ä½å›¾ç”¨pathï¼‰
            if "image_url" in frame:
                reused_frame["image_url"] = frame["image_url"]
            if "image_path" in frame:
                reused_frame["image_path"] = frame["image_path"]

            processed_frames.append(reused_frame)
            print(f"ğŸ”„ å¤ç”¨å¸§: {frame['frame_id']} -> {reused_frame['frame_id']}")

    return processed_frames


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "app:app",
        host=settings.api.host,
        port=settings.api.port,
        reload=settings.is_development
    )