# matcher/video_matcher.py
import httpx
from typing import List, Dict, Any, Optional
from ..models import VideoRequest, VideoResponse
try:
    from llm.qwen import QwenLLM
    qwen_client = QwenLLM()
except ImportError:
    qwen_client = None

try:
    from utils.color_analyzer import ColorStyleAnalyzer  # å‡è®¾å·²æœ‰è¯¥æ¨¡å—
except ImportError:
    ColorStyleAnalyzer = None

# -------------------------------
# ğŸ¯ å¤šçº§è§†é¢‘åŒ¹é…ä¸»å‡½æ•°
# -------------------------------
import asyncio
import base64
from config import settings


class MainVideoMatcher:
    """ä¸»è§†é¢‘åŒ¹é…å™¨ç±»"""

    def __init__(self):
        self.qwen_client = qwen_client
        self.color_analyzer = ColorStyleAnalyzer if ColorStyleAnalyzer else None

    async def match_videos(self, request: VideoRequest) -> VideoResponse:
        """åŒ¹é…è§†é¢‘ç´ æ"""
        # è¿™æ˜¯ä¸€ä¸ªå ä½å®ç°ï¼Œå®é™…é€»è¾‘éœ€è¦æ ¹æ®éœ€æ±‚å®Œå–„
        return VideoResponse(
            status="success",
            materials=[],
            message="Video matching not yet implemented"
        )

# å…¨å±€ HTTP å®¢æˆ·ç«¯
async def get_http_client():
    return httpx.AsyncClient(timeout=30.0)

# -------------------------------
# ğŸš€ ä¸»å‡½æ•°ï¼šå¤šçº§ç­›é€‰ + AI ä»‹å…¥
# -------------------------------
async def match_main_video(request: VideoRequest) -> List[VideoResponse]:

    # Step 1: è·å–å€™é€‰
    candidates = await fetch_candidates_from_java(request)
    if not candidates:
        gen = await generate_video_by_ai(request, reason="no_candidates")
        return [gen] if gen else []

    # Step 2: ä¸€çº§ç­›é€‰ - å†…å®¹è¯­ä¹‰åŒ¹é…ï¼ˆæ–‡æœ¬ï¼‰
    content_matched = await filter_by_content_semantic(candidates, request.description)
    if not content_matched:
        gen = await generate_video_by_ai(request, reason="content_mismatch")
        return [gen] if gen else []

    # Step 3: äºŒçº§ç­›é€‰ - å¤šæ¨¡æ€å›¾æ–‡ä¸€è‡´æ€§éªŒè¯ï¼ˆQwen-VLï¼‰
    visual_verified = await validate_with_qwen_vl(content_matched, request)
    if not visual_verified:
        # å›¾æ–‡å†…å®¹ä¸ä¸€è‡´ â†’ æ— æ³•ä¿®å¤ â†’ é‡æ–°ç”Ÿæˆ
        gen = await generate_video_by_ai(request, reason="visual_inconsistent")
        return [gen] if gen else []

    # Step 4: ä¸‰çº§å†³ç­– - é£æ ¼ä¸è‰²å½©æ˜¯å¦åŒ¹é…ï¼Ÿå†³å®šæ˜¯ç›´æ¥è¿”å›ã€é£æ ¼è¿ç§»ã€è¿˜æ˜¯ç”Ÿæˆ
    final_result = await decide_by_style_and_color(visual_verified, request)
    return [final_result] if final_result else []



    # Step 5: è‰²å½©éªŒè¯ï¼ˆå¯é€‰ï¼‰
    # final_candidates = await validate_color_style(visual_verified, request.category)
    # if not final_candidates:
    #     final_candidates = visual_verified  # é™çº§ä¿ç•™

    # # è½¬æ¢ä¸º VideoResponse
    # return [VideoResponse(
    #     url=c["url"],
    #     thumbnail=c["thumbnail"],
    #     in_point=0.0,
    #     out_point=min(c["duration"], request.duration),
    #     match_score=1.0
    # ) for c in final_candidates[:1]]


# -------------------------------
# 1ï¸âƒ£ ä» Java è·å–å€™é€‰ï¼ˆçœŸå®APIï¼‰
# -------------------------------
async def fetch_candidates_from_online(request: VideoRequest) -> List[Dict]:
    """è°ƒç”¨çœŸå®ç´ æåº“APIè·å–è§†é¢‘å€™é€‰"""
    
    # å¯¼å…¥provider manager
    from materials_supplies.providers.provider_manager import get_provider_manager
    from materials_supplies.providers.base_provider import MaterialType
    
    try:
        # è·å–provider manager
        provider_manager = get_provider_manager()
        await provider_manager.initialize()
        
        # æ„å»ºæœç´¢æŸ¥è¯¢
        search_query = request.description
        if hasattr(request, 'keywords') and request.keywords:
            search_query = f"{search_query} {' '.join(request.keywords)}"
            
        # æœç´¢è§†é¢‘ç´ æ
        search_results = await provider_manager.search(
            query=search_query,
            material_type=MaterialType.VIDEO,
            limit=20,  # è·å–æ›´å¤šå€™é€‰ä»¥ä¾¿ç­›é€‰
            filters={
                "min_duration": getattr(request, 'duration', 10) * 0.5,  # è‡³å°‘ä¸€åŠæ—¶é•¿
                "max_duration": getattr(request, 'duration', 10) * 3,    # æœ€å¤š3å€æ—¶é•¿
            }
        )
        
        # è½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼
        candidates = []
        for result in search_results:
            candidates.append({
                "material_id": result.material_id,
                "url": result.url,
                "thumbnail": result.thumbnail_url or result.preview_url or "",
                "description": result.description or result.title,
                "tags": result.tags,
                "style": result.metadata.get("style", "é€šç”¨"),
                "duration": result.duration or 30.0,
                "provider": result.provider,
                "relevance_score": result.relevance_score
            })
            
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°çœŸå®ç´ æï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºfallback
        if not candidates and settings.development.enable_mock_services:
            return [
                {
                    "material_id": "mock_vid_001",
                    "url": "https://video.com/flying-car-tech.mp4",
                    "thumbnail": "https://thumb.com/flying-car.jpg",
                    "description": "ä¸€è¾†é“¶è‰²é£è¡Œæ±½è½¦åœ¨éœ“è™¹ç§‘æŠ€åŸå¸‚ä¸Šç©ºé£è¡Œ",
                    "tags": ["é£è¡Œæ±½è½¦", "æœªæ¥åŸå¸‚", "ç§‘æŠ€æ„Ÿ"],
                    "style": "ç§‘æŠ€æ„Ÿ",
                    "duration": 60.0,
                    "provider": "mock",
                    "relevance_score": 0.5
                }
            ]
            
        return candidates
        
    except Exception as e:
        # è®°å½•é”™è¯¯å¹¶è¿”å›æ¨¡æ‹Ÿæ•°æ®
        print(f"Error fetching materials from providers: {e}")
        
        # Fallback to mock data in development
        if settings.development.enable_mock_services:
            return [
                {
                    "material_id": "fallback_vid_001",
                    "url": "https://video.com/default-tech.mp4",
                    "thumbnail": "https://thumb.com/default.jpg",
                    "description": "é»˜è®¤ç§‘æŠ€è§†é¢‘ç´ æ",
                    "tags": ["ç§‘æŠ€", "é»˜è®¤"],
                    "style": "é€šç”¨",
                    "duration": 30.0,
                    "provider": "mock",
                    "relevance_score": 0.3
                }
            ]
        
        return []


# -------------------------------
# 2ï¸âƒ£ ä¸€çº§ç­›é€‰ï¼šæè¿°è¯­ä¹‰åŒ¹é…
# -------------------------------
async def filter_by_content_semantic(candidates: List[Dict], user_desc: str) -> List[Dict]:
    """
    ä½¿ç”¨ Qwen åˆ¤æ–­å€™é€‰æè¿°æ˜¯å¦ä¸ç”¨æˆ·éœ€æ±‚å†…å®¹ä¸€è‡´
    """
    results = []
    async for c in candidates:
        prompt = f"""
        è¯·åˆ¤æ–­ä»¥ä¸‹ä¸¤ä¸ªæè¿°æ˜¯å¦è¡¨è¾¾ç›¸åŒæˆ–é«˜åº¦ç›¸ä¼¼çš„å†…å®¹ï¼š
        ã€ç”¨æˆ·éœ€æ±‚ã€‘{user_desc}
        ã€ç´ ææè¿°ã€‘{c['description']}
        è¯·è¾“å‡º JSONï¼š{{"match": true}} æˆ– {{"match": false}}
        """
        resp = await qwen_generate(prompt, parse_json=True)
        if resp and resp.get("match", False):
            results.append(c)
    return results


# -------------------------------
# 3ï¸âƒ£ äºŒçº§ç­›é€‰ï¼šé£æ ¼æ ‡ç­¾åŒ¹é…
# -------------------------------
def filter_by_style(candidates: List[Dict], required_style: str) -> List[Dict]:
    """
    ç®€å•é£æ ¼å…³é”®è¯åŒ¹é…
    """
    filtered = []
    req_lower = required_style.lower()
    for c in candidates:
        style = c.get("style", "").lower()
        tags = [t.lower() for t in c.get("tags", [])]
        if req_lower in style or any(req_lower in tag for tag in tags):
            filtered.append(c)
    return filtered


# -------------------------------
# 4ï¸âƒ£ ä¸‰çº§ç­›é€‰ï¼šè‰²å½©é£æ ¼åˆ†ææ‰“åˆ†
# -------------------------------
async def score_with_color_analysis(candidates: List[Dict], request: VideoRequest) -> List[Dict]:
    """
    ä½¿ç”¨ ColorStyleAnalyzer åˆ†æç¼©ç•¥å›¾è‰²å½©ï¼ŒåŒ¹é…é£æ ¼
    ç¤ºä¾‹ï¼šç§‘æŠ€æ„Ÿ â†’ è“/é“¶ï¼›å¤å¤ â†’ æ£•/é»„ï¼›èµ›åšæœ‹å…‹ â†’ ç´«/ç²‰
    """
    style_color_map = {
        "ç§‘æŠ€æ„Ÿ": ["blue", "silver", "cyan"],
        "æœªæ¥æ„Ÿ": ["white", "blue", "purple"],
        "å¤å¤": ["brown", "yellow", "beige"],
        "èµ›åšæœ‹å…‹": ["pink", "purple", "neon"]
    }

    target_colors = style_color_map.get(request.category.lower(), [])

    if not target_colors:
        return candidates  # è‹¥æ— è‰²å½©è§„åˆ™ï¼Œè·³è¿‡

    scored = []
    for c in candidates:
        try:
            # ä¸‹è½½ç¼©ç•¥å›¾å¹¶åˆ†æè‰²å½©
            async with httpx.AsyncClient() as client:
                resp = await client.get(c["thumbnail"], timeout=10.0)
                resp.raise_for_status()
                image_bytes = resp.content

            result = ColorStyleAnalyzer.analyze(image_bytes)
            dominant_colors = [col.lower() for col in result['dominant_colors']]

            # è®¡ç®—è‰²å½©åŒ¹é…å¾—åˆ†ï¼ˆäº¤é›†æ¯”ä¾‹ï¼‰
            match_count = sum(1 for dc in dominant_colors if any(tc in dc for tc in target_colors))
            color_score = match_count / len(dominant_colors) if dominant_colors else 0.0

            c["color_score"] = color_score
            scored.append(c)
        except Exception as e:
            c["color_score"] = 0.0
            scored.append(c)

    # æŒ‰è‰²å½©å¾—åˆ†æ’åºï¼ˆé«˜åˆ†ä¼˜å…ˆï¼‰
    scored.sort(key=lambda x: x["color_score"], reverse=True)
    return scored


# -------------------------------
# 5ï¸âƒ£ å››çº§ç²¾ç­›ï¼šQwen-VL å¤šæ¨¡æ€éªŒè¯ + æ‰“åˆ†
# -------------------------------
async def validate_with_qwen_vl(
    candidates: List[Dict],
    request: VideoRequest
) -> List[Dict]:
    """
    å¤šæ¨¡æ€å›¾æ–‡ä¸€è‡´æ€§ + é£æ ¼åˆæ­¥åˆ¤æ–­
    è¿”å›ï¼šä»…ä¿ç•™ã€å†…å®¹ä¸€è‡´ã€‘çš„å€™é€‰ï¼ˆé£æ ¼å¯åç»­è°ƒæ•´ï¼‰
    """
    verified = []
    client = await get_http_client()

    for c in candidates:
        try:
            resp = await client.get(c["thumbnail"])
            resp.raise_for_status()
            image_base64 = base64.b64encode(resp.content).decode('utf-8')

            prompt = f"""
            è¯·ç»¼åˆåˆ¤æ–­ï¼š
            
            ã€ç´ æä¿¡æ¯ã€‘
            - æè¿°ï¼š{c['description']}
            - å£°ç§°é£æ ¼ï¼š{c['style']}
            - æ ‡ç­¾ï¼š{', '.join(c['tags'])}

            ã€ç”¨æˆ·éœ€æ±‚ã€‘
            - å†…å®¹ï¼š{request.description}
            - ç›®æ ‡é£æ ¼ï¼š{request.category}

            è¯·å›ç­”ï¼š
            1. å›¾åƒå†…å®¹æ˜¯å¦çœŸå®åæ˜ æè¿°ï¼Ÿï¼ˆå¦‚ï¼šæè¿°â€œé£è¡Œæ±½è½¦â€ï¼Œå›¾ä¸­æ˜¯å¦æœ‰é£è¡Œçš„æ±½è½¦ï¼Ÿï¼‰
            2. æ•´ä½“è§†è§‰æ˜¯å¦ä¸ç”¨æˆ·éœ€æ±‚å†…å®¹ä¸€è‡´ï¼Ÿ
            3. å½“å‰è§†è§‰é£æ ¼æ˜¯å¦æ¥è¿‘â€œ{request.category}â€ï¼Ÿï¼ˆæ˜¯/å¦/éƒ¨åˆ†ç¬¦åˆï¼‰

            è¯·è¾“å‡º JSONï¼š
            {{
                "content_consistent": true,
                "style_match": "yes|partial|no",
                "reason": "å›¾åƒæ˜¾ç¤ºé£è¡Œæ±½è½¦ï¼Œå†…å®¹ä¸€è‡´ï¼Œä½†è‰²è°ƒåæš–ï¼Œç§‘æŠ€æ„Ÿä¸è¶³"
            }}
            """

            response = await qwen_client.generate(
                prompt=prompt,
                images=[f"data:image/jpeg;base64,{image_base64}"],
                parse_json=True,
                json_schema={
                    "content_consistent": True,
                    "style_match": "yes",
                    "reason": "ok"
                },
                temperature=0.1
            )

            if not response:
                continue

            # âœ… ä»…å½“å†…å®¹ä¸€è‡´æ—¶ä¿ç•™
            if response.get("content_consistent", False):
                # é™„åŠ  Qwen å¯¹é£æ ¼çš„åˆ¤æ–­ï¼Œä¾›åç»­ä½¿ç”¨
                c["vl_style_judgment"] = response.get("style_match", "no")
                c["vl_reason"] = response.get("reason", "")
                verified.append(c)

        except Exception as e:
            print(f"[Qwen-VL] éªŒè¯å¤±è´¥: {str(e)}")
            continue

    return verified


async def decide_by_style_and_color(
    candidates: List[Dict],
    request: VideoRequest
) -> Optional[VideoResponse]:
    """
    å…³é”®å˜æ›´ï¼š
    1. æ‰€æœ‰å€™é€‰è§†é¢‘ â†’ å…ˆå‰ªè¾‘å‡ºæœ€ä½³ç‰‡æ®µï¼ˆæ— è®ºé£æ ¼ï¼‰
    2. å†åˆ¤æ–­æ˜¯å¦éœ€è¦é£æ ¼è¿ç§»
    3. é£æ ¼è¿ç§»è¾“å…¥ä¸ºã€å·²å‰ªè¾‘çš„å°ç‰‡æ®µã€‘â†’ é™ä½æˆæœ¬
    """
    candidate = candidates[0]
    target_style = request.category
    required_duration = request.duration

    # âœ… STEP 1: æ™ºèƒ½å‰ªè¾‘ â€”â€” å…ˆå®šä½æœ€ç›¸å…³å†…å®¹ç‰‡æ®µï¼ˆæ ¸å¿ƒå‰ç½®æ­¥éª¤ï¼‰
    try:
        final_clip = await select_best_clip_with_vl(candidate, request)
    except Exception as e:
        print(f"[å‰ªè¾‘] å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç‰‡æ®µ: {str(e)}")
        # fallbackï¼šä¸­é—´æˆªå– required_duration
        dur = candidate["duration"]
        start_fallback = max(0, (dur - required_duration) / 2)
        end_fallback = start_fallback + required_duration
        final_clip = {
            "in_point": start_fallback,
            "out_point": min(end_fallback, dur),
            "confidence": 0.6
        }

    # æå–å‰ªè¾‘åçš„ in/out
    in_point = final_clip["in_point"]
    out_point = final_clip["out_point"]
    clip_duration = out_point - in_point

    # ç¡®ä¿ä¸è¶…é•¿
    if clip_duration > required_duration:
        out_point = in_point + required_duration

    # âœ… STEP 2: è·å–å‰ªè¾‘åçš„è§†é¢‘å…ƒä¿¡æ¯ï¼ˆæ¨¡æ‹Ÿï¼‰
    # å®é™…ä¸­ï¼Œå¯ç”Ÿæˆä¸€ä¸ªä¸´æ—¶å‰ªè¾‘ URLï¼Œæˆ–ç”± AI ç³»ç»Ÿæ¥æ”¶ in/out
    # è¿™é‡Œæˆ‘ä»¬ä»ç”¨åŸ URLï¼Œä½†ä¼ å…¥ in/out
    clip_url = candidate["url"]  # å®é™…å¯æ›¿æ¢ä¸ºå‰ªè¾‘åä¸´æ—¶ URL

    # âœ… STEP 3: é£æ ¼ä¸è‰²å½©åˆ¤æ–­ï¼ˆåŸºäºåŸ candidate + VL åˆ¤æ–­ï¼‰
    vl_style_judge = candidate.get("vl_style_judge", "no")
    color_analysis = await analyze_candidate_color(candidate, target_style)
    color_match = color_analysis.get("match", False)

    # --- æœ€ç»ˆå†³ç­– ---
    if vl_style_judge == "yes" and color_match:
        # âœ… é£æ ¼è‰²å½©åŒ¹é… â†’ ç›´æ¥è¿”å›å‰ªè¾‘ç‰‡æ®µ
        return VideoResponse(
            url=clip_url,
            thumbnail=candidate["thumbnail"],
            in_point=in_point,
            out_point=out_point,
            match_score=final_clip.get("confidence", 0.8)
        )

    else:
        # âŒ é£æ ¼ä¸åŒ¹é… â†’ ä½†åªè¿ç§»ã€å·²å‰ªè¾‘çš„å°ç‰‡æ®µã€‘ï¼
        return await stylize_video_by_ai(
            video_url=clip_url,           # âœ… è¾“å…¥æ˜¯å‰ªè¾‘åçš„å°ç‰‡æ®µ
            target_style=target_style,
            duration=required_duration,
            in_point=in_point,            # âœ… æ˜¾å¼ä¼ å…¥å‰ªè¾‘åŒºé—´
            out_point=out_point
        )
    
async def analyze_candidate_color(candidate: Dict, target_style: str) -> Dict:
    """åˆ†æå•ä¸ªå€™é€‰çš„è‰²å½©æ˜¯å¦ç¬¦åˆç›®æ ‡é£æ ¼"""
    try:
        async with httpx.AsyncClient() as client:
            resp = await client.get(candidate["thumbnail"])
            result = ColorStyleAnalyzer.analyze(resp.content)

        dominant_colors = [c.lower() for c in result['dominant_colors']]
        style_color_map = {
            "ç§‘æŠ€æ„Ÿ": ["blue", "silver", "cyan", "white"],
            "å¤å¤": ["brown", "yellow", "beige", "orange"],
            "èµ›åšæœ‹å…‹": ["pink", "purple", "neon", "magenta"],
            "æ¸…æ–°": ["green", "blue", "white", "pastel"]
        }
        target_colors = style_color_map.get(target_style, [])

        match = any(any(tc in dc for tc in target_colors) for dc in dominant_colors)
        return {"match": match, "colors": dominant_colors}
    except:
        return {"match": False}  # åˆ†æå¤±è´¥ â†’ ä¸åŒ¹é…
    

# æ™ºèƒ½å‰ªè¾‘æ—¶æ®µæ¨è
def split_into_segments(analyzed: Dict, window_sec: int = 5) -> List[Dict]:
    """
    å°†è§†é¢‘åˆ‡åˆ†ä¸º N ç§’çª—å£ï¼Œèšåˆå†…å®¹ç‰¹å¾
    """
    duration = analyzed["duration"]
    frames = analyzed["frames"]
    segments = []

    for start in range(0, int(duration), window_sec):
        end = min(start + window_sec, duration)
        segment_frames = [f for f in frames if start <= f["time"] < end]

        # èšåˆç‰¹å¾
        objects = [obj for f in segment_frames for obj in f.get("objects", [])]
        speeches = " ".join([f["speech"] for f in segment_frames if f["speech"]])
        avg_motion = sum(f["motion_score"] for f in segment_frames) / len(segment_frames)
        face_count = sum(1 for f in segment_frames if f.get("faces"))

        segments.append({
            "start": start,
            "end": end,
            "duration": end - start,
            "objects": list(set(objects)),
            "speech": speeches,
            "motion_score": avg_motion,
            "face_count": face_count,
            "key_frame_time": start + avg_motion * (end - start),  # ç²—ç•¥é€‰å…³é”®å¸§
        })

    return segments

async def score_segments_by_desc(segments: List[Dict], user_desc: str) -> List[Dict]:
    """
    ä½¿ç”¨ Qwen åˆ¤æ–­æ¯ä¸ª segment æ˜¯å¦åŒ¹é…ç”¨æˆ·æè¿°
    ä»…ç”¨äºæ’åºï¼Œä¸æ·˜æ±°
    """
    scored = []
    for seg in segments:
        prompt = f"""
        è¯·åˆ¤æ–­ä»¥ä¸‹è§†é¢‘ç‰‡æ®µæ˜¯å¦å¯èƒ½åŒ…å«æè¿°ä¸­çš„å†…å®¹ï¼š
        ã€ç”¨æˆ·éœ€æ±‚ã€‘{user_desc}
        ã€ç‰‡æ®µä¿¡æ¯ã€‘
        - æ—¶é—´ï¼š{seg['start']:.1f}s - {seg['end']:.1f}s
        - æ£€æµ‹ç‰©ä½“ï¼š{', '.join(seg['objects'][:5])}
        - è¯­éŸ³å†…å®¹ï¼š{seg['speech'][:100]}
        - åŠ¨ä½œå¼ºåº¦ï¼š{seg['motion_score']:.2f}
        - æ˜¯å¦æœ‰äººè„¸ï¼š{'æ˜¯' if seg['face_count'] > 0 else 'å¦'}

        è¯·è¾“å‡º JSONï¼š{{"relevance_score": 0.8}}
        """
        resp = await qwen_generate(prompt, parse_json=True)
        score = resp.get("relevance_score", 0.0) if resp else 0.0
        scored.append({**seg, "relevance_score": score})

    # æŒ‰ç›¸å…³æ€§æ’åº
    return sorted(scored, key=lambda x: x["relevance_score"], reverse=True)

async def select_best_clip_with_vl(
    candidate: Dict,           # å€™é€‰è§†é¢‘ï¼ˆå« url, descriptionï¼‰
    request: VideoRequest,
    top_k: int = 3             # æœ€å¤šéªŒè¯ 3 ä¸ªå€™é€‰ç‰‡æ®µ
) -> Dict:
    """
    ä¸ºä¸»è§†é¢‘å€™é€‰é€‰æ‹©æœ€ä½³å‰ªè¾‘åŒºé—´
    æ­¥éª¤ï¼š
    1. åˆ†æè§†é¢‘å†…å®¹
    2. åˆ‡åˆ†çª—å£ + æ‰“åˆ†
    3. å¯¹ top-k ç‰‡æ®µçš„å…³é”®å¸§è°ƒç”¨ Qwen-VL éªŒè¯
    4. è¿”å›æœ€ä½³ in/out
    """
    video_url = candidate["url"]
    user_desc = request.description

    # Step 1: è§†é¢‘åˆ†æ
    analyzed = await analyze_video_content(video_url)
    if not analyzed:
        return {"in_point": 0.0, "out_point": min(10.0, analyzed["duration"]), "vl_verified": False}

    # Step 2: åˆ‡åˆ†çª—å£
    segments = split_into_segments(analyzed, window_sec=5)

    # Step 3: æ–‡æœ¬æ‰“åˆ†æ’åºï¼ˆä½æˆæœ¬ï¼‰
    scored_segments = await score_segments_by_desc(segments, user_desc)
    top_candidates = scored_segments[:top_k]

    # Step 4: å¯¹ top-k å…³é”®å¸§è°ƒç”¨ Qwen-VLï¼ˆé«˜ä»·å€¼ç‚¹ï¼‰
    best_seg = None
    best_vl_score = 0.0
    client = await get_http_client()

    for seg in top_candidates:
        try:
            # ä¸‹è½½å…³é”®å¸§å›¾åƒï¼ˆæ¨¡æ‹Ÿï¼šå–ä¸­é—´å¸§æˆªå›¾ URLï¼‰
            key_time = (seg["start"] + seg["end"]) / 2
            thumbnail_url = f"{video_url.replace('.mp4', '')}_thumb_{int(key_time)}.jpg"
            resp = await client.get(thumbnail_url)
            if not resp.is_success:
                continue
            image_base64 = base64.b64encode(resp.content).decode('utf-8')

            # è°ƒç”¨ Qwen-VL éªŒè¯è¯¥ç‰‡æ®µæ˜¯å¦çœŸå®ç¬¦åˆæè¿°
            prompt = f"""
            è¯·åˆ¤æ–­è¯¥å¸§å›¾åƒæ˜¯å¦çœŸå®ä½“ç°ç”¨æˆ·éœ€æ±‚ï¼š
            ã€ç”¨æˆ·éœ€æ±‚ã€‘{user_desc}
            ã€ç‰‡æ®µæ—¶é—´ã€‘{seg['start']:.1f}s - {seg['end']:.1f}s
            ã€æ£€æµ‹å†…å®¹ã€‘ç‰©ä½“ï¼š{', '.join(seg['objects'][:3])}ï¼Œè¯­éŸ³ï¼š{seg['speech'][:80]}

            è¯·å›ç­”ï¼š
            - å›¾åƒæ˜¯å¦åæ˜ æè¿°å†…å®¹ï¼Ÿ
            - æ˜¯å¦å­˜åœ¨è¯¯å¯¼ï¼Ÿ

            è¾“å‡º JSONï¼š{{"vl_match": true, "confidence": 0.9}}
            """

            vl_resp = await qwen_client.generate(
                prompt=prompt,
                images=[f"data:image/jpeg;base64,{image_base64}"],
                parse_json=True,
                json_schema={"vl_match": True, "confidence": 0.5},
                temperature=0.1
            )

            if vl_resp and vl_resp.get("vl_match", False):
                confidence = vl_resp.get("confidence", 0.5)
                if confidence > best_vl_score:
                    best_vl_score = confidence
                    best_seg = seg

        except Exception as e:
            print(f"[Qwen-VL] å…³é”®å¸§éªŒè¯å¤±è´¥: {str(e)}")
            continue

    # Step 5: è¿”å›æœ€ä½³ç‰‡æ®µ
    if best_seg:
        return {
            "in_point": best_seg["start"],
            "out_point": min(best_seg["end"], request.duration + best_seg["start"]),  # æ§åˆ¶æ—¶é•¿
            "vl_verified": True,
            "confidence": best_vl_score
        }

    # fallbackï¼šè¿”å›æœ€é«˜æ–‡æœ¬åˆ†çš„ç‰‡æ®µï¼ˆä¸éªŒè¯ï¼‰
    fallback = scored_segments[0]
    dur = request.duration
    out = min(fallback["end"], fallback["start"] + dur)
    return {
        "in_point": fallback["start"],
        "out_point": out,
        "vl_verified": False,
        "confidence": fallback["relevance_score"]
    }