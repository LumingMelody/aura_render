# matcher/bgm_matcher.py
from materials_supplies.models import BGMRequest, BGMResponse
from materials_supplies.material_library_client import get_material_library_client
import random
import logging
from typing import List
import subprocess
import json

logger = logging.getLogger(__name__)


async def match_bgm(request: BGMRequest) -> List[BGMResponse]:
    """
    ä»ç´ æåº“åŒ¹é…BGMéŸ³é¢‘

    Args:
        request: BGMè¯·æ±‚ï¼ŒåŒ…å«:
            - description: æè¿°ä¿¡æ¯ (å¦‚"å†·é™æƒ…ç»ªï¼Œä½¿ç”¨åˆæˆè´æ–¯...")
            - category: éŸ³ä¹ç±»å‹ (å¦‚"æç®€ç”µå­")
            - duration: éœ€è¦çš„æ—¶é•¿(ç§’)

    Returns:
        BGMå“åº”åˆ—è¡¨ï¼ŒåŒ…å«åŒ¹é…åˆ°çš„éŸ³é¢‘URLå’Œè£å‰ªä¿¡æ¯
    """
    client = get_material_library_client()

    if not client:
        logger.warning("ç´ æåº“å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼ŒBGMåŒ¹é…å¤±è´¥")
        return []

    # ä»descriptionä¸­æå–moodï¼ˆæƒ…ç»ªï¼‰
    mood = ""
    if "æƒ…ç»ª" in request.description:
        mood = request.description.split("æƒ…ç»ª")[0].strip()

    # æ„é€ æœç´¢ç­–ç•¥ (å¤šçº§fallback)
    search_strategies = [
        {"tag": request.category, "keyword": ""},           # ä¼˜å…ˆ: ç²¾ç¡®é£æ ¼ (å¦‚"æç®€ç”µå­")
        {"tag": mood, "keyword": ""},                       # æ¬¡é€‰: æƒ…ç»ªåŒ¹é… (å¦‚"å†·é™")
        {"tag": request.category, "keyword": mood},         # ç»„åˆ: é£æ ¼+æƒ…ç»ª
        {"tag": "", "keyword": "èƒŒæ™¯éŸ³ä¹"},                  # å…œåº•: ä»»æ„BGM
    ]

    logger.info(f"ğŸµ å¼€å§‹åŒ¹é…BGM: category={request.category}, mood={mood}, duration={request.duration}ç§’")

    # é€ä¸ªå°è¯•æœç´¢ç­–ç•¥
    for idx, strategy in enumerate(search_strategies):
        tag = strategy["tag"]
        keyword = strategy["keyword"]

        logger.debug(f"   å°è¯•ç­–ç•¥ {idx+1}: tag='{tag}', keyword='{keyword}'")

        # è°ƒç”¨ç´ æåº“API
        audio_list = client.search_audios(
            keyword=keyword if keyword else None,
            tag=tag if tag else None,
            page_size=5
        )

        if audio_list and len(audio_list) > 0:
            logger.info(f"   âœ… ç­–ç•¥ {idx+1} æ‰¾åˆ° {len(audio_list)} ä¸ªå€™é€‰éŸ³é¢‘")

            # è½¬æ¢ä¸ºBGMResponse
            responses = []
            for item in audio_list[:3]:  # å–å‰3ä¸ªä½œä¸ºå€™é€‰
                audio_url = item.get("url", "")

                if not audio_url:
                    logger.warning(f"   è·³è¿‡æ— æ•ˆéŸ³é¢‘: {item.get('name')}")
                    continue

                # è·å–éŸ³é¢‘æ—¶é•¿
                audio_duration = await _get_audio_duration(audio_url)

                if audio_duration is None or audio_duration <= 0:
                    logger.warning(f"   æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿ï¼Œè·³è¿‡: {audio_url}")
                    continue

                # éšæœºè£å‰ªç‰‡æ®µ
                if audio_duration >= request.duration:
                    cut_start = random.uniform(0, audio_duration - request.duration)
                    cut_end = cut_start + request.duration
                else:
                    # éŸ³é¢‘æ—¶é•¿ä¸å¤Ÿï¼Œä½¿ç”¨å…¨éƒ¨
                    cut_start = 0.0
                    cut_end = audio_duration
                    logger.warning(f"   éŸ³é¢‘æ—¶é•¿ä¸è¶³: {audio_duration}ç§’ < {request.duration}ç§’")

                responses.append(BGMResponse(
                    url=audio_url,
                    cut_start=round(cut_start, 2),
                    cut_end=round(cut_end, 2),
                    duration=audio_duration
                ))

                logger.info(f"   æ·»åŠ å€™é€‰: {item.get('name')} [{cut_start:.1f}s - {cut_end:.1f}s]")

            if responses:
                logger.info(f"ğŸ‰ BGMåŒ¹é…æˆåŠŸï¼Œè¿”å› {len(responses)} ä¸ªå€™é€‰")
                return responses

    # æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥
    logger.warning("âš ï¸ æ‰€æœ‰BGMæœç´¢ç­–ç•¥éƒ½å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨ï¼ˆè§†é¢‘å°†ä¸åŒ…å«BGMï¼‰")
    return []


async def _get_audio_duration(audio_url: str) -> float:
    """
    ä½¿ç”¨ffprobeè·å–éŸ³é¢‘æ–‡ä»¶çš„æ—¶é•¿

    Args:
        audio_url: éŸ³é¢‘æ–‡ä»¶URL

    Returns:
        éŸ³é¢‘æ—¶é•¿(ç§’)ï¼Œå¤±è´¥è¿”å›None
    """
    try:
        # ä½¿ç”¨ffprobeè·å–éŸ³é¢‘ä¿¡æ¯
        cmd = [
            'ffprobe',
            '-v', 'error',
            '-show_entries', 'format=duration',
            '-of', 'json',
            audio_url
        ]

        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=10
        )

        if result.returncode == 0:
            data = json.loads(result.stdout)
            duration = float(data['format']['duration'])
            logger.debug(f"   éŸ³é¢‘æ—¶é•¿: {duration:.2f}ç§’")
            return duration
        else:
            logger.warning(f"   ffprobeå¤±è´¥: {result.stderr}")
            return None

    except subprocess.TimeoutExpired:
        logger.warning(f"   ffprobeè¶…æ—¶: {audio_url}")
        return None
    except Exception as e:
        logger.warning(f"   è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")
        # å¦‚æœffprobeå¤±è´¥ï¼Œè¿”å›é»˜è®¤æ—¶é•¿
        return 120.0  # é»˜è®¤å‡è®¾2åˆ†é’Ÿ


    def generate(self, context: Dict[str, Any]) -> Dict[str, Any]:
        super().generate(context)

        shot_blocks: List[Dict] = context["shot_blocks"]
        target_duration: float = context["target_duration"]

        # --- 1. è‡ªåŠ¨åˆ†æåˆ†é•œ â†’ æƒ…æ„Ÿã€èŠ‚å¥ã€ä¸»é¢˜ ---
        analysis = self._analyze_shot_blocks(shot_blocks)
        primary_mood = analysis["primary_mood"]
        avg_bpm_hint = analysis["estimated_bpm"]
        dominant_theme = analysis["dominant_theme"]

        print(f"ğŸ” åˆ†æç»“æœ: ä¸»æƒ…ç»ª={primary_mood}, å»ºè®®BPM={avg_bpm_hint:.1f}, ä¸»é¢˜={dominant_theme}")

        # --- 2. ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·ä¸Šä¼ éŸ³é¢‘ ---
        if self.uploaded_files:
            for file_info in self.uploaded_files:
                if file_info["type"] == "audio" and file_info["filename"].endswith((".mp3", ".wav", ".aiff")):
                    bgm_track = self._create_custom_track(file_info["path"], target_duration)
                    return {"bgm_track": bgm_track}

        # --- 3. è°ƒç”¨éŸ³ä¹ API è·å–å€™é€‰ ---
        candidate_tracks = self._fetch_matching_tracks(
            mood=primary_mood,
            bpm=avg_bpm_hint,
            duration=target_duration,
            theme=dominant_theme
        )

        if not candidate_tracks:
            print("âš ï¸ æœªæ‰¾åˆ°åŒ¹é…éŸ³ä¹ï¼Œå°è¯•é€šç”¨â€˜åŠ±å¿—â€™ç±»éŸ³ä¹...")
            candidate_tracks = self._fetch_matching_tracks(mood="åŠ±å¿—", bpm=100, duration=target_duration)

        if not candidate_tracks:
            print("âš ï¸ ä»æ— ç»“æœï¼Œä½¿ç”¨é»˜è®¤é™éŸ³æˆ–æç¤ºéŸ³")
            return {
                "bgm_track": {
                    "source": "fallback",
                    "title": "No BGM Available",
                    "duration": target_duration,
                    "file_path": None,
                    "volume_db": -20.0
                }
            }

        # --- 4. é€‰è¯„åˆ†æœ€é«˜çš„ ---
        best_track = max(candidate_tracks, key=lambda t: t.get("match_score", 0.5))
        bgm_track = self._create_library_track(best_track, target_duration)

        return {"bgm_track": bgm_track}

    def _analyze_shot_blocks(self, shots: List[Dict]) -> Dict[str, Any]:
        """ä»åˆ†é•œä¸­æ¨æ–­æƒ…ç»ªã€BPMã€ä¸»é¢˜"""
        total_duration = 0.0
        mood_counter = {}
        pacing_weights = {"å¿«": 1.8, "å¸¸è§„": 1.0, "æ…¢é•œå¤´": 0.6}
        theme_counter = {}

        for shot in shots:
            duration = shot.get("duration", 5.0)
            total_duration += duration

            # 1. æƒ…ç»ªæ¨æ–­ï¼ˆåŸºäº shot_type + visual_description + caption å…³é”®è¯ï¼‰
            mood = self._infer_mood_from_text(shot)
            mood_counter[mood] = mood_counter.get(mood, 0) + duration * MOOD_WEIGHTS.get(mood, 0.5)

            # 2. ä¸»é¢˜æ¨æ–­ï¼ˆæ•™è‚²ã€ç§‘æŠ€ã€ç”Ÿæ´»ã€åŠ±å¿—ç­‰ï¼‰
            theme = self._infer_theme_from_text(shot)
            theme_counter[theme] = theme_counter.get(theme, 0) + duration

            # 3. èŠ‚å¥æƒé‡ï¼ˆç”¨äºBPMä¼°ç®—ï¼‰
            pacing = shot.get("pacing", "å¸¸è§„")
            speed_factor = pacing_weights.get(pacing, 1.0)

        # ä¸»æƒ…ç»ª
        primary_mood = max(mood_counter, key=mood_counter.get) if mood_counter else "å†·é™"

        # ä¸»é¢˜
        dominant_theme = max(theme_counter, key=theme_counter.get) if theme_counter else "é€šç”¨"

        # BPM ä¼°ç®—ï¼šåŸºäºå‰ªè¾‘å¯†åº¦ Ã— èŠ‚å¥å› å­
        cuts_per_minute = (len(shots) / (total_duration or 1)) * 60
        estimated_bpm = cuts_per_minute * 4  # æ¯å°èŠ‚4æ‹
        estimated_bpm *= pacing_weights.get("å¸¸è§„", 1.0)  # å¯åŠ å…¥ pacing è°ƒæ•´

        return {
            "primary_mood": primary_mood,
            "estimated_bpm": round(estimated_bpm, 1),
            "dominant_theme": dominant_theme,
            "mood_dist": {k: v / sum(mood_counter.values()) for k, v in mood_counter.items()}
        }

    def _infer_mood_from_text(self, shot: Dict) -> str:
        """åŸºäºæ–‡æœ¬å…³é”®è¯æ¨æ–­æƒ…ç»ª"""
        text = f"{shot.get('visual_description', '')} {shot.get('caption', '')} {shot.get('shot_type', '')}"
        text_lower = text.lower()

        mood_keywords = {
            "æ¿€æ˜‚": ["æ¿€æƒ…", "æ¿€åŠ¨", "é«˜æ½®", "çªç ´", "æŒ‘æˆ˜"],
            "åŠ±å¿—": ["åŠ æ²¹", "ä½ å¯ä»¥", "åšæŒ", "æ¢¦æƒ³", "åŠªåŠ›", "æ—…ç¨‹", "å¼€å¯"],
            "æ„ŸåŠ¨": ["æ„ŸåŠ¨", "å›å¿†", "æ¸©æš–", "é™ªä¼´", "æˆé•¿"],
            "æ¸©é¦¨": ["æ¸©é¦¨", "å®¶åº­", "å¾®ç¬‘", "æ˜äº®", "æ•´æ´"],
            "å¹½é»˜": ["æç¬‘", "æ»‘ç¨½", "è°ƒçš®", "ç¬‘"],
            "å†·é™": ["åˆ†æ", "æ•°æ®", "é€»è¾‘", "æ€è€ƒ", "ç™½æ¿"],
            "æ‚¬ç–‘": ["ç§˜å¯†", "æœªçŸ¥", "æ¢ç´¢", "é»‘å½±"],
            "ç§‘æŠ€": ["AI", "æœºå™¨å­¦ä¹ ", "ä»£ç ", "ç”µè„‘", "ç®—æ³•", "é¡¹ç›®", "æŠ€æœ¯"]
        }

        for mood, keywords in mood_keywords.items():
            if any(k in text_lower for k in keywords):
                return mood
        return "å†·é™"  # é»˜è®¤

    def _infer_theme_from_text(self, shot: Dict) -> str:
        """æ¨æ–­ä¸»é¢˜ï¼ˆå¯ç”¨äºAPIè¿‡æ»¤ï¼‰"""
        text = f"{shot.get('visual_description', '')} {shot.get('caption', '')}".lower()
        if "å­¦ä¹ " in text or "è¯¾ç¨‹" in text or "å­¦ç”Ÿ" in text or "æ•™è‚²" in text:
            return "æ•™è‚²"
        elif "ç§‘æŠ€" in text or "AI" in text or "æœºå™¨å­¦ä¹ " in text or "ç¼–ç¨‹" in text:
            return "ç§‘æŠ€"
        elif "å®¶åº­" in text or "å®¶" in text or "ç”Ÿæ´»" in text:
            return "ç”Ÿæ´»"
        elif "è¿åŠ¨" in text or "æ¯”èµ›" in text:
            return "è¿åŠ¨"
        return "é€šç”¨"

    def _fetch_matching_tracks(self, mood: str, bpm: float, duration: float, theme: str = "é€šç”¨") -> List[Dict]:
        """è°ƒç”¨å¤–éƒ¨éŸ³ä¹APIæœç´¢åŒ¹é…æ›²ç›®"""
        try:
            response = requests.post(MUSIC_SEARCH_API, json={
                "mood": mood,
                "bpm": bpm,
                "bpm_tolerance": BPM_TOLERANCE,
                "duration": duration,
                "duration_tolerance": 10.0,
                "genre_hint": theme,
                "limit": 10
            }, timeout=5)

            if response.status_code == 200:
                tracks_data = response.json().get("tracks", [])
                candidates = []
                for item in tracks_data:
                    # è®¡ç®—åŒ¹é…åº¦è¯„åˆ†
                    bpm_diff = abs(item["bpm"] - bpm)
                    bpm_match = 1.0 if bpm_diff <= BPM_TOLERANCE else max(0, 1 - bpm_diff / 20)
                    mood_match = 1.0 if mood in item.get("mood", []) else 0.4

                    stretch_ratio = duration / item["duration"]
                    if stretch_ratio < 0.8 or stretch_ratio > 1.3:
                        continue

                    score = (mood_match * 0.6 + bpm_match * 0.4)

                    if score >= self.system_parameters["min_match_score"]:
                        item["match_score"] = score
                        item["stretch_ratio"] = stretch_ratio
                        candidates.append(item)
                return candidates
            else:
                print(f"âŒ APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                return []

        except Exception as e:
            print(f"âš ï¸  è¯·æ±‚éŸ³ä¹APIå‡ºé”™: {e}")
            return []

    def _create_library_track(self, track: Dict, target_duration: float) -> Dict:
        """åˆ›å»ºåº“å†…éŸ³ä¹çš„è½¨é“é…ç½®"""
        stretch_ratio = target_duration / track["duration"]

        return {
            "source": "library_api",
            "track_id": track["id"],
            "title": track["title"],
            "file_path": track["file_path"],
            "original_bpm": track["bpm"],
            "applied_bpm": track["bpm"],
            "duration": target_duration,
            "stretch_ratio": round(stretch_ratio, 3),
            "fade_in": DEFAULT_FADE_IN,
            "fade_out": max(DEFAULT_FADE_OUT, target_duration * 0.05),
            "volume_db": self.system_parameters["default_volume"],
            "processing": {
                "pitch_preserved": True,
                "time_stretch": True
            },
            "metadata": {
                "genre": track.get("genre", []),
                "mood": track.get("mood", []),
                "key": track.get("key", "N/A"),
                "has_bass_drop": track.get("has_bass_drop", False)
            }
        }

    def _create_custom_track(self, file_path: str, target_duration: float) -> Dict:
        """åˆ›å»ºè‡ªå®šä¹‰éŸ³é¢‘è½¨é“"""
        return {
            "source": "custom",
            "title": "ç”¨æˆ·ä¸Šä¼ BGM",
            "file_path": file_path,
            "duration": target_duration,
            "stretch_ratio": 1.0,
            "fade_in": DEFAULT_FADE_IN,
            "fade_out": max(DEFAULT_FADE_OUT, target_duration * 0.05),
            "volume_db": self.system_parameters["default_volume"],
            "processing": {
                "pitch_preserved": True,
                "time_stretch": True
            },
            "metadata": {},
            "anchor_processing": []
        }
