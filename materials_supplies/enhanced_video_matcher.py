"""
Enhanced Intelligent Video Matcher
ä¼˜åŒ–ç‰ˆæ™ºèƒ½è§†é¢‘åŒ¹é…å™¨ - åŸºäºæ–°çš„åˆ†ç±»ä½“ç³»å’ŒAIå¢å¼ºåŒ¹é…ç®—æ³•
"""
import asyncio
import json
import time
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
import math
from collections import defaultdict, Counter

from llm.qwen import QwenLLM
from .material_taxonomy import (
    MaterialMetadata, MediaType, ContentCategory, StyleTag,
    MaterialTagManager, MaterialTaxonomy
)
from .material_download_manager import MaterialStorage


@dataclass
class MatchingContext:
    """åŒ¹é…ä¸Šä¸‹æ–‡"""
    shot_description: str
    shot_duration: float
    content_category: Optional[ContentCategory] = None
    style_preferences: List[StyleTag] = field(default_factory=list)
    quality_requirement: str = "standard"
    user_constraints: Dict[str, Any] = field(default_factory=dict)
    project_theme: str = ""
    target_audience: str = ""


@dataclass
class MatchResult:
    """åŒ¹é…ç»“æœ"""
    material_id: str
    local_path: str
    metadata: MaterialMetadata
    match_score: float
    match_reasons: List[str] = field(default_factory=list)
    confidence: float = 0.0
    processing_time: float = 0.0


class SemanticMatcher:
    """è¯­ä¹‰åŒ¹é…å™¨ - åŸºäºAIç†è§£çš„è¯­ä¹‰åŒ¹é…"""

    def __init__(self):
        self.qwen = QwenLLM()
        self.cache = {}  # è¯­ä¹‰åˆ†æç¼“å­˜

    async def calculate_semantic_similarity(self, description1: str, description2: str) -> float:
        """è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦"""
        cache_key = f"{hash(description1)}_{hash(description2)}"

        if cache_key in self.cache:
            return self.cache[cache_key]

        prompt = f"""
        è¯·åˆ†æä»¥ä¸‹ä¸¤ä¸ªæè¿°çš„è¯­ä¹‰ç›¸ä¼¼åº¦ã€‚

        æè¿°1: {description1}
        æè¿°2: {description2}

        è¯·ä»ä»¥ä¸‹æ–¹é¢è¯„ä¼°ç›¸ä¼¼åº¦ï¼š
        1. ä¸»é¢˜å†…å®¹ç›¸å…³æ€§ (40%)
        2. æƒ…æ„Ÿè‰²è°ƒåŒ¹é…åº¦ (20%)
        3. è§†è§‰å…ƒç´ ç›¸ä¼¼æ€§ (25%)
        4. åœºæ™¯è®¾å®šåŒ¹é…åº¦ (15%)

        è¯·è¿”å›ä¸€ä¸ª0-1ä¹‹é—´çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼Œå¹¶ç®€è¦è¯´æ˜ç†ç”±ã€‚
        æ ¼å¼: åˆ†æ•°: 0.85
        ç†ç”±: ä¸»é¢˜ç›¸å…³åº¦é«˜ï¼Œæƒ…æ„Ÿè‰²è°ƒåŒ¹é…
        """

        try:
            loop = asyncio.get_event_loop()
            executor = ThreadPoolExecutor(max_workers=1)
            response = await loop.run_in_executor(
                executor,
                lambda: self.qwen.generate(prompt=prompt, max_retries=2)
            )

            if response:
                response_text = str(response).strip()

                # è§£æåˆ†æ•°
                score = 0.0
                if "åˆ†æ•°:" in response_text:
                    score_line = response_text.split("åˆ†æ•°:")[1].split("\n")[0]
                    try:
                        score = float(score_line.strip())
                    except:
                        score = 0.5  # é»˜è®¤ä¸­ç­‰ç›¸ä¼¼åº¦

                # ç¼“å­˜ç»“æœ
                self.cache[cache_key] = score
                return score

        except Exception as e:
            print(f"Semantic similarity calculation failed: {e}")

        return 0.5  # é»˜è®¤ä¸­ç­‰ç›¸ä¼¼åº¦


class StyleMatcher:
    """é£æ ¼åŒ¹é…å™¨ - æ™ºèƒ½é£æ ¼è¯†åˆ«å’ŒåŒ¹é…"""

    def __init__(self):
        self.style_compatibility_matrix = self._build_compatibility_matrix()

    def _build_compatibility_matrix(self) -> Dict[str, Dict[str, float]]:
        """æ„å»ºé£æ ¼å…¼å®¹æ€§çŸ©é˜µ"""
        return {
            StyleTag.CINEMATIC.value: {
                StyleTag.CINEMATIC.value: 1.0,
                StyleTag.REALISTIC.value: 0.8,
                StyleTag.DOCUMENTARY.value: 0.7,
                StyleTag.VINTAGE.value: 0.6,
                StyleTag.MODERN.value: 0.5,
                StyleTag.ANIME.value: 0.2,
                StyleTag.WATERCOLOR.value: 0.3
            },
            StyleTag.REALISTIC.value: {
                StyleTag.REALISTIC.value: 1.0,
                StyleTag.CINEMATIC.value: 0.8,
                StyleTag.DOCUMENTARY.value: 0.9,
                StyleTag.MODERN.value: 0.7,
                StyleTag.VINTAGE.value: 0.5,
                StyleTag.ANIME.value: 0.1,
                StyleTag.CYBERPUNK.value: 0.3
            },
            StyleTag.ANIME.value: {
                StyleTag.ANIME.value: 1.0,
                StyleTag.WATERCOLOR.value: 0.7,
                StyleTag.MODERN.value: 0.6,
                StyleTag.CYBERPUNK.value: 0.5,
                StyleTag.REALISTIC.value: 0.1,
                StyleTag.DOCUMENTARY.value: 0.1,
                StyleTag.CINEMATIC.value: 0.2
            },
            StyleTag.CYBERPUNK.value: {
                StyleTag.CYBERPUNK.value: 1.0,
                StyleTag.MODERN.value: 0.8,
                StyleTag.CINEMATIC.value: 0.6,
                StyleTag.ANIME.value: 0.5,
                StyleTag.REALISTIC.value: 0.3,
                StyleTag.VINTAGE.value: 0.2,
                StyleTag.DOCUMENTARY.value: 0.1
            }
        }

    def calculate_style_compatibility(self, requested_styles: List[StyleTag],
                                    material_styles: List[StyleTag]) -> float:
        """è®¡ç®—é£æ ¼å…¼å®¹æ€§"""
        if not requested_styles or not material_styles:
            return 0.5  # é»˜è®¤ä¸­ç­‰å…¼å®¹æ€§

        compatibility_scores = []

        for req_style in requested_styles:
            req_style_value = req_style.value if isinstance(req_style, StyleTag) else req_style
            best_match = 0.0

            for mat_style in material_styles:
                mat_style_value = mat_style.value if isinstance(mat_style, StyleTag) else mat_style

                # è·å–å…¼å®¹æ€§åˆ†æ•°
                compatibility = self.style_compatibility_matrix.get(
                    req_style_value, {}
                ).get(mat_style_value, 0.0)

                best_match = max(best_match, compatibility)

            compatibility_scores.append(best_match)

        # è¿”å›å¹³å‡å…¼å®¹æ€§
        return sum(compatibility_scores) / len(compatibility_scores)


class ContextualMatcher:
    """ä¸Šä¸‹æ–‡åŒ¹é…å™¨ - è€ƒè™‘é¡¹ç›®æ•´ä½“èƒŒæ™¯çš„æ™ºèƒ½åŒ¹é…"""

    def __init__(self):
        self.project_theme_keywords = {
            "ç§‘æŠ€": ["technology", "innovation", "digital", "future", "AI", "robot"],
            "å•†åŠ¡": ["business", "office", "meeting", "professional", "corporate"],
            "æ•™è‚²": ["education", "learning", "school", "knowledge", "study"],
            "ç”Ÿæ´»": ["lifestyle", "home", "family", "daily", "personal"],
            "è‡ªç„¶": ["nature", "landscape", "outdoor", "environment", "natural"],
            "è‰ºæœ¯": ["art", "creative", "design", "aesthetic", "artistic"]
        }

    def calculate_contextual_relevance(self, material_metadata: MaterialMetadata,
                                     context: MatchingContext) -> Tuple[float, List[str]]:
        """è®¡ç®—ä¸Šä¸‹æ–‡ç›¸å…³æ€§"""
        relevance_score = 0.0
        reasons = []

        # 1. é¡¹ç›®ä¸»é¢˜åŒ¹é…
        theme_score = self._calculate_theme_relevance(material_metadata, context.project_theme)
        relevance_score += theme_score * 0.3
        if theme_score > 0.7:
            reasons.append(f"é¡¹ç›®ä¸»é¢˜é«˜åº¦åŒ¹é… ({theme_score:.2f})")

        # 2. ç›®æ ‡å—ä¼—åŒ¹é…
        audience_score = self._calculate_audience_relevance(material_metadata, context.target_audience)
        relevance_score += audience_score * 0.2
        if audience_score > 0.6:
            reasons.append(f"ç›®æ ‡å—ä¼—é€‚é… ({audience_score:.2f})")

        # 3. æ—¶é•¿åŒ¹é…åº¦
        duration_score = self._calculate_duration_fitness(material_metadata, context.shot_duration)
        relevance_score += duration_score * 0.2
        if duration_score > 0.8:
            reasons.append(f"æ—¶é•¿é«˜åº¦é€‚é… ({duration_score:.2f})")

        # 4. è´¨é‡è¦æ±‚åŒ¹é…
        quality_score = self._calculate_quality_fitness(material_metadata, context.quality_requirement)
        relevance_score += quality_score * 0.3
        if quality_score > 0.7:
            reasons.append(f"è´¨é‡è¦æ±‚åŒ¹é… ({quality_score:.2f})")

        return min(relevance_score, 1.0), reasons

    def _calculate_theme_relevance(self, metadata: MaterialMetadata, theme: str) -> float:
        """è®¡ç®—ä¸»é¢˜ç›¸å…³æ€§"""
        if not theme:
            return 0.5

        theme_lower = theme.lower()
        material_keywords = [tag.value.lower() for tag in metadata.tags] + \
                          [kw.lower() for kw in metadata.keywords]

        # æ£€æŸ¥ä¸»é¢˜å…³é”®è¯åŒ¹é…
        for theme_key, keywords in self.project_theme_keywords.items():
            if theme_key in theme or any(kw in theme_lower for kw in keywords):
                # è®¡ç®—åŒ¹é…åº¦
                matches = sum(1 for kw in keywords if any(kw in mk for mk in material_keywords))
                if matches > 0:
                    return min(matches / len(keywords), 1.0)

        return 0.3  # é»˜è®¤ä½ç›¸å…³æ€§

    def _calculate_audience_relevance(self, metadata: MaterialMetadata, audience: str) -> float:
        """è®¡ç®—å—ä¼—åŒ¹é…åº¦"""
        if not audience:
            return 0.5

        audience_mapping = {
            "ä¸“ä¸š": ["business", "professional", "corporate"],
            "å¹´è½»": ["modern", "trendy", "energetic"],
            "å®¶åº­": ["family", "warm", "lifestyle"],
            "å­¦ç”Ÿ": ["education", "learning", "academic"],
            "åˆ›æ„": ["creative", "artistic", "innovative"]
        }

        audience_lower = audience.lower()
        material_keywords = [tag.value.lower() for tag in metadata.tags]

        for aud_key, keywords in audience_mapping.items():
            if aud_key in audience:
                matches = sum(1 for kw in keywords if any(kw in mk for mk in material_keywords))
                if matches > 0:
                    return min(matches / len(keywords), 1.0)

        return 0.4

    def _calculate_duration_fitness(self, metadata: MaterialMetadata, required_duration: float) -> float:
        """è®¡ç®—æ—¶é•¿é€‚é…åº¦"""
        if not metadata.duration or required_duration <= 0:
            return 0.5

        ratio = min(metadata.duration, required_duration) / max(metadata.duration, required_duration)

        # æ—¶é•¿è¶Šæ¥è¿‘ï¼Œé€‚é…åº¦è¶Šé«˜
        if ratio >= 0.9:
            return 1.0
        elif ratio >= 0.7:
            return 0.8
        elif ratio >= 0.5:
            return 0.6
        else:
            return 0.3

    def _calculate_quality_fitness(self, metadata: MaterialMetadata, quality_req: str) -> float:
        """è®¡ç®—è´¨é‡é€‚é…åº¦"""
        quality_hierarchy = {
            "low": 1,
            "standard": 2,
            "high": 3,
            "premium": 4
        }

        req_level = quality_hierarchy.get(quality_req.lower(), 2)
        mat_level = quality_hierarchy.get(metadata.quality_level.value.lower(), 2)

        # è´¨é‡ç­‰çº§åŒ¹é…æˆ–è¶…å‡ºè¦æ±‚
        if mat_level >= req_level:
            return 1.0
        else:
            return mat_level / req_level


class EnhancedVideoMatcher:
    """å¢å¼ºç‰ˆæ™ºèƒ½è§†é¢‘åŒ¹é…å™¨"""

    def __init__(self, storage: MaterialStorage):
        self.storage = storage
        self.taxonomy = MaterialTaxonomy()
        self.tag_manager = MaterialTagManager()

        # åŒ¹é…ç»„ä»¶
        self.semantic_matcher = SemanticMatcher()
        self.style_matcher = StyleMatcher()
        self.contextual_matcher = ContextualMatcher()

        # åŒ¹é…ç»Ÿè®¡
        self.match_stats = {
            "total_requests": 0,
            "successful_matches": 0,
            "average_match_score": 0.0,
            "processing_time_total": 0.0
        }

        # åŒ¹é…ç¼“å­˜
        self.match_cache = {}

    async def find_best_matches(self, context: MatchingContext,
                               max_results: int = 10) -> List[MatchResult]:
        """å¯»æ‰¾æœ€ä½³åŒ¹é…ç´ æ"""
        start_time = time.time()
        self.match_stats["total_requests"] += 1

        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = self._generate_cache_key(context)
            if cache_key in self.match_cache:
                return self.match_cache[cache_key]

            # è·å–å€™é€‰ç´ æ
            candidates = await self._get_candidate_materials(context)

            if not candidates:
                return []

            # å¹¶å‘è®¡ç®—åŒ¹é…åˆ†æ•°
            match_tasks = [
                self._calculate_match_score(candidate, context)
                for candidate in candidates
            ]

            results = await asyncio.gather(*match_tasks, return_exceptions=True)

            # è¿‡æ»¤æœ‰æ•ˆç»“æœå¹¶æ’åº
            valid_results = [
                result for result in results
                if isinstance(result, MatchResult) and result.match_score > 0.3
            ]

            # æŒ‰åŒ¹é…åˆ†æ•°æ’åº
            valid_results.sort(key=lambda x: x.match_score, reverse=True)

            # é™åˆ¶ç»“æœæ•°é‡
            final_results = valid_results[:max_results]

            # æ›´æ–°ç»Ÿè®¡
            processing_time = time.time() - start_time
            self.match_stats["processing_time_total"] += processing_time

            if final_results:
                self.match_stats["successful_matches"] += 1
                avg_score = sum(r.match_score for r in final_results) / len(final_results)
                self.match_stats["average_match_score"] = (
                    (self.match_stats["average_match_score"] * (self.match_stats["successful_matches"] - 1) + avg_score)
                    / self.match_stats["successful_matches"]
                )

                # ç¼“å­˜ç»“æœ
                self.match_cache[cache_key] = final_results

            # è®¾ç½®å¤„ç†æ—¶é—´
            for result in final_results:
                result.processing_time = processing_time / len(final_results)

            return final_results

        except Exception as e:
            print(f"Match finding failed: {e}")
            return []

    async def _get_candidate_materials(self, context: MatchingContext) -> List[MaterialMetadata]:
        """è·å–å€™é€‰ç´ æ"""
        # è·å–æ‰€æœ‰è§†é¢‘ç´ æ
        all_materials = self.storage.list_materials(
            media_type=MediaType.VIDEO,
            limit=500  # é™åˆ¶å€™é€‰æ•°é‡ä»¥æå‡æ€§èƒ½
        )

        candidates = []
        for material_data in all_materials:
            try:
                if 'parsed_metadata' in material_data:
                    metadata_dict = material_data['parsed_metadata']

                    # é‡æ„MaterialMetadataå¯¹è±¡
                    from .material_taxonomy import ContentCategory, StyleTag, QualityLevel, UsageRights
                    metadata = MaterialMetadata(
                        material_id=material_data['material_id'],
                        filename=material_data['filename'],
                        media_type=MediaType(metadata_dict['media_type']),
                        file_size=metadata_dict['file_size'],
                        primary_category=ContentCategory(metadata_dict['primary_category']),
                        quality_level=QualityLevel(metadata_dict['quality_level']),
                        usage_rights=UsageRights(metadata_dict['usage_rights']),
                        duration=metadata_dict.get('duration'),
                        keywords=metadata_dict.get('keywords', []),
                        created_at=datetime.fromisoformat(metadata_dict['created_at'])
                    )

                    # åŸºç¡€è¿‡æ»¤
                    if self._passes_basic_filter(metadata, context):
                        candidates.append(metadata)

            except Exception as e:
                print(f"Error processing material {material_data.get('material_id', 'unknown')}: {e}")
                continue

        return candidates

    def _passes_basic_filter(self, metadata: MaterialMetadata, context: MatchingContext) -> bool:
        """åŸºç¡€è¿‡æ»¤æ¡ä»¶"""
        # å†…å®¹ç±»åˆ«è¿‡æ»¤
        if context.content_category and metadata.primary_category != context.content_category:
            # æ£€æŸ¥æ˜¯å¦åœ¨æ¬¡è¦ç±»åˆ«ä¸­
            if context.content_category not in metadata.secondary_categories:
                return False

        # æ—¶é•¿è¿‡æ»¤ (å…è®¸Â±50%çš„å¼¹æ€§)
        if metadata.duration and context.shot_duration > 0:
            duration_ratio = metadata.duration / context.shot_duration
            if duration_ratio < 0.5 or duration_ratio > 2.0:
                return False

        # è´¨é‡è¿‡æ»¤
        quality_hierarchy = {"low": 1, "standard": 2, "high": 3, "premium": 4}
        required_level = quality_hierarchy.get(context.quality_requirement.lower(), 2)
        material_level = quality_hierarchy.get(metadata.quality_level.value.lower(), 2)

        if material_level < required_level:
            return False

        return True

    async def _calculate_match_score(self, metadata: MaterialMetadata,
                                   context: MatchingContext) -> MatchResult:
        """è®¡ç®—åŒ¹é…åˆ†æ•°"""
        try:
            scores = {}
            all_reasons = []

            # 1. è¯­ä¹‰ç›¸ä¼¼åº¦ (35%)
            material_description = " ".join(metadata.keywords + [tag.value for tag in metadata.tags])
            semantic_score = await self.semantic_matcher.calculate_semantic_similarity(
                context.shot_description, material_description
            )
            scores["semantic"] = semantic_score * 0.35
            if semantic_score > 0.7:
                all_reasons.append(f"è¯­ä¹‰é«˜åº¦åŒ¹é… ({semantic_score:.2f})")

            # 2. é£æ ¼åŒ¹é…åº¦ (25%)
            style_score = self.style_matcher.calculate_style_compatibility(
                context.style_preferences, metadata.style_tags
            )
            scores["style"] = style_score * 0.25
            if style_score > 0.6:
                all_reasons.append(f"é£æ ¼åŒ¹é… ({style_score:.2f})")

            # 3. ä¸Šä¸‹æ–‡ç›¸å…³æ€§ (30%)
            contextual_score, contextual_reasons = self.contextual_matcher.calculate_contextual_relevance(
                metadata, context
            )
            scores["contextual"] = contextual_score * 0.30
            all_reasons.extend(contextual_reasons)

            # 4. ä½¿ç”¨é¢‘ç‡åŠ æƒ (10%)
            popularity_score = self._calculate_popularity_score(metadata)
            scores["popularity"] = popularity_score * 0.10
            if popularity_score > 0.8:
                all_reasons.append(f"çƒ­é—¨ç´ æ ({popularity_score:.2f})")

            # è®¡ç®—æ€»åˆ†
            total_score = sum(scores.values())

            # è®¡ç®—ç½®ä¿¡åº¦ (åŸºäºåˆ†æ•°åˆ†å¸ƒçš„ä¸€è‡´æ€§)
            score_values = list(scores.values())
            confidence = 1.0 - (max(score_values) - min(score_values))

            # è·å–æœ¬åœ°è·¯å¾„
            local_path = self.storage.get_material_path(metadata.material_id)

            return MatchResult(
                material_id=metadata.material_id,
                local_path=local_path or "",
                metadata=metadata,
                match_score=total_score,
                match_reasons=all_reasons,
                confidence=confidence
            )

        except Exception as e:
            print(f"Error calculating match score for {metadata.material_id}: {e}")
            return MatchResult(
                material_id=metadata.material_id,
                local_path="",
                metadata=metadata,
                match_score=0.0,
                match_reasons=[f"è®¡ç®—é”™è¯¯: {str(e)}"],
                confidence=0.0
            )

    def _calculate_popularity_score(self, metadata: MaterialMetadata) -> float:
        """è®¡ç®—ç´ æçƒ­é—¨ç¨‹åº¦åˆ†æ•°"""
        # åŸºäºä¸‹è½½æ¬¡æ•°å’Œè¯„åˆ†è®¡ç®—çƒ­é—¨ç¨‹åº¦
        base_score = 0.5

        # æ ¹æ®è®¿é—®æ¬¡æ•°è°ƒæ•´
        if metadata.view_count > 100:
            base_score += 0.3
        elif metadata.view_count > 50:
            base_score += 0.2
        elif metadata.view_count > 10:
            base_score += 0.1

        # æ ¹æ®è¯„åˆ†è°ƒæ•´
        if metadata.rating > 4.0:
            base_score += 0.2
        elif metadata.rating > 3.0:
            base_score += 0.1

        return min(base_score, 1.0)

    def _generate_cache_key(self, context: MatchingContext) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_parts = [
            context.shot_description,
            str(context.shot_duration),
            str(context.content_category),
            str(sorted([s.value for s in context.style_preferences])),
            context.quality_requirement,
            context.project_theme,
            context.target_audience
        ]
        return hash(str(key_parts))

    def get_match_statistics(self) -> Dict[str, Any]:
        """è·å–åŒ¹é…ç»Ÿè®¡"""
        avg_processing_time = (
            self.match_stats["processing_time_total"] / max(1, self.match_stats["total_requests"])
        )

        success_rate = (
            self.match_stats["successful_matches"] / max(1, self.match_stats["total_requests"])
        ) * 100

        return {
            "total_requests": self.match_stats["total_requests"],
            "successful_matches": self.match_stats["successful_matches"],
            "success_rate": success_rate,
            "average_match_score": self.match_stats["average_match_score"],
            "average_processing_time": avg_processing_time,
            "cache_size": len(self.match_cache)
        }

    def clear_cache(self):
        """æ¸…é™¤åŒ¹é…ç¼“å­˜"""
        self.match_cache.clear()
        self.semantic_matcher.cache.clear()


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
async def test_enhanced_matcher():
    """æµ‹è¯•å¢å¼ºç‰ˆåŒ¹é…å™¨"""
    print("ğŸ§ª æµ‹è¯•å¢å¼ºç‰ˆæ™ºèƒ½è§†é¢‘åŒ¹é…å™¨")
    print("=" * 50)

    # åˆå§‹åŒ–å­˜å‚¨å’ŒåŒ¹é…å™¨
    from .material_download_manager import MaterialStorage
    storage = MaterialStorage("/tmp/aura_render_outputs/materials")
    matcher = EnhancedVideoMatcher(storage)

    # åˆ›å»ºæµ‹è¯•åŒ¹é…ä¸Šä¸‹æ–‡
    test_contexts = [
        MatchingContext(
            shot_description="ç°ä»£åŠå…¬å®¤ä¸­çš„å•†åŠ¡ä¼šè®®åœºæ™¯",
            shot_duration=8.0,
            content_category=ContentCategory.BUSINESS,
            style_preferences=[StyleTag.MODERN, StyleTag.REALISTIC],
            quality_requirement="high",
            project_theme="ä¼ä¸šå®£ä¼ ",
            target_audience="å•†åŠ¡ä¸“ä¸šäººå£«"
        ),
        MatchingContext(
            shot_description="ç¾ä¸½çš„è‡ªç„¶é£æ™¯ï¼Œå±±å³¦å’Œæ¹–æ³Š",
            shot_duration=10.0,
            content_category=ContentCategory.NATURE,
            style_preferences=[StyleTag.CINEMATIC, StyleTag.REALISTIC],
            quality_requirement="premium",
            project_theme="è‡ªç„¶çºªå½•ç‰‡",
            target_audience="è‡ªç„¶çˆ±å¥½è€…"
        ),
        MatchingContext(
            shot_description="ç§‘æŠ€æ„Ÿåè¶³çš„AIæœºå™¨äººåœºæ™¯",
            shot_duration=6.0,
            content_category=ContentCategory.TECHNOLOGY,
            style_preferences=[StyleTag.CYBERPUNK, StyleTag.MODERN],
            quality_requirement="high",
            project_theme="ç§‘æŠ€åˆ›æ–°",
            target_audience="ç§‘æŠ€ä¸“ä¸šäººå£«"
        )
    ]

    # æ‰§è¡ŒåŒ¹é…æµ‹è¯•
    all_results = []
    for i, context in enumerate(test_contexts):
        print(f"\nğŸ¯ æµ‹è¯•åœºæ™¯ {i+1}: {context.shot_description[:30]}...")

        start_time = time.time()
        results = await matcher.find_best_matches(context, max_results=5)
        processing_time = time.time() - start_time

        print(f"   æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…ç»“æœ (è€—æ—¶: {processing_time:.2f}s)")

        for j, result in enumerate(results):
            print(f"   {j+1}. {result.material_id}")
            print(f"      åŒ¹é…åˆ†æ•°: {result.match_score:.3f}")
            print(f"      ç½®ä¿¡åº¦: {result.confidence:.3f}")
            print(f"      åŒ¹é…åŸå› : {', '.join(result.match_reasons[:2])}")
            if j >= 2:  # åªæ˜¾ç¤ºå‰3ä¸ªç»“æœ
                break

        all_results.extend(results)

    # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
    stats = matcher.get_match_statistics()
    print(f"\nğŸ“Š åŒ¹é…ç»Ÿè®¡:")
    print(f"   æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
    print(f"   æˆåŠŸåŒ¹é…: {stats['successful_matches']}")
    print(f"   æˆåŠŸç‡: {stats['success_rate']:.1f}%")
    print(f"   å¹³å‡åŒ¹é…åˆ†æ•°: {stats['average_match_score']:.3f}")
    print(f"   å¹³å‡å¤„ç†æ—¶é—´: {stats['average_processing_time']:.3f}s")

    print("\nğŸ‰ å¢å¼ºç‰ˆåŒ¹é…å™¨æµ‹è¯•å®Œæˆï¼")

    return {
        "test_results": all_results,
        "statistics": stats
    }


if __name__ == "__main__":
    asyncio.run(test_enhanced_matcher())