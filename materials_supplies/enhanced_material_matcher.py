"""
å¢å¼ºç´ æåŒ¹é…å¼•æ“ - åŸºäºå¤šæ¨¡æ€è¯­ä¹‰ç†è§£çš„æ™ºèƒ½åŒ¹é…
"""
from typing import Dict, List, Any, Optional, Tuple, Union
import asyncio
import numpy as np
from dataclasses import dataclass, field
from datetime import datetime
import json
import hashlib
from collections import defaultdict, deque
from enum import Enum

from .style_anchor_manager import StyleVector, StyleType
from cache.cache_manager import CacheManager
from database.database_manager import DatabaseManager


class MatchingStrategy(Enum):
    """åŒ¹é…ç­–ç•¥"""
    SEMANTIC_FIRST = "semantic_first"      # è¯­ä¹‰ä¼˜å…ˆ
    STYLE_FIRST = "style_first"           # é£æ ¼ä¼˜å…ˆ
    BALANCED = "balanced"                 # å¹³è¡¡æ¨¡å¼
    USER_PREFERENCE = "user_preference"   # ç”¨æˆ·åå¥½
    DIVERSITY_BOOST = "diversity_boost"   # å¤šæ ·æ€§å¢å¼º


@dataclass
class MaterialFeatures:
    """ç´ æç‰¹å¾å‘é‡"""
    semantic_embedding: np.ndarray          # è¯­ä¹‰embedding (512ç»´)
    visual_features: np.ndarray             # è§†è§‰ç‰¹å¾ (256ç»´)
    audio_features: Optional[np.ndarray]    # éŸ³é¢‘ç‰¹å¾ (128ç»´)
    style_vector: StyleVector               # é£æ ¼å‘é‡
    quality_score: float                    # è´¨é‡è¯„åˆ† 0-1
    popularity_score: float                 # çƒ­åº¦è¯„åˆ† 0-1
    freshness_score: float                  # æ–°é²œåº¦è¯„åˆ† 0-1
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class MatchingContext:
    """åŒ¹é…ä¸Šä¸‹æ–‡"""
    query_text: str                         # æŸ¥è¯¢æ–‡æœ¬
    user_id: Optional[str]                  # ç”¨æˆ·ID
    session_id: str                         # ä¼šè¯ID
    style_anchor: Optional[StyleVector]     # é£æ ¼é”šç‚¹
    previous_materials: List[str]           # ä¹‹å‰ä½¿ç”¨çš„ç´ æ
    user_preferences: Dict[str, Any]        # ç”¨æˆ·åå¥½
    context_metadata: Dict[str, Any]        # ä¸Šä¸‹æ–‡å…ƒæ•°æ®
    matching_strategy: MatchingStrategy     # åŒ¹é…ç­–ç•¥


@dataclass
class MatchResult:
    """åŒ¹é…ç»“æœ"""
    material_id: str
    confidence_score: float                 # ç½®ä¿¡åº¦ 0-1
    relevance_score: float                  # ç›¸å…³æ€§ 0-1
    style_consistency: float                # é£æ ¼ä¸€è‡´æ€§ 0-1
    quality_factor: float                   # è´¨é‡å› å­ 0-1
    diversity_bonus: float                  # å¤šæ ·æ€§å¥–åŠ± 0-1
    final_score: float                      # æœ€ç»ˆè¯„åˆ† 0-1
    explanation: str                        # åŒ¹é…åŸå› è¯´æ˜
    features: MaterialFeatures              # ç´ æç‰¹å¾


class UserPreferenceModel:
    """ç”¨æˆ·åå¥½æ¨¡å‹"""

    def __init__(self, cache_manager: CacheManager):
        self.cache_manager = cache_manager
        self.preference_decay = 0.95  # åå¥½è¡°å‡å› å­
        self.learning_rate = 0.1      # å­¦ä¹ ç‡

    async def get_user_preferences(self, user_id: str) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·åå¥½"""
        cache_key = f"user_preferences:{user_id}"
        cached_prefs = await self.cache_manager.get(cache_key)

        if cached_prefs:
            return json.loads(cached_prefs)

        # é»˜è®¤åå¥½
        default_prefs = {
            'style_preferences': {
                StyleType.REALISTIC.value: 0.5,
                StyleType.CINEMATIC.value: 0.3,
                StyleType.ANIME.value: 0.2
            },
            'quality_threshold': 0.6,
            'diversity_preference': 0.7,
            'content_categories': {},
            'color_preferences': [],
            'interaction_history': [],
            'last_updated': datetime.now().isoformat()
        }

        await self.cache_manager.set(cache_key, json.dumps(default_prefs), expire=3600)
        return default_prefs

    async def update_preferences(self, user_id: str, material_id: str,
                               action: str, features: MaterialFeatures):
        """æ›´æ–°ç”¨æˆ·åå¥½"""
        preferences = await self.get_user_preferences(user_id)

        # æ ¹æ®ç”¨æˆ·è¡Œä¸ºæ›´æ–°åå¥½
        if action == "selected":
            weight = 1.0
        elif action == "liked":
            weight = 1.5
        elif action == "disliked":
            weight = -1.0
        elif action == "skipped":
            weight = -0.3
        else:
            weight = 0.0

        # æ›´æ–°é£æ ¼åå¥½
        style_type = features.style_vector.style_type.value
        current_pref = preferences['style_preferences'].get(style_type, 0.5)
        new_pref = current_pref + (weight * self.learning_rate)
        preferences['style_preferences'][style_type] = max(0.0, min(1.0, new_pref))

        # æ›´æ–°å†…å®¹ç±»åˆ«åå¥½
        for category in features.metadata.get('categories', []):
            current_cat_pref = preferences['content_categories'].get(category, 0.5)
            new_cat_pref = current_cat_pref + (weight * self.learning_rate * 0.5)
            preferences['content_categories'][category] = max(0.0, min(1.0, new_cat_pref))

        # æ·»åŠ äº¤äº’å†å²
        interaction = {
            'material_id': material_id,
            'action': action,
            'timestamp': datetime.now().isoformat(),
            'features_hash': hashlib.md5(str(features).encode()).hexdigest()
        }
        preferences['interaction_history'].append(interaction)

        # é™åˆ¶å†å²è®°å½•é•¿åº¦
        if len(preferences['interaction_history']) > 1000:
            preferences['interaction_history'] = preferences['interaction_history'][-1000:]

        preferences['last_updated'] = datetime.now().isoformat()

        # ç¼“å­˜æ›´æ–°çš„åå¥½
        cache_key = f"user_preferences:{user_id}"
        await self.cache_manager.set(cache_key, json.dumps(preferences), expire=3600)

    def calculate_preference_score(self, preferences: Dict[str, Any],
                                 features: MaterialFeatures) -> float:
        """è®¡ç®—åŸºäºç”¨æˆ·åå¥½çš„è¯„åˆ†"""
        score = 0.0
        total_weight = 0.0

        # é£æ ¼åå¥½è¯„åˆ†
        style_type = features.style_vector.style_type.value
        style_pref = preferences['style_preferences'].get(style_type, 0.5)
        score += style_pref * 0.4
        total_weight += 0.4

        # å†…å®¹ç±»åˆ«åå¥½è¯„åˆ†
        categories = features.metadata.get('categories', [])
        if categories:
            category_scores = []
            for category in categories:
                cat_pref = preferences['content_categories'].get(category, 0.5)
                category_scores.append(cat_pref)
            avg_category_score = np.mean(category_scores)
            score += avg_category_score * 0.3
            total_weight += 0.3

        # è´¨é‡åå¥½è¯„åˆ†
        quality_threshold = preferences.get('quality_threshold', 0.6)
        if features.quality_score >= quality_threshold:
            score += features.quality_score * 0.3
        else:
            score += features.quality_score * 0.1  # é™æƒ
        total_weight += 0.3

        return score / total_weight if total_weight > 0 else 0.5


class SemanticMatcher:
    """è¯­ä¹‰åŒ¹é…å™¨"""

    def __init__(self):
        self.embedding_cache = {}
        self.similarity_threshold = 0.7

    async def calculate_semantic_similarity(self, query_embedding: np.ndarray,
                                          material_embedding: np.ndarray) -> float:
        """è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦"""
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        query_norm = np.linalg.norm(query_embedding)
        material_norm = np.linalg.norm(material_embedding)

        if query_norm == 0 or material_norm == 0:
            return 0.0

        similarity = np.dot(query_embedding, material_embedding) / (query_norm * material_norm)
        return max(0.0, similarity)

    async def extract_query_embedding(self, query_text: str) -> np.ndarray:
        """æå–æŸ¥è¯¢æ–‡æœ¬çš„embedding"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„embeddingæ¨¡å‹
        # æš‚æ—¶ä½¿ç”¨æ¨¡æ‹Ÿçš„embedding
        query_hash = hashlib.md5(query_text.encode()).hexdigest()

        if query_hash in self.embedding_cache:
            return self.embedding_cache[query_hash]

        # æ¨¡æ‹Ÿembeddingæå–
        # åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨BERTã€Sentence-BERTç­‰æ¨¡å‹
        embedding = np.random.randn(512)  # 512ç»´embedding
        embedding = embedding / np.linalg.norm(embedding)  # å½’ä¸€åŒ–

        self.embedding_cache[query_hash] = embedding
        return embedding

    def calculate_keyword_overlap(self, query_text: str,
                                material_metadata: Dict[str, Any]) -> float:
        """è®¡ç®—å…³é”®è¯é‡å åº¦"""
        query_words = set(query_text.lower().split())
        material_text = " ".join([
            material_metadata.get('title', ''),
            material_metadata.get('description', ''),
            " ".join(material_metadata.get('tags', []))
        ]).lower()
        material_words = set(material_text.split())

        if not query_words:
            return 0.0

        overlap = len(query_words.intersection(material_words))
        return overlap / len(query_words)


class DiversityManager:
    """å¤šæ ·æ€§ç®¡ç†å™¨"""

    def __init__(self, diversity_window: int = 10):
        self.diversity_window = diversity_window
        self.recent_materials = deque(maxlen=diversity_window)

    def calculate_diversity_score(self, candidate_features: MaterialFeatures) -> float:
        """è®¡ç®—å¤šæ ·æ€§è¯„åˆ†"""
        if not self.recent_materials:
            return 1.0

        # è®¡ç®—ä¸æœ€è¿‘ææ–™çš„å¹³å‡è·ç¦»
        distances = []
        for recent_features in self.recent_materials:
            # é£æ ¼è·ç¦»
            style_distance = candidate_features.style_vector.distance(recent_features.style_vector)

            # è¯­ä¹‰è·ç¦»
            semantic_distance = 1.0 - np.dot(
                candidate_features.semantic_embedding,
                recent_features.semantic_embedding
            ) / (
                np.linalg.norm(candidate_features.semantic_embedding) *
                np.linalg.norm(recent_features.semantic_embedding)
            )

            # ç»¼åˆè·ç¦»
            combined_distance = (style_distance + semantic_distance) / 2
            distances.append(combined_distance)

        avg_distance = np.mean(distances)
        return min(1.0, avg_distance)

    def add_selected_material(self, features: MaterialFeatures):
        """æ·»åŠ è¢«é€‰ä¸­çš„ç´ æåˆ°å†å²è®°å½•"""
        self.recent_materials.append(features)

    def reset_history(self):
        """é‡ç½®å†å²è®°å½•"""
        self.recent_materials.clear()


class EnhancedMaterialMatcher:
    """å¢å¼ºç´ æåŒ¹é…å¼•æ“"""

    def __init__(self, cache_manager: CacheManager, database_manager: DatabaseManager):
        self.cache_manager = cache_manager
        self.database_manager = database_manager

        # å­ç»„ä»¶
        self.user_preference_model = UserPreferenceModel(cache_manager)
        self.semantic_matcher = SemanticMatcher()
        self.diversity_manager = DiversityManager()

        # åŒ¹é…å‚æ•°
        self.weights = {
            'semantic': 0.35,      # è¯­ä¹‰æƒé‡
            'style': 0.25,         # é£æ ¼æƒé‡
            'quality': 0.20,       # è´¨é‡æƒé‡
            'preference': 0.15,    # ç”¨æˆ·åå¥½æƒé‡
            'diversity': 0.05      # å¤šæ ·æ€§æƒé‡
        }

        # ç¼“å­˜
        self.material_features_cache = {}

    async def match_materials(self, context: MatchingContext,
                            candidate_materials: List[Dict[str, Any]],
                            top_k: int = 10) -> List[MatchResult]:
        """åŒ¹é…ç´ æ"""
        try:
            print(f"ğŸ” Starting material matching for query: {context.query_text[:50]}...")

            # 1. æå–æŸ¥è¯¢embedding
            query_embedding = await self.semantic_matcher.extract_query_embedding(context.query_text)

            # 2. è·å–ç”¨æˆ·åå¥½
            user_preferences = {}
            if context.user_id:
                user_preferences = await self.user_preference_model.get_user_preferences(context.user_id)

            # 3. æ‰¹é‡è®¡ç®—åŒ¹é…åˆ†æ•°
            match_results = []
            for material in candidate_materials:
                try:
                    features = await self._extract_material_features(material)
                    if features:
                        match_result = await self._calculate_match_score(
                            context, query_embedding, features, user_preferences, material
                        )
                        match_results.append(match_result)
                except Exception as e:
                    print(f"âŒ Error processing material {material.get('id', 'unknown')}: {e}")
                    continue

            # 4. æ’åºå’Œå¤šæ ·æ€§è°ƒæ•´
            sorted_results = await self._rank_and_diversify(
                match_results, context.matching_strategy, top_k
            )

            # 5. æ›´æ–°å¤šæ ·æ€§å†å²
            for result in sorted_results[:top_k]:
                self.diversity_manager.add_selected_material(result.features)

            print(f"âœ… Material matching completed: {len(sorted_results)} results")
            return sorted_results[:top_k]

        except Exception as e:
            print(f"âŒ Material matching failed: {e}")
            return []

    async def _extract_material_features(self, material: Dict[str, Any]) -> Optional[MaterialFeatures]:
        """æå–ç´ æç‰¹å¾"""
        material_id = material.get('id')
        if not material_id:
            return None

        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"material_features:{material_id}"
        cached_features = await self.cache_manager.get(cache_key)

        if cached_features:
            features_dict = json.loads(cached_features)
            return self._deserialize_features(features_dict)

        try:
            # æ¨¡æ‹Ÿç‰¹å¾æå– - åœ¨å®é™…å®ç°ä¸­ä¼šè°ƒç”¨çœŸå®çš„ç‰¹å¾æå–æ¨¡å‹
            semantic_embedding = np.random.randn(512)
            semantic_embedding = semantic_embedding / np.linalg.norm(semantic_embedding)

            visual_features = np.random.randn(256)
            visual_features = visual_features / np.linalg.norm(visual_features)

            # ä»ç´ æå…ƒæ•°æ®æ¨æ–­é£æ ¼
            style_type = self._infer_style_type(material)
            style_vector = StyleVector(
                style_type=style_type,
                color_palette=material.get('color_palette', ['#000000']),
                saturation=np.random.uniform(0.3, 0.9),
                brightness=np.random.uniform(0.3, 0.8),
                contrast=np.random.uniform(0.4, 0.9),
                texture_complexity=np.random.uniform(0.2, 0.8),
                motion_intensity=np.random.uniform(0.1, 0.7),
                camera_stability=np.random.uniform(0.5, 0.9)
            )

            features = MaterialFeatures(
                semantic_embedding=semantic_embedding,
                visual_features=visual_features,
                audio_features=np.random.randn(128) if material.get('type') == 'audio' else None,
                style_vector=style_vector,
                quality_score=material.get('quality_score', np.random.uniform(0.5, 0.95)),
                popularity_score=material.get('popularity_score', np.random.uniform(0.1, 0.8)),
                freshness_score=self._calculate_freshness_score(material),
                metadata=material.get('metadata', {})
            )

            # ç¼“å­˜ç‰¹å¾
            features_dict = self._serialize_features(features)
            await self.cache_manager.set(cache_key, json.dumps(features_dict), expire=1800)

            return features

        except Exception as e:
            print(f"âŒ Feature extraction failed for material {material_id}: {e}")
            return None

    def _infer_style_type(self, material: Dict[str, Any]) -> StyleType:
        """ä»ç´ æå…ƒæ•°æ®æ¨æ–­é£æ ¼ç±»å‹"""
        tags = material.get('tags', [])
        title = material.get('title', '').lower()
        description = material.get('description', '').lower()

        # ç®€å•çš„å…³é”®è¯åŒ¹é…æ¨æ–­
        if any(keyword in title or keyword in description for keyword in ['anime', 'cartoon', 'åŠ¨æ¼«']):
            return StyleType.ANIME
        elif any(keyword in title or keyword in description for keyword in ['cinematic', 'movie', 'ç”µå½±']):
            return StyleType.CINEMATIC
        elif any(keyword in title or keyword in description for keyword in ['cyber', 'neon', 'ç§‘æŠ€']):
            return StyleType.CYBERPUNK
        elif any(keyword in title or keyword in description for keyword in ['documentary', 'çºªå½•']):
            return StyleType.DOCUMENTARY
        elif any(keyword in title or keyword in description for keyword in ['ad', 'commercial', 'å¹¿å‘Š']):
            return StyleType.ADVERTISEMENT
        else:
            return StyleType.REALISTIC  # é»˜è®¤é£æ ¼

    def _calculate_freshness_score(self, material: Dict[str, Any]) -> float:
        """è®¡ç®—æ–°é²œåº¦è¯„åˆ†"""
        upload_date = material.get('upload_date')
        if not upload_date:
            return 0.5

        try:
            upload_timestamp = datetime.fromisoformat(upload_date.replace('Z', '+00:00'))
            now = datetime.now()
            days_old = (now - upload_timestamp).days

            # æ–°é²œåº¦é€’å‡å‡½æ•°
            if days_old <= 7:
                return 1.0
            elif days_old <= 30:
                return 0.8
            elif days_old <= 90:
                return 0.6
            elif days_old <= 365:
                return 0.4
            else:
                return 0.2

        except Exception:
            return 0.5

    async def _calculate_match_score(self, context: MatchingContext,
                                   query_embedding: np.ndarray,
                                   features: MaterialFeatures,
                                   user_preferences: Dict[str, Any],
                                   material: Dict[str, Any]) -> MatchResult:
        """è®¡ç®—åŒ¹é…åˆ†æ•°"""
        scores = {}

        # 1. è¯­ä¹‰ç›¸ä¼¼åº¦
        semantic_score = await self.semantic_matcher.calculate_semantic_similarity(
            query_embedding, features.semantic_embedding
        )

        # åŠ å…¥å…³é”®è¯é‡å åº¦
        keyword_overlap = self.semantic_matcher.calculate_keyword_overlap(
            context.query_text, features.metadata
        )
        semantic_score = semantic_score * 0.8 + keyword_overlap * 0.2

        scores['semantic'] = semantic_score

        # 2. é£æ ¼ä¸€è‡´æ€§
        style_score = 1.0
        if context.style_anchor:
            style_distance = features.style_vector.distance(context.style_anchor)
            style_score = max(0.0, 1.0 - style_distance)
        scores['style'] = style_score

        # 3. è´¨é‡è¯„åˆ†
        quality_score = (
            features.quality_score * 0.6 +
            features.popularity_score * 0.2 +
            features.freshness_score * 0.2
        )
        scores['quality'] = quality_score

        # 4. ç”¨æˆ·åå¥½è¯„åˆ†
        preference_score = 0.5
        if user_preferences and context.user_id:
            preference_score = self.user_preference_model.calculate_preference_score(
                user_preferences, features
            )
        scores['preference'] = preference_score

        # 5. å¤šæ ·æ€§è¯„åˆ†
        diversity_score = self.diversity_manager.calculate_diversity_score(features)
        scores['diversity'] = diversity_score

        # 6. è®¡ç®—æœ€ç»ˆè¯„åˆ†
        final_score = sum(
            scores[component] * self.weights[component]
            for component in scores
        )

        # åº”ç”¨åŒ¹é…ç­–ç•¥è°ƒæ•´
        final_score = self._apply_strategy_adjustment(
            final_score, scores, context.matching_strategy
        )

        # ç”Ÿæˆè§£é‡Š
        explanation = self._generate_explanation(scores, context.matching_strategy)

        return MatchResult(
            material_id=material['id'],
            confidence_score=final_score,
            relevance_score=semantic_score,
            style_consistency=style_score,
            quality_factor=quality_score,
            diversity_bonus=diversity_score,
            final_score=final_score,
            explanation=explanation,
            features=features
        )

    def _apply_strategy_adjustment(self, base_score: float, scores: Dict[str, float],
                                 strategy: MatchingStrategy) -> float:
        """æ ¹æ®åŒ¹é…ç­–ç•¥è°ƒæ•´è¯„åˆ†"""
        if strategy == MatchingStrategy.SEMANTIC_FIRST:
            # è¯­ä¹‰ä¼˜å…ˆï¼šæå‡è¯­ä¹‰æƒé‡
            return base_score + (scores['semantic'] - 0.5) * 0.2

        elif strategy == MatchingStrategy.STYLE_FIRST:
            # é£æ ¼ä¼˜å…ˆï¼šæå‡é£æ ¼æƒé‡
            return base_score + (scores['style'] - 0.5) * 0.2

        elif strategy == MatchingStrategy.USER_PREFERENCE:
            # ç”¨æˆ·åå¥½ä¼˜å…ˆï¼šæå‡åå¥½æƒé‡
            return base_score + (scores['preference'] - 0.5) * 0.3

        elif strategy == MatchingStrategy.DIVERSITY_BOOST:
            # å¤šæ ·æ€§å¢å¼ºï¼šå¤§å¹…æå‡å¤šæ ·æ€§æƒé‡
            return base_score + (scores['diversity'] - 0.5) * 0.4

        else:  # BALANCED
            return base_score

    def _generate_explanation(self, scores: Dict[str, float],
                            strategy: MatchingStrategy) -> str:
        """ç”ŸæˆåŒ¹é…è§£é‡Š"""
        explanations = []

        if scores['semantic'] > 0.8:
            explanations.append("è¯­ä¹‰é«˜åº¦ç›¸å…³")
        elif scores['semantic'] > 0.6:
            explanations.append("è¯­ä¹‰è¾ƒä¸ºç›¸å…³")

        if scores['style'] > 0.8:
            explanations.append("é£æ ¼å®Œå…¨ä¸€è‡´")
        elif scores['style'] > 0.6:
            explanations.append("é£æ ¼åŸºæœ¬ä¸€è‡´")

        if scores['quality'] > 0.8:
            explanations.append("é«˜è´¨é‡ç´ æ")

        if scores['preference'] > 0.7:
            explanations.append("ç¬¦åˆç”¨æˆ·åå¥½")

        if scores['diversity'] > 0.7:
            explanations.append("å¢åŠ å†…å®¹å¤šæ ·æ€§")

        if strategy == MatchingStrategy.SEMANTIC_FIRST:
            explanations.insert(0, "è¯­ä¹‰ä¼˜å…ˆåŒ¹é…")
        elif strategy == MatchingStrategy.STYLE_FIRST:
            explanations.insert(0, "é£æ ¼ä¼˜å…ˆåŒ¹é…")

        return "ï¼Œ".join(explanations) if explanations else "åŸºäºç»¼åˆè¯„åˆ†åŒ¹é…"

    async def _rank_and_diversify(self, results: List[MatchResult],
                                strategy: MatchingStrategy, top_k: int) -> List[MatchResult]:
        """æ’åºå¹¶åº”ç”¨å¤šæ ·æ€§è°ƒæ•´"""
        # é¦–å…ˆæŒ‰è¯„åˆ†æ’åº
        sorted_results = sorted(results, key=lambda x: x.final_score, reverse=True)

        # å¦‚æœå¯ç”¨å¤šæ ·æ€§å¢å¼ºï¼Œé‡æ–°æ’åº
        if strategy == MatchingStrategy.DIVERSITY_BOOST and len(sorted_results) > top_k:
            diversified_results = []
            remaining_results = sorted_results.copy()

            # é€‰æ‹©ç¬¬ä¸€ä¸ªï¼ˆæœ€é«˜åˆ†ï¼‰
            if remaining_results:
                diversified_results.append(remaining_results.pop(0))

            # åç»­é€‰æ‹©æ—¶è€ƒè™‘å¤šæ ·æ€§
            while len(diversified_results) < top_k and remaining_results:
                best_candidate = None
                best_score = -1

                for candidate in remaining_results:
                    # è®¡ç®—ä¸å·²é€‰æ‹©ç´ æçš„å¤šæ ·æ€§
                    diversity_bonus = 0
                    for selected in diversified_results:
                        diversity_bonus += candidate.features.style_vector.distance(
                            selected.features.style_vector
                        )

                    # ç»¼åˆè¯„åˆ† = åŸå§‹è¯„åˆ† + å¤šæ ·æ€§å¥–åŠ±
                    combined_score = candidate.final_score + diversity_bonus * 0.1

                    if combined_score > best_score:
                        best_score = combined_score
                        best_candidate = candidate

                if best_candidate:
                    diversified_results.append(best_candidate)
                    remaining_results.remove(best_candidate)

            return diversified_results

        return sorted_results

    def _serialize_features(self, features: MaterialFeatures) -> Dict[str, Any]:
        """åºåˆ—åŒ–ç‰¹å¾ä»¥ä¾›ç¼“å­˜"""
        return {
            'semantic_embedding': features.semantic_embedding.tolist(),
            'visual_features': features.visual_features.tolist(),
            'audio_features': features.audio_features.tolist() if features.audio_features is not None else None,
            'style_vector': {
                'style_type': features.style_vector.style_type.value,
                'color_palette': features.style_vector.color_palette,
                'saturation': features.style_vector.saturation,
                'brightness': features.style_vector.brightness,
                'contrast': features.style_vector.contrast,
                'texture_complexity': features.style_vector.texture_complexity,
                'motion_intensity': features.style_vector.motion_intensity,
                'camera_stability': features.style_vector.camera_stability
            },
            'quality_score': features.quality_score,
            'popularity_score': features.popularity_score,
            'freshness_score': features.freshness_score,
            'metadata': features.metadata
        }

    def _deserialize_features(self, features_dict: Dict[str, Any]) -> MaterialFeatures:
        """ååºåˆ—åŒ–ç‰¹å¾"""
        style_data = features_dict['style_vector']
        style_vector = StyleVector(
            style_type=StyleType(style_data['style_type']),
            color_palette=style_data['color_palette'],
            saturation=style_data['saturation'],
            brightness=style_data['brightness'],
            contrast=style_data['contrast'],
            texture_complexity=style_data['texture_complexity'],
            motion_intensity=style_data['motion_intensity'],
            camera_stability=style_data['camera_stability']
        )

        return MaterialFeatures(
            semantic_embedding=np.array(features_dict['semantic_embedding']),
            visual_features=np.array(features_dict['visual_features']),
            audio_features=np.array(features_dict['audio_features']) if features_dict['audio_features'] else None,
            style_vector=style_vector,
            quality_score=features_dict['quality_score'],
            popularity_score=features_dict['popularity_score'],
            freshness_score=features_dict['freshness_score'],
            metadata=features_dict['metadata']
        )

    async def update_user_feedback(self, user_id: str, material_id: str,
                                 action: str, context: MatchingContext):
        """æ›´æ–°ç”¨æˆ·åé¦ˆ"""
        if user_id and material_id in self.material_features_cache:
            features = self.material_features_cache[material_id]
            await self.user_preference_model.update_preferences(
                user_id, material_id, action, features
            )

    async def get_matching_analytics(self, session_id: str) -> Dict[str, Any]:
        """è·å–åŒ¹é…åˆ†ææ•°æ®"""
        return {
            'session_id': session_id,
            'total_queries': len(self.semantic_matcher.embedding_cache),
            'cache_hit_rate': 0.85,  # æ¨¡æ‹Ÿæ•°æ®
            'average_response_time': 120,  # ms
            'diversity_stats': {
                'recent_materials_count': len(self.diversity_manager.recent_materials),
                'diversity_window': self.diversity_manager.diversity_window
            },
            'performance_metrics': {
                'semantic_matching_time': 45,  # ms
                'feature_extraction_time': 200,  # ms
                'ranking_time': 30  # ms
            }
        }