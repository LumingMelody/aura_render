#!/usr/bin/env python3
"""
çœŸå®è§†é¢‘ç”Ÿæˆå™¨ - ä½¿ç”¨MoviePyç”Ÿæˆå®é™…è§†é¢‘æ–‡ä»¶
"""

import os
import json
import random
import tempfile
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
import logging
from datetime import datetime

import numpy as np
from PIL import Image, ImageDraw, ImageFont, ImageColor
import cv2
from moviepy import VideoClip, TextClip, CompositeVideoClip, AudioClip, AudioFileClip, concatenate_videoclips, ColorClip
import requests
from gtts import gTTS

logger = logging.getLogger(__name__)

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
OUTPUT_DIR = Path("/tmp/aura_render_outputs")
ASSETS_DIR = Path("/tmp/aura_render_assets")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
ASSETS_DIR.mkdir(parents=True, exist_ok=True)


class RealVideoGenerator:
    """çœŸå®è§†é¢‘ç”Ÿæˆå™¨"""

    def __init__(self):
        """åˆå§‹åŒ–è§†é¢‘ç”Ÿæˆå™¨"""
        self.temp_dir = Path(tempfile.gettempdir()) / "aura_render_temp"
        self.temp_dir.mkdir(parents=True, exist_ok=True)

        # è§†é¢‘å‚æ•°
        self.default_resolution = (1920, 1080)
        self.default_fps = 30
        self.default_duration = 30

        # é¢œè‰²ä¸»é¢˜
        self.themes = {
            "åŠ±å¿—": {"primary": "#FF6B6B", "secondary": "#4ECDC4", "bg": "#95E1D3"},
            "ä¸“ä¸š": {"primary": "#2C3E50", "secondary": "#3498DB", "bg": "#ECF0F1"},
            "åˆ›æ–°": {"primary": "#9B59B6", "secondary": "#E74C3C", "bg": "#F39C12"},
            "ç§‘æŠ€": {"primary": "#00B4D8", "secondary": "#0077B6", "bg": "#CAF0F8"},
            "æ¸©é¦¨": {"primary": "#F4A261", "secondary": "#E76F51", "bg": "#F9DCC4"}
        }

    def generate_video(self,
                       task_id: str,
                       description: str,
                       keywords: List[str],
                       duration: int = 30,
                       emotion: str = "åŠ±å¿—") -> Dict[str, Any]:
        """
        ç”ŸæˆçœŸå®è§†é¢‘

        Args:
            task_id: ä»»åŠ¡ID
            description: è§†é¢‘æè¿°
            keywords: å…³é”®è¯åˆ—è¡¨
            duration: è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
            emotion: æƒ…æ„ŸåŸºè°ƒ

        Returns:
            è§†é¢‘ç”Ÿæˆç»“æœ
        """
        try:
            logger.info(f"ğŸ¬ å¼€å§‹ç”ŸæˆçœŸå®è§†é¢‘ - Task ID: {task_id}")

            # é€‰æ‹©é¢œè‰²ä¸»é¢˜
            theme = self.themes.get(emotion, self.themes["ä¸“ä¸š"])

            # ç”Ÿæˆè§†é¢‘ç‰‡æ®µ
            clips = []
            segment_duration = duration / (len(keywords) + 2)  # +2 for intro and outro

            # 1. åˆ›å»ºå¼€åœºç‰‡æ®µ
            intro_clip = self._create_intro_clip(
                title=description[:50],
                duration=segment_duration,
                theme=theme
            )
            clips.append(intro_clip)

            # 2. ä¸ºæ¯ä¸ªå…³é”®è¯åˆ›å»ºç‰‡æ®µ
            for i, keyword in enumerate(keywords):
                keyword_clip = self._create_keyword_clip(
                    keyword=keyword,
                    index=i + 1,
                    duration=segment_duration,
                    theme=theme
                )
                clips.append(keyword_clip)

            # 3. åˆ›å»ºç»“å°¾ç‰‡æ®µ
            outro_clip = self._create_outro_clip(
                duration=segment_duration,
                theme=theme
            )
            clips.append(outro_clip)

            # 4. åˆå¹¶æ‰€æœ‰ç‰‡æ®µ
            final_video = concatenate_videoclips(clips, method="compose")

            # 5. æ·»åŠ èƒŒæ™¯éŸ³ä¹
            audio_path = self._generate_background_music(duration)
            if audio_path and os.path.exists(audio_path):
                background_audio = AudioFileClip(audio_path)
                background_audio = background_audio.subclipped(0, min(duration, background_audio.duration))
                background_audio = background_audio.volumex(0.3)  # é™ä½éŸ³é‡
                final_video = final_video.with_audio(background_audio)

            # 6. ç”Ÿæˆå­—å¹•
            subtitles = self._generate_subtitles(description, keywords, duration)
            if subtitles:
                final_video = self._add_subtitles(final_video, subtitles)

            # 7. è¾“å‡ºè§†é¢‘
            output_path = OUTPUT_DIR / f"video_{task_id}.mp4"
            final_video.write_videofile(
                str(output_path),
                fps=self.default_fps,
                codec='libx264',
                audio_codec='aac',
                temp_audiofile=str(self.temp_dir / f"temp_audio_{task_id}.m4a"),
                remove_temp=True
            )

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for clip in clips:
                clip.close()
            final_video.close()

            # è·å–æ–‡ä»¶ä¿¡æ¯
            file_size = output_path.stat().st_size / (1024 * 1024)  # MB

            result = {
                "success": True,
                "output_path": str(output_path),
                "duration": duration,
                "resolution": f"{self.default_resolution[0]}x{self.default_resolution[1]}",
                "file_size_mb": round(file_size, 2),
                "segments": len(clips),
                "emotion": emotion,
                "keywords": keywords,
                "timestamp": datetime.now().isoformat()
            }

            logger.info(f"âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ: {output_path}")
            return result

        except Exception as e:
            logger.error(f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "task_id": task_id
            }

    def _create_intro_clip(self, title: str, duration: float, theme: Dict) -> VideoClip:
        """åˆ›å»ºå¼€åœºåŠ¨ç”»"""
        def make_frame(t):
            """ç”Ÿæˆæ¯ä¸€å¸§"""
            img = Image.new('RGB', self.default_resolution, color=theme["bg"])
            draw = ImageDraw.Draw(img)

            # åŠ¨ç”»æ•ˆæœ - æ·¡å…¥
            alpha = min(1.0, t / 2.0)

            # ç»˜åˆ¶æ ‡é¢˜
            try:
                font = ImageFont.truetype("/System/Library/Fonts/PingFang.ttc", 80)
            except:
                font = ImageFont.load_default()

            text_bbox = draw.textbbox((0, 0), title, font=font)
            text_width = text_bbox[2] - text_bbox[0]
            text_height = text_bbox[3] - text_bbox[1]

            x = (self.default_resolution[0] - text_width) // 2
            y = (self.default_resolution[1] - text_height) // 2

            # ç»˜åˆ¶é˜´å½±
            shadow_offset = 5
            draw.text((x + shadow_offset, y + shadow_offset), title,
                     fill=(0, 0, 0, int(128 * alpha)), font=font)

            # ç»˜åˆ¶ä¸»æ–‡å­—
            draw.text((x, y), title, fill=theme["primary"], font=font)

            # æ·»åŠ è£…é¥°å…ƒç´ 
            if t > 1:
                # ç»˜åˆ¶åŠ¨æ€çº¿æ¡
                line_y = int(y + text_height + 50)
                line_width = int(text_width * min(1.0, (t - 1) / 1.0))
                line_x = x + (text_width - line_width) // 2
                draw.rectangle(
                    [line_x, line_y, line_x + line_width, line_y + 5],
                    fill=theme["secondary"]
                )

            return np.array(img)

        return VideoClip(make_frame, duration=duration)

    def _create_keyword_clip(self, keyword: str, index: int, duration: float, theme: Dict) -> VideoClip:
        """åˆ›å»ºå…³é”®è¯å±•ç¤ºç‰‡æ®µ"""
        def make_frame(t):
            """ç”Ÿæˆæ¯ä¸€å¸§"""
            img = Image.new('RGB', self.default_resolution, color=theme["bg"])
            draw = ImageDraw.Draw(img)

            # åŠ¨ç”»æ•ˆæœ - ç¼©æ”¾
            scale = 0.8 + 0.2 * np.sin(t * 2 * np.pi / 3)

            try:
                font_size = int(120 * scale)
                font = ImageFont.truetype("/System/Library/Fonts/PingFang.ttc", font_size)
                small_font = ImageFont.truetype("/System/Library/Fonts/PingFang.ttc", 40)
            except:
                font = ImageFont.load_default()
                small_font = ImageFont.load_default()

            # ç»˜åˆ¶åºå·
            number_text = f"#{index}"
            draw.text((100, 100), number_text, fill=theme["secondary"], font=small_font)

            # ç»˜åˆ¶å…³é”®è¯
            text_bbox = draw.textbbox((0, 0), keyword, font=font)
            text_width = text_bbox[2] - text_bbox[0]
            text_height = text_bbox[3] - text_bbox[1]

            x = (self.default_resolution[0] - text_width) // 2
            y = (self.default_resolution[1] - text_height) // 2

            # ç»˜åˆ¶èƒŒæ™¯å½¢çŠ¶
            padding = 50
            shape_alpha = int(255 * 0.3)
            overlay = Image.new('RGBA', self.default_resolution, (255, 255, 255, 0))
            overlay_draw = ImageDraw.Draw(overlay)
            overlay_draw.ellipse(
                [x - padding, y - padding,
                 x + text_width + padding, y + text_height + padding],
                fill=(*ImageColor.getrgb(theme["primary"]), shape_alpha)
            )
            img = Image.alpha_composite(img.convert('RGBA'), overlay).convert('RGB')
            draw = ImageDraw.Draw(img)

            # ç»˜åˆ¶å…³é”®è¯
            draw.text((x, y), keyword, fill="white", font=font)

            # æ·»åŠ åŠ¨æ€ç²’å­æ•ˆæœ
            if t > 0.5:
                for _ in range(5):
                    px = random.randint(0, self.default_resolution[0])
                    py = random.randint(0, self.default_resolution[1])
                    draw.ellipse([px, py, px + 5, px + 5], fill=theme["secondary"])

            return np.array(img)

        return VideoClip(make_frame, duration=duration)

    def _create_outro_clip(self, duration: float, theme: Dict) -> VideoClip:
        """åˆ›å»ºç»“å°¾åŠ¨ç”»"""
        def make_frame(t):
            """ç”Ÿæˆæ¯ä¸€å¸§"""
            img = Image.new('RGB', self.default_resolution, color=theme["bg"])
            draw = ImageDraw.Draw(img)

            # æ·¡å‡ºæ•ˆæœ
            alpha = max(0, 1.0 - t / duration)

            try:
                font = ImageFont.truetype("/System/Library/Fonts/PingFang.ttc", 60)
                small_font = ImageFont.truetype("/System/Library/Fonts/PingFang.ttc", 30)
            except:
                font = ImageFont.load_default()
                small_font = ImageFont.load_default()

            # ç»˜åˆ¶æ„Ÿè°¢æ–‡å­—
            thanks_text = "Thanks for Watching"
            text_bbox = draw.textbbox((0, 0), thanks_text, font=font)
            text_width = text_bbox[2] - text_bbox[0]
            text_height = text_bbox[3] - text_bbox[1]

            x = (self.default_resolution[0] - text_width) // 2
            y = (self.default_resolution[1] - text_height) // 2 - 50

            draw.text((x, y), thanks_text,
                     fill=theme["primary"], font=font)

            # ç»˜åˆ¶å‰¯æ ‡é¢˜
            subtitle = "Created with Aura Render"
            sub_bbox = draw.textbbox((0, 0), subtitle, font=small_font)
            sub_width = sub_bbox[2] - sub_bbox[0]

            sub_x = (self.default_resolution[0] - sub_width) // 2
            sub_y = y + text_height + 30

            draw.text((sub_x, sub_y), subtitle,
                     fill=theme["secondary"], font=small_font)

            # æ·»åŠ Logoæˆ–å›¾æ ‡ï¼ˆç®€å•çš„åœ†å½¢ï¼‰
            logo_y = sub_y + 80
            logo_size = 60
            logo_x = (self.default_resolution[0] - logo_size) // 2
            draw.ellipse(
                [logo_x, logo_y, logo_x + logo_size, logo_y + logo_size],
                fill=theme["primary"]
            )

            return np.array(img)

        return VideoClip(make_frame, duration=duration)

    def _generate_background_music(self, duration: int) -> Optional[str]:
        """ç”Ÿæˆæˆ–è·å–èƒŒæ™¯éŸ³ä¹"""
        try:
            # è¿™é‡Œå¯ä»¥é›†æˆéŸ³ä¹ç”ŸæˆAPIæˆ–ä½¿ç”¨é¢„è®¾éŸ³ä¹
            # æš‚æ—¶ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æ­£å¼¦æ³¢ä½œä¸ºç¤ºä¾‹
            audio_path = self.temp_dir / f"bgm_{datetime.now().timestamp()}.mp3"

            # ç”Ÿæˆç®€å•çš„éŸ³è°ƒ
            from moviepy import AudioClip

            def make_audio(t):
                """ç”ŸæˆéŸ³é¢‘æ³¢å½¢"""
                # åˆ›å»ºå’Œè°çš„éŸ³è°ƒ
                frequency1 = 440  # A4
                frequency2 = 554  # C#5
                frequency3 = 659  # E5

                signal = (np.sin(2 * np.pi * frequency1 * t) * 0.3 +
                         np.sin(2 * np.pi * frequency2 * t) * 0.2 +
                         np.sin(2 * np.pi * frequency3 * t) * 0.1)

                # æ·»åŠ æ·¡å…¥æ·¡å‡º
                if isinstance(t, (int, float)):
                    if t < 2:
                        signal *= t / 2
                    elif t > duration - 2:
                        signal *= (duration - t) / 2
                else:
                    # Handle numpy arrays
                    fade_in_mask = t < 2
                    fade_out_mask = t > duration - 2
                    signal = np.where(fade_in_mask, signal * t / 2, signal)
                    signal = np.where(fade_out_mask, signal * (duration - t) / 2, signal)

                return signal

            audio_clip = AudioClip(make_audio, duration=duration, fps=44100)
            audio_clip.write_audiofile(str(audio_path), logger=None)
            audio_clip.close()

            return str(audio_path)

        except Exception as e:
            logger.warning(f"èƒŒæ™¯éŸ³ä¹ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def _generate_subtitles(self, description: str, keywords: List[str], duration: int) -> List[Dict]:
        """ç”Ÿæˆå­—å¹•æ•°æ®"""
        subtitles = []
        segment_duration = duration / (len(keywords) + 2)

        # å¼€åœºå­—å¹•
        subtitles.append({
            "start": 0,
            "end": segment_duration,
            "text": description[:50]
        })

        # å…³é”®è¯å­—å¹•
        for i, keyword in enumerate(keywords):
            start_time = segment_duration * (i + 1)
            subtitles.append({
                "start": start_time,
                "end": start_time + segment_duration,
                "text": f"å…³é”®è¯: {keyword}"
            })

        # ç»“å°¾å­—å¹•
        subtitles.append({
            "start": duration - segment_duration,
            "end": duration,
            "text": "æ„Ÿè°¢è§‚çœ‹"
        })

        return subtitles

    def _add_subtitles(self, video: VideoClip, subtitles: List[Dict]) -> VideoClip:
        """æ·»åŠ å­—å¹•åˆ°è§†é¢‘"""
        subtitle_clips = []

        for subtitle in subtitles:
            # åˆ›å»ºæ–‡å­—ç‰‡æ®µ
            # Create text clip with font fallback
            try:
                txt_clip = TextClip(
                    text=subtitle["text"],
                    font_size=40,
                    color='white',
                    stroke_color='black',
                    stroke_width=2,
                    font='Arial',  # Use system default font
                    method='caption',
                    size=(self.default_resolution[0] - 100, None)
                )
            except Exception as e:
                self.logger.warning(f"Failed to create text clip: {e}")
                # Skip this subtitle if it fails
                continue

            # è®¾ç½®ä½ç½®å’Œæ—¶é•¿
            txt_clip = txt_clip.set_position(('center', 'bottom'))
            txt_clip = txt_clip.set_start(subtitle["start"])
            txt_clip = txt_clip.set_duration(subtitle["end"] - subtitle["start"])

            subtitle_clips.append(txt_clip)

        # åˆå¹¶å­—å¹•å’Œè§†é¢‘
        return CompositeVideoClip([video] + subtitle_clips)

    def generate_from_template(self, template: str, task_id: str, **kwargs) -> Dict[str, Any]:
        """åŸºäºæ¨¡æ¿ç”Ÿæˆè§†é¢‘"""
        templates = {
            "product_demo": {
                "description": "äº§å“æ¼”ç¤ºè§†é¢‘",
                "keywords": ["åˆ›æ–°", "å“è´¨", "ä¸“ä¸š"],
                "duration": 30,
                "emotion": "ä¸“ä¸š"
            },
            "birthday": {
                "description": "ç”Ÿæ—¥ç¥ç¦è§†é¢‘",
                "keywords": ["ç¥ç¦", "å¿«ä¹", "ç¾å¥½"],
                "duration": 20,
                "emotion": "æ¸©é¦¨"
            },
            "tech_intro": {
                "description": "ç§‘æŠ€ä»‹ç»è§†é¢‘",
                "keywords": ["AI", "æœªæ¥", "æ™ºèƒ½"],
                "duration": 30,
                "emotion": "ç§‘æŠ€"
            }
        }

        if template in templates:
            params = templates[template]
            params.update(kwargs)
            return self.generate_video(task_id, **params)
        else:
            return {"success": False, "error": f"Unknown template: {template}"}


# å•ä¾‹æ¨¡å¼
_generator_instance = None

def get_video_generator() -> RealVideoGenerator:
    """è·å–è§†é¢‘ç”Ÿæˆå™¨å®ä¾‹"""
    global _generator_instance
    if _generator_instance is None:
        _generator_instance = RealVideoGenerator()
    return _generator_instance


if __name__ == "__main__":
    # æµ‹è¯•è§†é¢‘ç”Ÿæˆ
    generator = get_video_generator()
    result = generator.generate_video(
        task_id="test_001",
        description="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•è§†é¢‘ï¼Œå±•ç¤ºAIæŠ€æœ¯çš„åˆ›æ–°åŠ›é‡",
        keywords=["äººå·¥æ™ºèƒ½", "åˆ›æ–°", "æœªæ¥"],
        duration=15,
        emotion="ç§‘æŠ€"
    )
    print(json.dumps(result, indent=2, ensure_ascii=False))