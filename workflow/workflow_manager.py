"""
å·¥ä½œæµç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†å¤šä¸ªå·¥ä½œæµå®ä¾‹
"""
from typing import Dict, List, Any, Optional, Callable
import asyncio
import uuid
from datetime import datetime
from dataclasses import dataclass, field

from .workflow_orchestrator import (
    WorkflowOrchestrator,
    WorkflowConfig,
    WorkflowResult,
    WorkflowStatus
)
from nodes.base_node import ProcessingContext
from task_queue.task_queue_manager import TaskQueueManager


@dataclass
class WorkflowInstance:
    """å·¥ä½œæµå®ä¾‹"""
    instance_id: str
    orchestrator: WorkflowOrchestrator
    context: ProcessingContext
    created_at: datetime
    status: WorkflowStatus = WorkflowStatus.IDLE
    result: Optional[WorkflowResult] = None


class WorkflowManager:
    """å·¥ä½œæµç®¡ç†å™¨"""

    def __init__(self, queue_manager: Optional[TaskQueueManager] = None):
        self.queue_manager = queue_manager

        # å·¥ä½œæµå®ä¾‹ç®¡ç†
        self.active_workflows: Dict[str, WorkflowInstance] = {}
        self.workflow_templates: Dict[str, Callable] = {}
        self.completed_workflows: Dict[str, WorkflowInstance] = {}

        # åå°ä»»åŠ¡ç®¡ç†ï¼ˆé˜²æ­¢è¢«åƒåœ¾å›æ”¶ï¼‰
        self.background_tasks: Dict[str, asyncio.Task] = {}

        # ç›‘æ§æ•°æ®
        self.global_metrics = {
            'total_workflows': 0,
            'active_workflows': 0,
            'completed_workflows': 0,
            'failed_workflows': 0,
            'average_execution_time': 0.0
        }

    def register_workflow_template(self, template_name: str,
                                 builder_func: Callable[[WorkflowConfig], WorkflowOrchestrator]):
        """æ³¨å†Œå·¥ä½œæµæ¨¡æ¿"""
        self.workflow_templates[template_name] = builder_func
        print(f"âœ… Workflow template registered: {template_name}")

    async def create_workflow(self, template_name: str, config: WorkflowConfig,
                            context: ProcessingContext, instance_id: Optional[str] = None) -> str:
        """åˆ›å»ºæ–°çš„å·¥ä½œæµå®ä¾‹

        Args:
            template_name: å·¥ä½œæµæ¨¡æ¿åç§°
            config: å·¥ä½œæµé…ç½®
            context: å¤„ç†ä¸Šä¸‹æ–‡
            instance_id: å¯é€‰çš„é¢„å®šä¹‰instance_idï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆ
        """
        try:
            if template_name not in self.workflow_templates:
                raise ValueError(f"Unknown workflow template: {template_name}")

            # åˆ›å»ºå·¥ä½œæµç¼–æ’å™¨
            builder = self.workflow_templates[template_name]
            orchestrator = builder(config)

            # ä½¿ç”¨æä¾›çš„instance_idæˆ–ç”Ÿæˆæ–°çš„
            if instance_id is None:
                instance_id = str(uuid.uuid4())

            instance = WorkflowInstance(
                instance_id=instance_id,
                orchestrator=orchestrator,
                context=context,
                created_at=datetime.now()
            )

            self.active_workflows[instance_id] = instance
            self.global_metrics['total_workflows'] += 1
            self.global_metrics['active_workflows'] += 1

            print(f"âœ… Workflow instance created: {instance_id}")
            return instance_id

        except Exception as e:
            print(f"âŒ Failed to create workflow: {e}")
            raise

    async def execute_workflow(self, instance_id: str) -> WorkflowResult:
        """æ‰§è¡Œå·¥ä½œæµ"""
        if instance_id not in self.active_workflows:
            raise ValueError(f"Workflow instance not found: {instance_id}")

        instance = self.active_workflows[instance_id]

        try:
            print(f"ğŸš€ Starting workflow execution: {instance_id}")

            # æ‰§è¡Œå·¥ä½œæµ
            result = await instance.orchestrator.execute(instance.context)

            # æ›´æ–°å®ä¾‹çŠ¶æ€
            instance.status = result.status
            instance.result = result

            # ç§»åŠ¨åˆ°å®Œæˆåˆ—è¡¨
            self.completed_workflows[instance_id] = instance
            del self.active_workflows[instance_id]

            # æ›´æ–°ç»Ÿè®¡
            self.global_metrics['active_workflows'] -= 1
            if result.status == WorkflowStatus.COMPLETED:
                self.global_metrics['completed_workflows'] += 1
            else:
                self.global_metrics['failed_workflows'] += 1

            # æ›´æ–°å¹³å‡æ‰§è¡Œæ—¶é—´
            self._update_average_execution_time(result.execution_time)

            print(f"âœ… Workflow completed: {instance_id} (Status: {result.status.value})")
            return result

        except Exception as e:
            instance.status = WorkflowStatus.FAILED
            print(f"âŒ Workflow execution failed: {instance_id} - {e}")
            raise

    async def execute_workflow_async(self, instance_id: str) -> str:
        """å¼‚æ­¥æ‰§è¡Œå·¥ä½œæµï¼ˆè¿”å›ä»»åŠ¡IDï¼‰"""
        if self.queue_manager:
            # ä½¿ç”¨ä»»åŠ¡é˜Ÿåˆ—å¼‚æ­¥æ‰§è¡Œ
            task_data = {
                'instance_id': instance_id,
                'action': 'execute_workflow'
            }

            task_id = await self.queue_manager.enqueue_task(
                'workflow_execution',
                'execute_workflow_task',
                args=(instance_id,),
                metadata=task_data
            )
            return task_id
        else:
            # ç›´æ¥ä½¿ç”¨asyncioï¼ˆä¿å­˜taskå¼•ç”¨é˜²æ­¢è¢«åƒåœ¾å›æ”¶ï¼‰
            task = asyncio.create_task(self.execute_workflow(instance_id))

            # ä¿å­˜taskå¼•ç”¨ï¼Œé˜²æ­¢è¢«åƒåœ¾å›æ”¶
            self.background_tasks[instance_id] = task

            # æ·»åŠ å®Œæˆå›è°ƒï¼šæ¸…ç†å·²å®Œæˆçš„task
            def cleanup_task(t):
                try:
                    # ä»å­—å…¸ä¸­ç§»é™¤å·²å®Œæˆçš„task
                    if instance_id in self.background_tasks:
                        del self.background_tasks[instance_id]
                        print(f"ğŸ§¹ Cleaned up background task for workflow: {instance_id}")
                except Exception as e:
                    print(f"âš ï¸ Error cleaning up task {instance_id}: {e}")

            task.add_done_callback(cleanup_task)

            # è¿”å› instance_idï¼ˆè€Œä¸æ˜¯æ— ç”¨çš„å†…å­˜åœ°å€ï¼‰
            # è¿™æ ·ç”¨æˆ·å¯ä»¥é€šè¿‡ /status/{instance_id} æŸ¥è¯¢çŠ¶æ€
            return instance_id

    def get_workflow_status(self, instance_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å·¥ä½œæµçŠ¶æ€"""
        instance = self.active_workflows.get(instance_id) or self.completed_workflows.get(instance_id)

        if not instance:
            return None

        status_info = instance.orchestrator.get_workflow_status()
        status_info.update({
            'instance_id': instance_id,
            'template_config': {
                'name': instance.orchestrator.config.name,
                'description': instance.orchestrator.config.description
            },
            'created_at': instance.created_at.isoformat(),
            'is_active': instance_id in self.active_workflows
        })

        if instance.result:
            status_info['final_result'] = {
                'status': instance.result.status.value,
                'execution_time': instance.result.execution_time,
                'nodes_executed': instance.result.nodes_executed,
                'nodes_failed': instance.result.nodes_failed
            }

        return status_info

    def list_workflows(self, status_filter: Optional[WorkflowStatus] = None) -> List[Dict[str, Any]]:
        """åˆ—å‡ºå·¥ä½œæµå®ä¾‹"""
        all_workflows = {}
        all_workflows.update(self.active_workflows)
        all_workflows.update(self.completed_workflows)

        workflows = []
        for instance_id, instance in all_workflows.items():
            if status_filter and instance.status != status_filter:
                continue

            workflow_info = {
                'instance_id': instance_id,
                'status': instance.status.value,
                'config_name': instance.orchestrator.config.name,
                'created_at': instance.created_at.isoformat(),
                'is_active': instance_id in self.active_workflows
            }

            if instance.result:
                workflow_info.update({
                    'execution_time': instance.result.execution_time,
                    'nodes_executed': instance.result.nodes_executed,
                    'nodes_failed': instance.result.nodes_failed
                })

            workflows.append(workflow_info)

        return workflows

    async def pause_workflow(self, instance_id: str) -> bool:
        """æš‚åœå·¥ä½œæµ"""
        if instance_id not in self.active_workflows:
            return False

        instance = self.active_workflows[instance_id]
        await instance.orchestrator.pause()
        instance.status = WorkflowStatus.PAUSED
        print(f"â¸ï¸ Workflow paused: {instance_id}")
        return True

    async def resume_workflow(self, instance_id: str) -> bool:
        """æ¢å¤å·¥ä½œæµ"""
        if instance_id not in self.active_workflows:
            return False

        instance = self.active_workflows[instance_id]
        await instance.orchestrator.resume()
        instance.status = WorkflowStatus.RUNNING
        print(f"â–¶ï¸ Workflow resumed: {instance_id}")
        return True

    async def cancel_workflow(self, instance_id: str) -> bool:
        """å–æ¶ˆå·¥ä½œæµ"""
        if instance_id not in self.active_workflows:
            return False

        instance = self.active_workflows[instance_id]
        await instance.orchestrator.cancel()
        instance.status = WorkflowStatus.CANCELLED

        # ç§»åŠ¨åˆ°å®Œæˆåˆ—è¡¨
        self.completed_workflows[instance_id] = instance
        del self.active_workflows[instance_id]

        self.global_metrics['active_workflows'] -= 1
        self.global_metrics['failed_workflows'] += 1

        print(f"ğŸ›‘ Workflow cancelled: {instance_id}")
        return True

    def cleanup_completed_workflows(self, max_age_hours: int = 24) -> int:
        """æ¸…ç†è¿‡æœŸçš„å·²å®Œæˆå·¥ä½œæµ"""
        cutoff_time = datetime.now().timestamp() - (max_age_hours * 3600)

        to_remove = []
        for instance_id, instance in self.completed_workflows.items():
            if instance.created_at.timestamp() < cutoff_time:
                to_remove.append(instance_id)

        for instance_id in to_remove:
            del self.completed_workflows[instance_id]

        print(f"ğŸ§¹ Cleaned up {len(to_remove)} completed workflows")
        return len(to_remove)

    def get_global_metrics(self) -> Dict[str, Any]:
        """è·å–å…¨å±€æŒ‡æ ‡"""
        metrics = self.global_metrics.copy()

        # æ·»åŠ å®æ—¶ç»Ÿè®¡
        metrics.update({
            'active_workflow_details': {
                instance_id: {
                    'config_name': instance.orchestrator.config.name,
                    'status': instance.status.value,
                    'runtime_seconds': (datetime.now() - instance.created_at).total_seconds()
                }
                for instance_id, instance in self.active_workflows.items()
            },
            'background_tasks_count': len(self.background_tasks),
            'background_tasks': list(self.background_tasks.keys())
        })

        return metrics

    def _update_average_execution_time(self, execution_time: float):
        """æ›´æ–°å¹³å‡æ‰§è¡Œæ—¶é—´"""
        total_completed = self.global_metrics['completed_workflows'] + self.global_metrics['failed_workflows']

        if total_completed == 1:
            self.global_metrics['average_execution_time'] = execution_time
        else:
            current_avg = self.global_metrics['average_execution_time']
            new_avg = ((current_avg * (total_completed - 1)) + execution_time) / total_completed
            self.global_metrics['average_execution_time'] = new_avg

    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        health_status = {
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'workflows': {
                'active': len(self.active_workflows),
                'templates': len(self.workflow_templates)
            },
            'queue_manager': {
                'available': self.queue_manager is not None,
                'status': 'unknown'
            }
        }

        # æ£€æŸ¥é˜Ÿåˆ—ç®¡ç†å™¨çŠ¶æ€
        if self.queue_manager:
            try:
                # è¿™é‡Œå¯ä»¥æ·»åŠ é˜Ÿåˆ—ç®¡ç†å™¨çš„å¥åº·æ£€æŸ¥
                health_status['queue_manager']['status'] = 'healthy'
            except Exception as e:
                health_status['queue_manager']['status'] = f'error: {e}'
                health_status['status'] = 'degraded'

        # æ£€æŸ¥æ´»è·ƒå·¥ä½œæµ
        stuck_workflows = []
        for instance_id, instance in self.active_workflows.items():
            runtime = (datetime.now() - instance.created_at).total_seconds()
            if runtime > 3600:  # è¶…è¿‡1å°æ—¶
                stuck_workflows.append({
                    'instance_id': instance_id,
                    'runtime_hours': runtime / 3600
                })

        if stuck_workflows:
            health_status['warnings'] = {
                'stuck_workflows': stuck_workflows
            }
            health_status['status'] = 'warning'

        return health_status

    def get_workflow_templates(self) -> List[str]:
        """è·å–å¯ç”¨çš„å·¥ä½œæµæ¨¡æ¿"""
        return list(self.workflow_templates.keys())

    def has_template(self, template_name: str) -> bool:
        """æ£€æŸ¥æ¨¡æ¿æ˜¯å¦å­˜åœ¨"""
        return template_name in self.workflow_templates

    async def restart_workflow(self, instance_id: str) -> str:
        """é‡å¯å·¥ä½œæµ"""
        # è·å–åŸå§‹å®ä¾‹
        instance = self.completed_workflows.get(instance_id) or self.active_workflows.get(instance_id)

        if not instance:
            raise ValueError(f"Workflow instance not found: {instance_id}")

        # å¦‚æœæ˜¯æ´»è·ƒå·¥ä½œæµï¼Œå…ˆå–æ¶ˆ
        if instance_id in self.active_workflows:
            await self.cancel_workflow(instance_id)

        # é‡ç½®ç¼–æ’å™¨
        instance.orchestrator.reset()

        # åˆ›å»ºæ–°å®ä¾‹
        new_instance_id = str(uuid.uuid4())
        new_instance = WorkflowInstance(
            instance_id=new_instance_id,
            orchestrator=instance.orchestrator,
            context=instance.context,
            created_at=datetime.now()
        )

        self.active_workflows[new_instance_id] = new_instance
        self.global_metrics['total_workflows'] += 1
        self.global_metrics['active_workflows'] += 1

        print(f"ğŸ”„ Workflow restarted: {instance_id} -> {new_instance_id}")
        return new_instance_id